{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11452216,"sourceType":"datasetVersion","datasetId":7175487},{"sourceId":342981,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":286894,"modelId":307707},{"sourceId":344038,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":287724,"modelId":308514}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b6598962-85c3-488b-8a9e-317157d0d2c5","cell_type":"markdown","source":"# Game","metadata":{}},{"id":"b5a345ea-dd69-438d-accc-1eeb4fe996c3","cell_type":"code","source":"import random\nimport numpy as np\n\n\nclass player():\n    \"\"\"Representation of a player in no thanks\"\"\"\n    def __init__(self, chip:int = 11 ):\n        \"\"\"\n        chip: number of chip the player has at the moment\n        card: list of cards that the player owns\n        \"\"\"\n        self.chip = chip\n        self.card = []\n    \n    def __repr__(self):\n        return f'Chip: {self.chip} | Card owned: {self.card}'\n        \n    def calculate_score(self):\n        \"\"\"Calculate the score of the player based on his card and chip\n        Idea: sum the value of all the cards. For a series of incremental values, only take the lowest\"\"\"\n        sorted_card = sorted(self.card)\n        total_score = 0\n        if len(sorted_card) == 0:\n            return self.chip\n        total_score -= sorted_card[0]\n        for score, prev_score in zip(sorted_card[1:], sorted_card[:-1]):\n            if score - prev_score > 1:\n                total_score -= score\n        total_score += self.chip\n        return total_score\n    \nclass game:\n    \"\"\"Representation of the state of the game\"\"\"\n    full_deck = [i for i in range(3,36)]\n    \n    def __init__(self,\n                 card: int = None,\n                 n_player: int = 3,\n                 n_chip: int = 11,\n                 n_remove_card: int = 9\n                 ):\n        \"\"\"\n        card: the card to start the game with\n        n_player: number of players\n        n_chip: number of chips for each player\n        n_remove_card: number of card to burn before playing\n        \"\"\"\n        self.min_card = 3\n        self.max_card = 35\n        \n        self.n_remove_card = n_remove_card\n        self.remain_card = game.full_deck\n        self.played_card = []\n        self.current_card = self.flip_card(card) if card else self.flip_card()\n        \n        self.chip_in_pot = 0\n        self.turn = 0 # need this to know which player to take\n        self.n_player = n_player\n        self.n_chip = n_chip\n\n        self.max_score = 20\n        self.min_score = -20\n        self.score_range = self.max_score - self.min_score\n        self.rollout_rule = {'pass': 0.9,\n                             'take': 0.1}\n        self.is_continue = True\n        self.init_player(n_player)\n    \n    def __len__(self):\n        return len(self.remain_card)\n    \n    def __str__(self):\n        return f'Current card: {self.current_card} | Played cards: {self.played_card}'\n    def __repr__(self):\n        return f'Current card: {self.current_card} | Played cards: {self.played_card}'\n\n    def init_player(self, n_player):\n        self.players = [player(chip =  self.n_chip) for _ in range(n_player)]\n        \n    def set_remain_card(self):\n        \"\"\"Update list of remaining cards\"\"\"\n        self.remain_card = [i for i in game.full_deck \n                            if i not in self.played_card]\n\n    def set_removed_card(self):\n        \"Remove 9 cards\"\n        self.removed_card = self.get_cards(9)\n        self.set_remain_card()\n\n    def get_cards(self, n):\n        'Randomize a card, if number of card remained == 9'\n        if len(self.remain_card) == self.n_remove_card:\n            return False\n        card = random.sample(self.remain_card, n)\n        return card[0] if n == 1 else card\n    \n    def flip_card(self, \n                card: int = None):\n        '''Progress the game by flipping a new card'''\n        if card == None:\n            card = self.get_cards(1)\n            if not card:\n                return card\n        self.played_card.append(card)\n        self.set_remain_card()\n        self.current_card = card\n        return card\n    \n    def calculate_ranking(self) -> list:\n        \"\"\"Get score for each player based on their ranking\"\"\"\n        score_list = np.array([player.calculate_score() for player in self.players])\n        rank_tmp = score_list.argsort()\n        ranking = rank_tmp.argsort()\n        step = self.score_range/(self.n_player - 1)\n        final_score = [self.min_score + step*float(rank) for rank in ranking]\n        return final_score\n    \n    def get_legal_action(self) -> list[str]:\n        \"\"\"Get the possible action a player can carry out\"\"\"\n        if not self.is_continue:\n            print('Game over, no legal action')\n            return []\n        current_player = self.players[self.turn]\n        if current_player.chip > 0:\n            return ['pass', 'take']\n        else:\n            return ['take']\n\n    def next_player(self, move) -> int:\n        \"\"\"Get index of next player. if take then turn does not change\"\"\"\n        if move == 'take':\n            return self.turn\n        elif move == 'pass':\n            return self.turn + 1 if self.turn + 1 < self.n_player else 0\n            \n    def action(self, move: str = 0, card: int = None) -> bool:\n        \"\"\"Progress the game\n        move: the action of the current player: pass or take\n        \"\"\"\n        if not self.is_continue:\n            print('Game over, cannot act')\n            return False\n        current_player = self.players[self.turn]\n        if move == 'take':\n            current_player.card.append(self.current_card)\n            current_player.chip += self.chip_in_pot\n            self.chip_in_pot = 0\n            is_continue = self.flip_card(card)\n            self.is_continue = is_continue\n            return self.is_continue\n\n        elif move == 'pass':\n            current_player.chip -= 1\n            self.chip_in_pot += 1\n            self.turn = self.next_player(move)\n            return True\n    \n    def rollout_policy_rule(self):\n        \"\"\"Rule based policy no.1 of rollout stage \n        Idea: 90% pass, 10% take\"\"\"\n        legal_action = self.get_legal_action()\n        weight = [self.rollout_rule.get(i) for i in legal_action]\n        move = random.choices(legal_action, weight)[0]\n        return move\n    \n    def rollout_policy_1(self, verbose = False) ->str:\n        \"\"\"Rule based policy no.2 of rollout stage\n        Idea: probability of a \"pass\" increases linearly as number of chips in pot increase. Reaches 100% if number of chips == 1/2 value of flipped card\n        \"\"\"\n        # current_player = self.players[self.turn]\n        legal_action = self.get_legal_action()\n        const = 0.5\n        prob = (self.chip_in_pot/self.current_card)/const\n        weight = [prob if i == 'take' else 1 - prob for i in legal_action]\n        move = random.choices(legal_action, weight)[0]\n        if verbose:\n            print(legal_action, weight)\n        return move\n    \n    def rollout_policy_2(self, verbose = False) -> str:\n        \"\"\"if number of chip in pot >= card value -1 -> 90% pass else 1% pass\"\"\"\n        # current_player = self.players[self.turn]\n        legal_action = self.get_legal_action()\n        remain = self.current_card//2 - self.chip_in_pot\n        if remain <= 1:\n            prob = 0.9\n        else:\n            prob = 0.01\n\n        weight = [prob if i == 'take' else 1 - prob for i in legal_action]\n        move = random.choices(legal_action, weight)[0]\n        if verbose:\n            print(legal_action, weight)\n        return move\n    \n    def rollout_policy_3(self, p = 0.98, verbose = False) -> str:\n        \"\"\"A bit more complicated, explained in comment\n        \n        p: probability of the selected action\n        \"\"\"\n        current_player = self.players[self.turn]\n        other_card = [i for i in self.played_card if i not in current_player.card]\n        good_for_me = any([abs(self.current_card - card) <= 2 for card in current_player.card])\n        good_for_them = any([abs(self.current_card - card) <= 2 for card in other_card])\n        least_chip = min([self.players[turn].chip for turn in range(self.n_player) if turn != self.turn])\n        legal_action = self.get_legal_action()\n\n        if good_for_me:\n            if good_for_them:\n                #then you must take or the other guy will take it\n                good_action = 'take'\n            else:\n                #how much can i farm\n                # look at the guy with the least chip\n                good_action = 'take'\n                if least_chip >= 3:\n                    # I will farm until the guy with the least chip has fewer than 3 chips\n                    good_action = 'pass'\n        else:\n            # can i afford to pass it till taken?\n            good_action = 'pass'\n            if current_player.chip <= 2 or self.chip_in_pot >= self.current_card//2:\n                # \n                good_action = 'take'\n\n        weight = [p if act == good_action else 1 - p for act in legal_action]\n        move = random.choices(legal_action, weight)[0]\n        if verbose:\n            print(legal_action, weight)\n        return move\n\n\n    def self_play(self, verbose = False):\n        \"\"\"Keeps playing till the game end\n        This is where you deploy your rollout policy\n        \"\"\"\n        while self.is_continue:\n            move = self.rollout_policy_3(verbose = verbose)\n            if verbose:\n                print(f'''Card: {self.current_card} | Chip in pot: {self.chip_in_pot} | Player: {self.turn} - {self.players[self.turn]}\nmove: {move}'''\n    )\n            self.is_continue = self.action(move)        \n        score_list = self.calculate_ranking()\n        return score_list\n    \n\nclass game_state:\n    \"\"\"This is node of the tree for later search\"\"\"\n    def __init__(self, parent = None, \n                turn: int = 0,\n                 depth = 0):\n        \"\"\"\n        turn: whose turn is it at this node\n        depth: number of turns passed. Could be use to limit the depth of the tree\n        \"\"\"\n\n        self.depth = depth\n        self.win = 0\n        self.n_explored = 0\n        self.parent = parent\n        self.child = [] # (uct, move, next node)\n        self.simulation_score = [0,0,0]\n        self.turn = turn # need this as reference when doing backpropagation\n\n    def calculate_uct(self):\n        \"\"\"Calculate its own UCT: Upper Confidence Bound\n        Can set your uct policy here\"\"\"\n        if self.n_explored == 0:\n            return np.inf\n        else:\n            exploitation = self.win/self.n_explored\n            exploration = np.sqrt(4*np.log(self.parent.n_explored)/self.n_explored)\n            return exploitation + exploration\n        \n    def get_best_move(self):\n        \"\"\"Get move with the highest win percentage. Used after simulation is finished\"\"\"\n        win_list = [child_node[-1].win/child_node[-1].n_explored for child_node in self.child]\n        return self.child[np.argmax(win_list)][1]\n    \n","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-18T15:58:06.944541Z","iopub.execute_input":"2025-04-18T15:58:06.945251Z","iopub.status.idle":"2025-04-18T15:58:06.969898Z","shell.execute_reply.started":"2025-04-18T15:58:06.945224Z","shell.execute_reply":"2025-04-18T15:58:06.969372Z"}},"outputs":[],"execution_count":2},{"id":"60794f84-4ce6-495f-8c8d-34b6534221fc","cell_type":"code","source":"","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"0c5fcc14-f22f-44fe-acdf-37e02021c3e5","cell_type":"markdown","source":"# PPO","metadata":{}},{"id":"196c3985-02e2-4056-82ba-6eaa51883b91","cell_type":"code","source":"import copy\nimport random\n\nimport pandas as pd\n\nfrom torch import nn\nimport torch\nfrom torch.optim import Adam\nfrom torch.distributions.categorical import Categorical\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:08.701080Z","iopub.execute_input":"2025-04-18T15:58:08.701352Z","iopub.status.idle":"2025-04-18T15:58:10.460836Z","shell.execute_reply.started":"2025-04-18T15:58:08.701332Z","shell.execute_reply":"2025-04-18T15:58:10.460303Z"}},"outputs":[],"execution_count":3},{"id":"4dda7e44-ac20-4ee9-9ae5-772c0944474a","cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:10.461890Z","iopub.execute_input":"2025-04-18T15:58:10.462348Z","iopub.status.idle":"2025-04-18T15:58:10.550800Z","shell.execute_reply.started":"2025-04-18T15:58:10.462322Z","shell.execute_reply":"2025-04-18T15:58:10.550151Z"}},"outputs":[],"execution_count":4},{"id":"de52ca57","cell_type":"code","source":"torch.manual_seed(1)\nrandom.seed(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:10.551638Z","iopub.execute_input":"2025-04-18T15:58:10.551875Z","iopub.status.idle":"2025-04-18T15:58:10.587160Z","shell.execute_reply.started":"2025-04-18T15:58:10.551859Z","shell.execute_reply":"2025-04-18T15:58:10.586434Z"}},"outputs":[],"execution_count":5},{"id":"1bd8fdb3","cell_type":"markdown","source":"# Model","metadata":{}},{"id":"435fe918","cell_type":"code","source":"class ppo(nn.Module):\n    def __init__(self, n_player, n_card = 33):\n        super().__init__()\n        self.n_action = 2\n        self.n_card = n_card\n        self.n_player = n_player\n        self.n_param_per_player = self.n_card + 1 # 33 cards + 1 number of chips\n        self.n_state_param = self.n_card*2 + 5 # 33 for flipped card, 33 for remain card, 1 for chip in pot, 1 for number of cards remained, 1 for good card self, 1 for good card other, 1 for chipinpot/current\n        self.input_dim = self.n_player*self.n_param_per_player + self.n_state_param\n\n        # self.policy = nn.Sequential(\n        #     nn.Linear(self.input_dim, 64),\n        #     nn.Tanh(),\n        #     nn.Linear(64, 64),\n        #     nn.Tanh(),\n        #     nn.Linear(64, self.n_action)\n        #     #FIX: NEED A MASK IN HERE FOR LEGAL ACTIONS\n        #     # no need to run through softmax, use logit instead for numerical stability\n        #     )\n        \n        # self.value = nn.Sequential(\n        #     nn.Linear(self.input_dim, 64),\n        #     nn.Tanh(),\n        #     nn.Linear(64, 64),\n        #     nn.Tanh(),\n        #     nn.Linear(64, 1)\n        #     )\n        \n        self.policy = nn.Sequential(\n            nn.Linear(self.input_dim, 256),\n            nn.LeakyReLU(negative_slope=0.01),\n            nn.Linear(256, 128),\n            nn.LeakyReLU(negative_slope=0.01),\n            nn.Linear(128, self.n_action)\n            #FIX: NEED A MASK IN HERE FOR LEGAL ACTIONS\n            # no need to run through softmax, use logit instead for numerical stability\n            )\n        \n        self.value = nn.Sequential(\n            nn.Linear(self.input_dim, 256),\n            nn.LeakyReLU(negative_slope=0.01),\n            nn.Linear(256, 128),\n            nn.LeakyReLU(negative_slope=0.01),\n            nn.Linear(128, 1)\n            )\n    \n    def get_policy(self, X, legal_move_mask):\n        \"\"\"Mask the legal output\n        legal_move_mask: boolean tensor, True for masked\"\"\"\n        logit = self.policy(X)\n        logit_masked = logit.masked_fill(legal_move_mask, float('-inf'))\n        return logit_masked\n\n    def forward(self, X, legal_move_mask, action = None):\n        \"\"\"Get value, probability\n        legal_move_mask: boolean tensor\n        action: tensor(1) Integer. This is the old sampled action. If none will do sampling\n        \"\"\"\n        logit = self.get_policy(X, legal_move_mask)\n        prob = Categorical(logits = logit)\n        if action == None:\n            action = prob.sample() # sample the action\n        log_prob = prob.log_prob(action) # this will be used for surrogate loss (log(a) - log(b) = log(a/b))\n        value = self.value(X)\n\n        return action, log_prob, prob.entropy(), value # sampled action, log probability of it, its entropy,value from value network\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:12.441268Z","iopub.execute_input":"2025-04-18T15:58:12.441536Z","iopub.status.idle":"2025-04-18T15:58:12.449177Z","shell.execute_reply.started":"2025-04-18T15:58:12.441515Z","shell.execute_reply":"2025-04-18T15:58:12.448429Z"}},"outputs":[],"execution_count":6},{"id":"ee11f1a8","cell_type":"markdown","source":"## test Categorical","metadata":{}},{"id":"e6726af9","cell_type":"code","source":"sm = nn.Softmax()\nlogit = torch.tensor((1.,2.))\na = Categorical(logits = logit)\nsampled = a.sample() # apply a softmax then sample from that distribution\nprint(a.log_prob(sampled)) # It will apply a softmax on the logit first, then a log over it\n# validate\nprint(np.log(sm(logit)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:58:44.369312Z","iopub.execute_input":"2025-04-16T22:58:44.369644Z","iopub.status.idle":"2025-04-16T22:58:44.526294Z","shell.execute_reply.started":"2025-04-16T22:58:44.369618Z","shell.execute_reply":"2025-04-16T22:58:44.525303Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"tensor(-1.3133)\ntensor([-1.3133, -0.3133])\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n","output_type":"stream"}],"execution_count":7},{"id":"39c8ffad","cell_type":"code","source":"a.entropy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:58:46.539164Z","iopub.execute_input":"2025-04-16T22:58:46.539448Z","iopub.status.idle":"2025-04-16T22:58:46.550652Z","shell.execute_reply.started":"2025-04-16T22:58:46.539428Z","shell.execute_reply":"2025-04-16T22:58:46.549871Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor(0.5822)"},"metadata":{}}],"execution_count":8},{"id":"fe0108ff","cell_type":"markdown","source":"## test model","metadata":{}},{"id":"c8e8d039","cell_type":"code","source":"model = ppo(n_player = 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:58:47.330032Z","iopub.execute_input":"2025-04-16T22:58:47.330344Z","iopub.status.idle":"2025-04-16T22:58:47.339317Z","shell.execute_reply.started":"2025-04-16T22:58:47.330320Z","shell.execute_reply":"2025-04-16T22:58:47.338194Z"}},"outputs":[],"execution_count":9},{"id":"f8a7ea59","cell_type":"code","source":"legal_move_mask = torch.tensor([False, True])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:58:47.673370Z","iopub.execute_input":"2025-04-16T22:58:47.673682Z","iopub.status.idle":"2025-04-16T22:58:47.678513Z","shell.execute_reply.started":"2025-04-16T22:58:47.673659Z","shell.execute_reply":"2025-04-16T22:58:47.677603Z"}},"outputs":[],"execution_count":10},{"id":"f3651e33","cell_type":"code","source":"x_test = torch.randn(model.input_dim)\nmasked_preoutput = model.policy(x_test).masked_fill(legal_move_mask, float('-inf'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:58:47.984379Z","iopub.execute_input":"2025-04-16T22:58:47.984678Z","iopub.status.idle":"2025-04-16T22:58:48.011127Z","shell.execute_reply.started":"2025-04-16T22:58:47.984657Z","shell.execute_reply":"2025-04-16T22:58:48.010037Z"}},"outputs":[],"execution_count":11},{"id":"c9efceaf","cell_type":"code","source":"sm = nn.Softmax(dim = 0)\nsm(masked_preoutput)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:58:49.660481Z","iopub.execute_input":"2025-04-16T22:58:49.660758Z","iopub.status.idle":"2025-04-16T22:58:49.667522Z","shell.execute_reply.started":"2025-04-16T22:58:49.660739Z","shell.execute_reply":"2025-04-16T22:58:49.666865Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor([1., 0.], grad_fn=<SoftmaxBackward0>)"},"metadata":{}}],"execution_count":12},{"id":"db1da695-16d2-495a-90ab-c2e793f4edff","cell_type":"code","source":"a = [1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:37:34.540359Z","iopub.execute_input":"2025-04-17T04:37:34.540899Z","iopub.status.idle":"2025-04-17T04:37:34.544081Z","shell.execute_reply.started":"2025-04-17T04:37:34.540879Z","shell.execute_reply":"2025-04-17T04:37:34.543510Z"}},"outputs":[],"execution_count":149},{"id":"46e5afa5-810b-4efc-a406-96969e94e4ef","cell_type":"code","source":"if len(a):\n    print('ye')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:37:34.810054Z","iopub.execute_input":"2025-04-17T04:37:34.810736Z","iopub.status.idle":"2025-04-17T04:37:34.814365Z","shell.execute_reply.started":"2025-04-17T04:37:34.810714Z","shell.execute_reply":"2025-04-17T04:37:34.813662Z"}},"outputs":[{"name":"stdout","text":"ye\n","output_type":"stream"}],"execution_count":150},{"id":"d1257888","cell_type":"markdown","source":"# Rollout","metadata":{}},{"id":"22836843","cell_type":"code","source":"class nothanks_ppo(game):\n    def __init__(self, card = None):\n        super().__init__(card)\n        self.move_encode = {0: 'pass',\n                            1: 'take'\n                            }\n        \n    def rotate_player(self, turn):\n        player_list = list(range(self.n_player))\n        return player_list[turn:] + player_list[:turn]\n        \n        \n    def get_state(self):\n        # Get info about the state to save it\n        player_info = []\n        player_list = self.rotate_player(self.turn)\n        for player in self.players:\n            player_info.append((player.card, player.chip))\n        return player_info, self.turn, self.remain_card, self.chip_in_pot, self.current_card\n    \n    def encode_card(self, card_list: list) -> list:\n        \"\"\"Encode the card list to binaries\"\"\"\n        encode = [0]* len(self.full_deck)\n        for card in card_list:\n            encode[card - self.min_card] = 1\n        return encode\n    \n    # def encode_turn(self, turn) -> list:\n    #     return [1 if i == turn else 0 for i in range(self.n_player)]\n\n    def check_favorable_self(self):\n        player_tmp = self.players[self.turn]\n        if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n            return 1\n        else:\n            return 0\n\n    def check_favorable_other(self):\n        other_player = [player_tmp for index, player_tmp in enumerate(self.players) if index != self.turn]\n        check = []\n        for player_tmp in other_player:\n            if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n                check.append(1)\n            else:\n                check.append(0)\n        return max(check)\n        \n    \n    def encode_state(self):\n        \"\"\"Feature engineering here\"\"\"\n        player_info, turn, remain_card, chip_in_pot, current_card = self.get_state()\n        result = []\n        for player_card, chip in player_info:\n            chip_tmp = chip/max(self.full_deck)\n            card_tmp = self.encode_card(player_card)\n            \n            result.extend(card_tmp)\n            result.append(chip_tmp)\n        \n        # result.extend(self.encode_turn(self.turn))\n        result.extend(self.encode_card([current_card]))\n        result.append(chip_in_pot/max(self.full_deck))\n        result.extend(self.encode_card(remain_card))\n        result.append((len(self.remain_card) - self.n_remove_card)/(len(self.full_deck) - self.n_remove_card))\n        result.append(self.check_favorable_self())\n\n        #new\n        result.append(self.check_favorable_other())\n        result.append(chip_in_pot/self.current_card)\n        # player_a, chip_a, ..., player_n, chip_n, turn, current_card, chip, remain_card, n_legal_remain_card, good card self, good card opponent, chip_in_pot/current_card\n        return result\n\n    def calculate_reward(self, action):\n        \"\"\"This puts too heavy penalty on taking\"\"\"\n        if action == 'pass':\n            return -1/self.n_chip*self.n_player\n        if action == 'take':\n            # FIX: could improve this part\n            # FIX: need to normalize the result: chip/total_chip + card_val (neg)/max_card_val (pos)\n            # Calculate difference between new score and old score\n            player = copy.deepcopy(self.players[self.turn])\n            old_score = player.calculate_score()\n            player.card.append(self.current_card)\n            new_score = player.calculate_score()\n            score_diff = new_score - old_score\n            chip_contr = self.chip_in_pot\n            card_contr = score_diff - chip_contr\n            # FIX: check if this make sense\n            return card_contr/self.max_card + chip_contr/(self.n_chip * self.n_player)\n    \n    def calculate_reward_1(self, action):\n        \"\"\"This encourage taking no matter what\"\"\"\n        if action == 'pass':\n            return -1\n        if action == 'take':\n            if self.chip_in_pot >= self.current_card//2:\n                return 1\n            return 0\n    \n    def calculate_reward_2(self, action):\n        player_tmp = self.players[self.turn]\n        \n        if action == 'pass':\n            # pass over half of the card value and the card is favorable is bad, punish for being too greedy\n            if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n                if self.chip_in_pot >= self.current_card//2:\n                    return -3\n            return -0.2  # light discouragement to avoid infinite pass\n    \n        if action == 'take':\n            \n            # Penalize taking too late or too early\n            if player_tmp.chip == 0:\n                return -2\n            if self.chip_in_pot == 0:\n                return -2\n                \n            reward = 0\n\n            # Reward for taking early in the game\n            if self.chip_in_pot < self.current_card and len(player_tmp.card) < 4:\n                reward += (self.chip_in_pot / (self.current_card + 1)) * 3\n    \n            # Encourage sequential cards\n            if any(abs(self.current_card - card_tmp) <= 3 for card_tmp in player_tmp.card):\n                reward += 2\n    \n            # Penalty for taking later in the game\n            distance_threshold = 4\n            if len(player_tmp.card) > 4:\n                dist = min(abs(self.current_card - c) for c in player_tmp.card)\n                if dist > distance_threshold:\n                    reward -= (dist - distance_threshold) * 0.5\n            return reward\n    \n    def calculate_reward_3(self, action):\n        return 0\n                \n    def reward_func(self, move):\n        return self.calculate_reward_3(move)\n                \n    def rollout(self, model, n_game = None):\n        \"\"\"Play games, save state\n        Need to get the turn\n        \"\"\"\n        random_chance = 0.99\n        # FIX: need to send 1 terminal state for each player:\n        playing_buffer = {i: [] for i in range(self.n_player)}\n        i = 0\n        while self.is_continue:\n            current_state = torch.tensor(self.encode_state()).to(device)\n            legal_move = self.get_legal_action() # a list \n            legal_move_mask = torch.tensor([False if move in legal_move else True for move in self.move_encode.values()]).to(device)\n            random_move = None\n            if random.random() > random_chance:\n                random_move = torch.tensor(random.choice([0 if move == 'pass' else 1 for move in legal_move])).to(device)\n            with torch.no_grad():\n                move_raw, log_prob, entropy, value = model.forward(current_state, legal_move_mask, random_move)\n            move = self.move_encode.get(move_raw.item())\n            reward = torch.tensor([self.reward_func(move)]).to(device)\n            playing_buffer[self.turn].append([current_state, move_raw, legal_move_mask, log_prob, value, reward]) # if this change, need to change the hard code\n            # move\n            self.is_continue = self.action(move)\n        final_reward = self.calculate_ranking()\n\n        for player in range(self.n_player):\n            playing_buffer[player].append([None, None, None, None, None, final_reward[player]])  # if this change, need to change the hard code\n            # playing_buffer[player].append([None, None, None, None, None, -self.players[player].calculate_score() ])  # if this change, need to change the hard code\n        return playing_buffer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:03:29.964095Z","iopub.execute_input":"2025-04-18T17:03:29.964672Z","iopub.status.idle":"2025-04-18T17:03:29.982680Z","shell.execute_reply.started":"2025-04-18T17:03:29.964649Z","shell.execute_reply":"2025-04-18T17:03:29.982137Z"}},"outputs":[],"execution_count":88},{"id":"38920749","cell_type":"code","source":"model = ppo(3).to(device)\nnothanks = nothanks_ppo()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:19.423684Z","iopub.execute_input":"2025-04-18T15:58:19.424276Z","iopub.status.idle":"2025-04-18T15:58:19.649977Z","shell.execute_reply.started":"2025-04-18T15:58:19.424254Z","shell.execute_reply":"2025-04-18T15:58:19.649437Z"}},"outputs":[],"execution_count":8},{"id":"95f50815","cell_type":"code","source":"# test encode state\nstate = nothanks.encode_state()\nprint(len(state) == model.input_dim)\nlegal_move_mask = torch.tensor([False, True]).to(device)\nstate_2 = torch.tensor(state).to(device)\nmove, _, _, _ = model.forward(state_2, legal_move_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:20.139151Z","iopub.execute_input":"2025-04-18T15:58:20.139373Z","iopub.status.idle":"2025-04-18T15:58:20.813693Z","shell.execute_reply.started":"2025-04-18T15:58:20.139357Z","shell.execute_reply":"2025-04-18T15:58:20.813142Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":9},{"id":"f6c0331f","cell_type":"code","source":"nothanks = nothanks_ppo()\nplay_buffer = nothanks.rollout(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T23:13:03.185173Z","iopub.execute_input":"2025-04-17T23:13:03.185440Z","iopub.status.idle":"2025-04-17T23:13:03.322680Z","shell.execute_reply.started":"2025-04-17T23:13:03.185419Z","shell.execute_reply":"2025-04-17T23:13:03.322159Z"}},"outputs":[],"execution_count":266},{"id":"dc4aaa9f-8e88-470d-9b40-19840058aead","cell_type":"code","source":"play_buffer[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T23:13:20.077318Z","iopub.execute_input":"2025-04-17T23:13:20.077871Z","iopub.status.idle":"2025-04-17T23:13:20.195775Z","shell.execute_reply.started":"2025-04-17T23:13:20.077847Z","shell.execute_reply":"2025-04-17T23:13:20.195049Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":268,"output_type":"execute_result","data":{"text/plain":"[[tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3143, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.3143, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.3143, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 0.9583], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1914, device='cuda:0'),\n  tensor([-1.5775], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2857, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.3143, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.2857, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 0.0000, 0.0000, 0.0571, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.9167], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2548, device='cuda:0'),\n  tensor([-1.2751], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2571, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.2857, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3714, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0286, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.8750], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-1.6488, device='cuda:0'),\n  tensor([-0.7186], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2857, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.2857, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3714, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.8333], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1859, device='cuda:0'),\n  tensor([-0.8081], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2571, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.2571, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3429, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0857, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.8333], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1983, device='cuda:0'),\n  tensor([-0.8653], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2286, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.2286, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3143, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.1714, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.8333], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2117, device='cuda:0'),\n  tensor([-0.9226], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.2857, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.2571, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.8333], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2262, device='cuda:0'),\n  tensor([-0.9799], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1714, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1714, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.2571, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.3429, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.8333], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2418, device='cuda:0'),\n  tensor([-1.0370], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.6286, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0286, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.7500], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-1.3894, device='cuda:0'),\n  tensor([-1.1180], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1714, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.6286, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.7083], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1561, device='cuda:0'),\n  tensor([-0.4616], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.6000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0571, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.6667], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1738, device='cuda:0'),\n  tensor([-0.0479], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1143, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1143, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.6857, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0286, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.6250], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1481, device='cuda:0'),\n  tensor([-0.5555], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0857, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0857, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.6571, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.1143, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.6250], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1575, device='cuda:0'),\n  tensor([-0.6137], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0571, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.6286, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0571, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.5833], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1456, device='cuda:0'),\n  tensor([0.2357], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0286, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1714, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.6000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.1429, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.5833], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1547, device='cuda:0'),\n  tensor([0.2141], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.5714, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.2286, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.5833], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([ True, False], device='cuda:0'),\n  tensor(0., device='cuda:0'),\n  tensor([0.1906], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2286, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.5714, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.5417], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1807, device='cuda:0'),\n  tensor([0.1622], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1143, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.6000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0286, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.5000], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1886, device='cuda:0'),\n  tensor([-0.1753], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1714, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.5714, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0571, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.4583], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1313, device='cuda:0'),\n  tensor([0.1776], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1143, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.5429, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.1429, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.4583], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-2.0400, device='cuda:0'),\n  tensor([0.1516], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2857, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1143, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.5429, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.4167], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1958, device='cuda:0'),\n  tensor([0.2726], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2571, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0857, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.5143, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0857, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.4167], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-1.6684, device='cuda:0'),\n  tensor([0.2745], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3429, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0857, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.5143, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.3750], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1677, device='cuda:0'),\n  tensor([0.0346], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3143, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0571, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.4857, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0857, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.3750], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1785, device='cuda:0'),\n  tensor([-0.0014], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2857, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0286, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.4571, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.1714, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.3750], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.1901, device='cuda:0'),\n  tensor([-0.0396], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2571, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.4286, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.2571, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.3750], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2027, device='cuda:0'),\n  tensor([-0.0802], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2286, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2571, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.4286, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0286, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.2917], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2112, device='cuda:0'),\n  tensor([0.4253], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2286, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.4000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.1143, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.2917], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-1.6005, device='cuda:0'),\n  tensor([0.4210], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3143, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2286, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.4000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.2500], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-1.1831, device='cuda:0'),\n  tensor([0.1925], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3143, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2286, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.4000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.2083], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2432, device='cuda:0'),\n  tensor([-0.0917], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2857, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3714, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0857, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          1.0000, 0.2083], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-1.4754, device='cuda:0'),\n  tensor([-0.0986], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3714, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3714, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.1667], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-1.9723, device='cuda:0'),\n  tensor([-0.6579], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3714, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3714, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.1250], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.4554, device='cuda:0'),\n  tensor([-2.2637], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3429, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.1714, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3429, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0857, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.1250], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.4855, device='cuda:0'),\n  tensor([-2.2770], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3143, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2571, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3143, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0571, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0417], device='cuda:0'),\n  tensor(1, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-1.5062, device='cuda:0'),\n  tensor([-2.2146], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3714, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2571, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.3143, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2071, device='cuda:0'),\n  tensor([-2.3673], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3429, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.2286, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.2857, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0857, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n          0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n          0.0000, 0.0000], device='cuda:0'),\n  tensor(0, device='cuda:0'),\n  tensor([False, False], device='cuda:0'),\n  tensor(-0.2209, device='cuda:0'),\n  tensor([-2.3737], device='cuda:0'),\n  tensor([0], device='cuda:0')],\n [None, None, None, None, None, -20.0]]"},"metadata":{}}],"execution_count":268},{"id":"80bf9b07","cell_type":"markdown","source":"# Calculate targets & create training data","metadata":{}},{"id":"837ddf21","cell_type":"code","source":"# FIX: need to detach at some point, only leave the new pi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:58:54.228242Z","iopub.execute_input":"2025-04-16T22:58:54.228571Z","iopub.status.idle":"2025-04-16T22:58:54.233468Z","shell.execute_reply.started":"2025-04-16T22:58:54.228548Z","shell.execute_reply":"2025-04-16T22:58:54.232090Z"}},"outputs":[],"execution_count":17},{"id":"f4e455da","cell_type":"code","source":"# reward_target = []\n# advantage_target = []\n# policy_old = []\n\ndef create_training_data(play_buffer, gamma = 0.99, reward_index = -1):\n    \"\"\"\n    gamma: discount constant\n    reward_index: index of reward returned in the play buffer\n    \"\"\"\n    training_data = []\n    for _, player_data in play_buffer.items():\n        discounted_reward = player_data[-1][reward_index] # take the reward of the last stage. At the end of the game, all players receive 1 more step containing the final reward (final rank)\n        for index in reversed(range(len(player_data) - 1)): # go from back to front, skip the final step\n\n            state_tmp, move_tmp, legal_move_mask, log_prob_tmp, value_tmp, reward_tmp = player_data[index]\n            discounted_reward = reward_tmp + discounted_reward*gamma\n            # discounted reward\n            # reward_target = [discounted_reward] + reward_target\n\n            #advantage\n            advantage_tmp = discounted_reward - value_tmp\n            # advantage_target = [advantage_tmp] + advantage_target # need to detach this at policy loss\n\n            # policy_old = [policy_tmp] + policy_old # need to detach this at policy loss\n            training_data.append([state_tmp, move_tmp, legal_move_mask, log_prob_tmp, advantage_tmp, discounted_reward]) #state, action, sampled action, advantage, discounted_reward (aka return)\n    return training_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:53.647639Z","iopub.execute_input":"2025-04-18T15:58:53.647912Z","iopub.status.idle":"2025-04-18T15:58:53.652835Z","shell.execute_reply.started":"2025-04-18T15:58:53.647893Z","shell.execute_reply":"2025-04-18T15:58:53.652299Z"}},"outputs":[],"execution_count":11},{"id":"fd88fcc0","cell_type":"code","source":"training_data = create_training_data(play_buffer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T21:41:50.704454Z","iopub.execute_input":"2025-04-17T21:41:50.704969Z","iopub.status.idle":"2025-04-17T21:41:50.729400Z","shell.execute_reply.started":"2025-04-17T21:41:50.704948Z","shell.execute_reply":"2025-04-17T21:41:50.728715Z"}},"outputs":[],"execution_count":196},{"id":"f50dcbcd","cell_type":"code","source":"n_game = 5\ntraining_data = []\ntorch.manual_seed(1)\nmodel = ppo(3).to(device)\n\nfor _ in range(n_game):\n    nothanks = nothanks_ppo()\n    play_buffer = nothanks.rollout(model)\n    training_data_tmp = create_training_data(play_buffer)\n    training_data.extend(training_data_tmp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T21:42:09.024091Z","iopub.execute_input":"2025-04-17T21:42:09.024374Z","iopub.status.idle":"2025-04-17T21:42:09.380059Z","shell.execute_reply.started":"2025-04-17T21:42:09.024354Z","shell.execute_reply":"2025-04-17T21:42:09.379361Z"}},"outputs":[],"execution_count":199},{"id":"f414f9e5","cell_type":"code","source":"# TEST: the order is right?\n# need to check the training data for order of the samples. Especially the part where you go backward","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:58:57.794129Z","iopub.execute_input":"2025-04-16T22:58:57.794462Z","iopub.status.idle":"2025-04-16T22:58:57.799117Z","shell.execute_reply.started":"2025-04-16T22:58:57.794437Z","shell.execute_reply":"2025-04-16T22:58:57.797860Z"}},"outputs":[],"execution_count":21},{"id":"e09062f4","cell_type":"markdown","source":"# Data loader","metadata":{}},{"id":"11afd372","cell_type":"code","source":"class dataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        return self.data[index]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:55.798285Z","iopub.execute_input":"2025-04-18T15:58:55.798815Z","iopub.status.idle":"2025-04-18T15:58:55.802701Z","shell.execute_reply.started":"2025-04-18T15:58:55.798795Z","shell.execute_reply":"2025-04-18T15:58:55.802077Z"}},"outputs":[],"execution_count":12},{"id":"b299655d","cell_type":"code","source":"def collate_fn(batch_data):\n    result = []\n    for item in zip(*batch_data):\n        result.append(torch.stack(item).unsqueeze(dim = 1)) # add 1 more dimension for batch\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:55.948688Z","iopub.execute_input":"2025-04-18T15:58:55.949154Z","iopub.status.idle":"2025-04-18T15:58:55.952839Z","shell.execute_reply.started":"2025-04-18T15:58:55.949135Z","shell.execute_reply":"2025-04-18T15:58:55.952066Z"}},"outputs":[],"execution_count":13},{"id":"731b7a50","cell_type":"code","source":"params = {'batch_size': 2,\n          'shuffle': True,\n          'collate_fn': collate_fn\n          }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:58:56.204212Z","iopub.execute_input":"2025-04-18T15:58:56.204651Z","iopub.status.idle":"2025-04-18T15:58:56.207668Z","shell.execute_reply.started":"2025-04-18T15:58:56.204635Z","shell.execute_reply":"2025-04-18T15:58:56.207136Z"}},"outputs":[],"execution_count":14},{"id":"7e0f96c6","cell_type":"code","source":"train_data = dataset(training_data)\ndataloader = DataLoader(train_data, **params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T20:47:47.702174Z","iopub.execute_input":"2025-04-17T20:47:47.702644Z","iopub.status.idle":"2025-04-17T20:47:47.705824Z","shell.execute_reply.started":"2025-04-17T20:47:47.702626Z","shell.execute_reply":"2025-04-17T20:47:47.705135Z"}},"outputs":[],"execution_count":142},{"id":"78850407","cell_type":"markdown","source":"## Test batch","metadata":{}},{"id":"6399cfa7","cell_type":"code","source":"a = iter(dataloader)\nx = next(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:12:26.627228Z","iopub.execute_input":"2025-04-17T03:12:26.627794Z","iopub.status.idle":"2025-04-17T03:12:26.676838Z","shell.execute_reply.started":"2025-04-17T03:12:26.627768Z","shell.execute_reply":"2025-04-17T03:12:26.676277Z"}},"outputs":[],"execution_count":29},{"id":"23fb7b84","cell_type":"code","source":"state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:12:26.850508Z","iopub.execute_input":"2025-04-17T03:12:26.851105Z","iopub.status.idle":"2025-04-17T03:12:26.854582Z","shell.execute_reply.started":"2025-04-17T03:12:26.851084Z","shell.execute_reply":"2025-04-17T03:12:26.853866Z"}},"outputs":[],"execution_count":30},{"id":"59a0f55f","cell_type":"code","source":"print(state_tmp.shape)\nprint(move_tmp.shape)\nprint(legal_move_mask.shape)\nprint(discounted_reward.shape)\nprint(log_prob_old.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:12:27.735512Z","iopub.execute_input":"2025-04-17T03:12:27.736093Z","iopub.status.idle":"2025-04-17T03:12:27.740085Z","shell.execute_reply.started":"2025-04-17T03:12:27.736071Z","shell.execute_reply":"2025-04-17T03:12:27.739406Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 1, 172])\ntorch.Size([32, 1])\ntorch.Size([32, 1, 2])\ntorch.Size([32, 1, 1])\ntorch.Size([32, 1])\n","output_type":"stream"}],"execution_count":31},{"id":"5e2508df","cell_type":"code","source":"discounted_reward\nlegal_move_mask[0][0][0] = True\nlegal_move_mask\nmodel.policy(state_tmp)\n\n# .masked_fill(legal_move_mask, 4)\nmove, log_prob, entropy, value = model.forward(state_tmp, legal_move_mask)\nvalue\ndiscounted_reward\n((value - discounted_reward)**2).mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:59:04.509835Z","iopub.execute_input":"2025-04-16T22:59:04.510635Z","iopub.status.idle":"2025-04-16T22:59:04.529833Z","shell.execute_reply.started":"2025-04-16T22:59:04.510610Z","shell.execute_reply":"2025-04-16T22:59:04.528909Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"tensor(10.5459, grad_fn=<MeanBackward0>)"},"metadata":{}}],"execution_count":30},{"id":"97462921","cell_type":"markdown","source":"# Loss function","metadata":{}},{"id":"0c402f57","cell_type":"code","source":"# policy loss\n# clipped surrogate loss\na = torch.tensor(5)\ntorch.clamp(a, -1, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:59:07.574444Z","iopub.execute_input":"2025-04-16T22:59:07.574782Z","iopub.status.idle":"2025-04-16T22:59:07.582377Z","shell.execute_reply.started":"2025-04-16T22:59:07.574711Z","shell.execute_reply":"2025-04-16T22:59:07.581698Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"tensor(1)"},"metadata":{}}],"execution_count":31},{"id":"1cb9da1b","cell_type":"code","source":"lr = 5e-4\noptimizer = Adam(model.parameters(), lr = lr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T12:36:06.218509Z","iopub.execute_input":"2025-04-17T12:36:06.218769Z","iopub.status.idle":"2025-04-17T12:36:06.223796Z","shell.execute_reply.started":"2025-04-17T12:36:06.218748Z","shell.execute_reply":"2025-04-17T12:36:06.222990Z"}},"outputs":[],"execution_count":19},{"id":"6b45329f-db38-4e7f-b42a-e68d8b0f6832","cell_type":"code","source":"model = ppo(N_PLAYER).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T20:47:25.956145Z","iopub.execute_input":"2025-04-17T20:47:25.956396Z","iopub.status.idle":"2025-04-17T20:47:25.961760Z","shell.execute_reply.started":"2025-04-17T20:47:25.956378Z","shell.execute_reply":"2025-04-17T20:47:25.961269Z"}},"outputs":[],"execution_count":139},{"id":"5f21120e","cell_type":"code","source":"# calculate the new policy?\n# FOR BATCH PLAY\n\n# FIX: WATCH WHICH ONE IS DETACHED\n\nN_EPOCH = 1\ne = 0.2 #clipping constant\nvalue_coef = 0.5\nentropy_coef = 0.01\nfor epoch in range(N_EPOCH):\n    loss_record = 0\n    for index, (state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward) in enumerate(dataloader):\n        optimizer.zero_grad()\n        _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n                                                legal_move_mask= legal_move_mask,\n                                                action = move_tmp)\n        # policy loss\n        # advantage_norm_tmp = advantage_tmp.detach()\n        advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/advantage_tmp.std()\n        # print(advantage_norm_tmp.shape)\n        ratio = torch.exp(log_prob_new - log_prob_old).unsqueeze(dim = 1) # pi_new/pi_old\n        surrogate_1 = ratio*advantage_norm_tmp\n        ratio_clamp = torch.clamp(ratio, 1 - e, 1 + e) # clipped ratio\n        surrogate_2 = ratio_clamp*advantage_norm_tmp\n        policy_loss = -torch.min(surrogate_1, surrogate_2).mean() #FIX: is this adv detached? yes\n\n        print(advantage_norm_tmp, log_prob_old, log_prob_new)\n        \n        # value loss\n        value_loss = ((value_new - discounted_reward)**2).mean()\n\n        # entropy loss: to encourage exploration\n        entropy_loss = entropy.mean()\n\n        loss = policy_loss + value_coef * value_loss - entropy_coef * entropy_loss\n        loss_record += loss.item()\n        \n        break\n    #     loss.backward()\n    #     nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.5) # FIX: check this\n    #     optimizer.step()\n\n    # print(f'Epoch: {epoch} - loss: {round(loss_record/index,2)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T20:47:49.334767Z","iopub.execute_input":"2025-04-17T20:47:49.335396Z","iopub.status.idle":"2025-04-17T20:47:49.348054Z","shell.execute_reply.started":"2025-04-17T20:47:49.335375Z","shell.execute_reply":"2025-04-17T20:47:49.347524Z"}},"outputs":[{"name":"stdout","text":"tensor([[[ 0.7071]],\n\n        [[-0.7071]]], device='cuda:0') tensor([[-2.9280],\n        [-0.1518]], device='cuda:0') tensor([[-0.6770],\n        [-0.6955]], device='cuda:0', grad_fn=<SqueezeBackward1>)\n","output_type":"stream"}],"execution_count":143},{"id":"8d14dede","cell_type":"markdown","source":"# Training","metadata":{}},{"id":"c1b65913","cell_type":"code","source":"BATCH_SIZE = 64\nLEARNING_RATE = 5e-4\nN_PLAYER = 3\nDATA_LENGTH = 5000\nN_CYCLE = 100\nN_EPOCH = 4\ne = 0.2 #clipping constant\nvalue_coef = 0.6\nentropy_coef = 0.01\n\nmodel = ppo(N_PLAYER).to(device)\n# model.load_state_dict(torch.load('/kaggle/working/model_new_arc_default_rwd_71_iter.pth'))\n\noptimizer = Adam(model.parameters(), lr = LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:03:39.613601Z","iopub.execute_input":"2025-04-18T17:03:39.613850Z","iopub.status.idle":"2025-04-18T17:03:39.622185Z","shell.execute_reply.started":"2025-04-18T17:03:39.613831Z","shell.execute_reply":"2025-04-18T17:03:39.621497Z"}},"outputs":[],"execution_count":89},{"id":"0f1f115b-092d-4c1d-9d68-b3adf6c29654","cell_type":"code","source":"dataloader_params = {'batch_size': BATCH_SIZE,\n          'shuffle': True,\n          'drop_last': True, # drop the last batch where the size could be 1\n          'collate_fn': collate_fn\n          }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:03:40.021590Z","iopub.execute_input":"2025-04-18T17:03:40.022017Z","iopub.status.idle":"2025-04-18T17:03:40.025408Z","shell.execute_reply.started":"2025-04-18T17:03:40.021998Z","shell.execute_reply":"2025-04-18T17:03:40.024774Z"}},"outputs":[],"execution_count":90},{"id":"e0bb4c8d-8159-4073-b1aa-46d9b022bc69","cell_type":"code","source":"loss_list = []\ngame_length_list = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:03:41.012794Z","iopub.execute_input":"2025-04-18T17:03:41.013080Z","iopub.status.idle":"2025-04-18T17:03:41.017379Z","shell.execute_reply.started":"2025-04-18T17:03:41.013055Z","shell.execute_reply":"2025-04-18T17:03:41.016273Z"}},"outputs":[],"execution_count":91},{"id":"21f8f888","cell_type":"code","source":"train_flag = 1\n\nfor cycle in range(N_CYCLE):\n    print(f'-------------CYCLE: {cycle}-------------')\n\n    # Rollout\n    training_data = []\n    game_length = []\n    while len(training_data) <= DATA_LENGTH:\n        nothanks = nothanks_ppo()\n        play_buffer = nothanks.rollout(model)\n        training_data_tmp = create_training_data(play_buffer)\n        game_length.append(len(training_data_tmp))\n        training_data.extend(training_data_tmp)\n    print(f'game length: {round(np.mean(game_length),0)}')\n    game_length_list.append(round(np.mean(game_length),0))\n    \n    # train_flag = int(input('Continue training?: 0.no | 1. yes'))\n    if train_flag:\n        # create a new data loader\n        train_data = dataset(training_data)\n        dataloader = DataLoader(train_data, **dataloader_params)\n        \n        # Train\n        for epoch in range(N_EPOCH):\n            loss_record = 0\n            for index, (state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward) in enumerate(dataloader):\n                optimizer.zero_grad()\n                _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n                                                        legal_move_mask= legal_move_mask,\n                                                        action = move_tmp)\n                # policy loss\n                # advantage_norm_tmp = advantage_tmp.detach()\n                # advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/(advantage_tmp.std() + 1e-8)\n                # print(advantage_norm_tmp.shape)\n                ratio = torch.exp(log_prob_new - log_prob_old).unsqueeze(dim = 1) # pi_new/pi_old\n                surrogate_1 = ratio*advantage_tmp\n                ratio_clamp = torch.clamp(ratio, 1 - e, 1 + e) # clipped ratio\n                surrogate_2 = ratio_clamp*advantage_tmp\n                policy_loss = -torch.min(surrogate_1, surrogate_2).mean() #FIX: is this adv detached? yes\n\n                # value loss\n                value_loss = ((value_new - discounted_reward)**2).mean()\n\n                # entropy loss: to encourage exploration\n                entropy_loss = entropy.mean()\n\n                loss = policy_loss + value_coef * value_loss - entropy_coef * entropy_loss\n                loss_record += loss.item()\n                loss.backward()\n                nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.5) # FIX: check this\n                optimizer.step()\n    \n            print(f'Epoch: {epoch} - loss: {round(loss_record/index,2)}')\n            loss_list.append(loss_record//index)\n        torch.save(model.state_dict(), './model_state_tmp.pth')\n    if cycle % 10 == 0:\n        torch.save(model.state_dict(), f'./model_gen_3_default_rwd_{cycle}_iter.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:03:51.367646Z","iopub.execute_input":"2025-04-18T17:03:51.368193Z","iopub.status.idle":"2025-04-18T17:14:58.356660Z","shell.execute_reply.started":"2025-04-18T17:03:51.368169Z","shell.execute_reply":"2025-04-18T17:14:58.355683Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"-------------CYCLE: 0-------------\ngame length: 49.0\nEpoch: 0 - loss: 135.63\nEpoch: 1 - loss: 134.24\nEpoch: 2 - loss: 133.59\nEpoch: 3 - loss: 132.49\n-------------CYCLE: 1-------------\ngame length: 61.0\nEpoch: 0 - loss: 129.05\nEpoch: 1 - loss: 127.79\nEpoch: 2 - loss: 127.31\nEpoch: 3 - loss: 126.51\n-------------CYCLE: 2-------------\ngame length: 73.0\nEpoch: 0 - loss: 125.91\nEpoch: 1 - loss: 124.91\nEpoch: 2 - loss: 124.06\nEpoch: 3 - loss: 123.17\n-------------CYCLE: 3-------------\ngame length: 83.0\nEpoch: 0 - loss: 121.56\nEpoch: 1 - loss: 120.47\nEpoch: 2 - loss: 119.84\nEpoch: 3 - loss: 118.33\n-------------CYCLE: 4-------------\ngame length: 85.0\nEpoch: 0 - loss: 121.09\nEpoch: 1 - loss: 119.74\nEpoch: 2 - loss: 118.72\nEpoch: 3 - loss: 117.76\n-------------CYCLE: 5-------------\ngame length: 95.0\nEpoch: 0 - loss: 118.24\nEpoch: 1 - loss: 116.66\nEpoch: 2 - loss: 116.25\nEpoch: 3 - loss: 115.24\n-------------CYCLE: 6-------------\ngame length: 107.0\nEpoch: 0 - loss: 112.52\nEpoch: 1 - loss: 110.12\nEpoch: 2 - loss: 108.68\nEpoch: 3 - loss: 107.52\n-------------CYCLE: 7-------------\ngame length: 107.0\nEpoch: 0 - loss: 113.22\nEpoch: 1 - loss: 110.69\nEpoch: 2 - loss: 108.75\nEpoch: 3 - loss: 107.46\n-------------CYCLE: 8-------------\ngame length: 111.0\nEpoch: 0 - loss: 111.96\nEpoch: 1 - loss: 108.85\nEpoch: 2 - loss: 107.1\nEpoch: 3 - loss: 105.53\n-------------CYCLE: 9-------------\ngame length: 110.0\nEpoch: 0 - loss: 112.91\nEpoch: 1 - loss: 109.82\nEpoch: 2 - loss: 107.86\nEpoch: 3 - loss: 106.82\n-------------CYCLE: 10-------------\ngame length: 115.0\nEpoch: 0 - loss: 110.09\nEpoch: 1 - loss: 106.58\nEpoch: 2 - loss: 103.77\nEpoch: 3 - loss: 101.98\n-------------CYCLE: 11-------------\ngame length: 116.0\nEpoch: 0 - loss: 111.61\nEpoch: 1 - loss: 108.75\nEpoch: 2 - loss: 107.13\nEpoch: 3 - loss: 105.7\n-------------CYCLE: 12-------------\ngame length: 116.0\nEpoch: 0 - loss: 110.0\nEpoch: 1 - loss: 107.48\nEpoch: 2 - loss: 105.71\nEpoch: 3 - loss: 104.27\n-------------CYCLE: 13-------------\ngame length: 122.0\nEpoch: 0 - loss: 109.63\nEpoch: 1 - loss: 106.28\nEpoch: 2 - loss: 105.04\nEpoch: 3 - loss: 102.97\n-------------CYCLE: 14-------------\ngame length: 124.0\nEpoch: 0 - loss: 108.2\nEpoch: 1 - loss: 104.55\nEpoch: 2 - loss: 101.86\nEpoch: 3 - loss: 99.66\n-------------CYCLE: 15-------------\ngame length: 113.0\nEpoch: 0 - loss: 111.05\nEpoch: 1 - loss: 106.97\nEpoch: 2 - loss: 104.75\nEpoch: 3 - loss: 103.33\n-------------CYCLE: 16-------------\ngame length: 113.0\nEpoch: 0 - loss: 110.33\nEpoch: 1 - loss: 106.98\nEpoch: 2 - loss: 105.11\nEpoch: 3 - loss: 103.4\n-------------CYCLE: 17-------------\ngame length: 126.0\nEpoch: 0 - loss: 106.74\nEpoch: 1 - loss: 102.26\nEpoch: 2 - loss: 100.34\nEpoch: 3 - loss: 98.76\n-------------CYCLE: 18-------------\ngame length: 125.0\nEpoch: 0 - loss: 106.37\nEpoch: 1 - loss: 102.7\nEpoch: 2 - loss: 100.17\nEpoch: 3 - loss: 98.36\n-------------CYCLE: 19-------------\ngame length: 118.0\nEpoch: 0 - loss: 111.09\nEpoch: 1 - loss: 105.79\nEpoch: 2 - loss: 103.56\nEpoch: 3 - loss: 101.87\n-------------CYCLE: 20-------------\ngame length: 122.0\nEpoch: 0 - loss: 108.59\nEpoch: 1 - loss: 103.69\nEpoch: 2 - loss: 101.04\nEpoch: 3 - loss: 99.02\n-------------CYCLE: 21-------------\ngame length: 119.0\nEpoch: 0 - loss: 109.07\nEpoch: 1 - loss: 103.83\nEpoch: 2 - loss: 101.47\nEpoch: 3 - loss: 99.95\n-------------CYCLE: 22-------------\ngame length: 112.0\nEpoch: 0 - loss: 113.19\nEpoch: 1 - loss: 107.72\nEpoch: 2 - loss: 104.63\nEpoch: 3 - loss: 101.92\n-------------CYCLE: 23-------------\ngame length: 114.0\nEpoch: 0 - loss: 111.59\nEpoch: 1 - loss: 104.95\nEpoch: 2 - loss: 101.85\nEpoch: 3 - loss: 99.54\n-------------CYCLE: 24-------------\ngame length: 104.0\nEpoch: 0 - loss: 116.25\nEpoch: 1 - loss: 109.55\nEpoch: 2 - loss: 106.45\nEpoch: 3 - loss: 103.62\n-------------CYCLE: 25-------------\ngame length: 104.0\nEpoch: 0 - loss: 114.53\nEpoch: 1 - loss: 109.32\nEpoch: 2 - loss: 106.16\nEpoch: 3 - loss: 103.77\n-------------CYCLE: 26-------------\ngame length: 102.0\nEpoch: 0 - loss: 114.39\nEpoch: 1 - loss: 108.05\nEpoch: 2 - loss: 105.09\nEpoch: 3 - loss: 102.97\n-------------CYCLE: 27-------------\ngame length: 107.0\nEpoch: 0 - loss: 114.27\nEpoch: 1 - loss: 107.56\nEpoch: 2 - loss: 104.22\nEpoch: 3 - loss: 102.08\n-------------CYCLE: 28-------------\ngame length: 115.0\nEpoch: 0 - loss: 111.22\nEpoch: 1 - loss: 104.59\nEpoch: 2 - loss: 101.04\nEpoch: 3 - loss: 98.81\n-------------CYCLE: 29-------------\ngame length: 115.0\nEpoch: 0 - loss: 110.93\nEpoch: 1 - loss: 104.25\nEpoch: 2 - loss: 101.22\nEpoch: 3 - loss: 98.42\n-------------CYCLE: 30-------------\ngame length: 121.0\nEpoch: 0 - loss: 105.37\nEpoch: 1 - loss: 99.91\nEpoch: 2 - loss: 96.82\nEpoch: 3 - loss: 94.27\n-------------CYCLE: 31-------------\ngame length: 121.0\nEpoch: 0 - loss: 109.99\nEpoch: 1 - loss: 103.25\nEpoch: 2 - loss: 99.48\nEpoch: 3 - loss: 96.11\n-------------CYCLE: 32-------------\ngame length: 128.0\nEpoch: 0 - loss: 106.76\nEpoch: 1 - loss: 99.81\nEpoch: 2 - loss: 96.13\nEpoch: 3 - loss: 93.39\n-------------CYCLE: 33-------------\ngame length: 115.0\nEpoch: 0 - loss: 110.95\nEpoch: 1 - loss: 105.04\nEpoch: 2 - loss: 101.51\nEpoch: 3 - loss: 99.15\n-------------CYCLE: 34-------------\ngame length: 118.0\nEpoch: 0 - loss: 110.94\nEpoch: 1 - loss: 103.99\nEpoch: 2 - loss: 100.15\nEpoch: 3 - loss: 97.57\n-------------CYCLE: 35-------------\ngame length: 116.0\nEpoch: 0 - loss: 110.56\nEpoch: 1 - loss: 103.83\nEpoch: 2 - loss: 100.81\nEpoch: 3 - loss: 98.08\n-------------CYCLE: 36-------------\ngame length: 123.0\nEpoch: 0 - loss: 107.53\nEpoch: 1 - loss: 100.23\nEpoch: 2 - loss: 96.62\nEpoch: 3 - loss: 93.73\n-------------CYCLE: 37-------------\ngame length: 121.0\nEpoch: 0 - loss: 110.23\nEpoch: 1 - loss: 102.68\nEpoch: 2 - loss: 98.98\nEpoch: 3 - loss: 96.07\n-------------CYCLE: 38-------------\ngame length: 121.0\nEpoch: 0 - loss: 108.8\nEpoch: 1 - loss: 101.58\nEpoch: 2 - loss: 98.21\nEpoch: 3 - loss: 95.95\n-------------CYCLE: 39-------------\ngame length: 112.0\nEpoch: 0 - loss: 111.54\nEpoch: 1 - loss: 104.63\nEpoch: 2 - loss: 101.37\nEpoch: 3 - loss: 99.2\n-------------CYCLE: 40-------------\ngame length: 119.0\nEpoch: 0 - loss: 110.46\nEpoch: 1 - loss: 103.8\nEpoch: 2 - loss: 99.91\nEpoch: 3 - loss: 97.09\n-------------CYCLE: 41-------------\ngame length: 110.0\nEpoch: 0 - loss: 113.77\nEpoch: 1 - loss: 107.61\nEpoch: 2 - loss: 104.02\nEpoch: 3 - loss: 101.54\n-------------CYCLE: 42-------------\ngame length: 109.0\nEpoch: 0 - loss: 112.38\nEpoch: 1 - loss: 106.35\nEpoch: 2 - loss: 102.97\nEpoch: 3 - loss: 100.99\n-------------CYCLE: 43-------------\ngame length: 113.0\nEpoch: 0 - loss: 111.47\nEpoch: 1 - loss: 104.92\nEpoch: 2 - loss: 101.43\nEpoch: 3 - loss: 98.6\n-------------CYCLE: 44-------------\ngame length: 115.0\nEpoch: 0 - loss: 111.24\nEpoch: 1 - loss: 106.07\nEpoch: 2 - loss: 102.92\nEpoch: 3 - loss: 100.31\n-------------CYCLE: 45-------------\ngame length: 120.0\nEpoch: 0 - loss: 109.17\nEpoch: 1 - loss: 101.83\nEpoch: 2 - loss: 97.75\nEpoch: 3 - loss: 95.05\n-------------CYCLE: 46-------------\ngame length: 120.0\nEpoch: 0 - loss: 108.06\nEpoch: 1 - loss: 101.3\nEpoch: 2 - loss: 98.09\nEpoch: 3 - loss: 95.19\n-------------CYCLE: 47-------------\ngame length: 117.0\nEpoch: 0 - loss: 111.71\nEpoch: 1 - loss: 103.13\nEpoch: 2 - loss: 98.59\nEpoch: 3 - loss: 95.67\n-------------CYCLE: 48-------------\ngame length: 114.0\nEpoch: 0 - loss: 111.52\nEpoch: 1 - loss: 104.43\nEpoch: 2 - loss: 100.64\nEpoch: 3 - loss: 98.61\n-------------CYCLE: 49-------------\ngame length: 114.0\nEpoch: 0 - loss: 112.34\nEpoch: 1 - loss: 107.33\nEpoch: 2 - loss: 103.57\nEpoch: 3 - loss: 100.48\n-------------CYCLE: 50-------------\ngame length: 119.0\nEpoch: 0 - loss: 110.05\nEpoch: 1 - loss: 103.03\nEpoch: 2 - loss: 100.15\nEpoch: 3 - loss: 96.96\n-------------CYCLE: 51-------------\ngame length: 119.0\nEpoch: 0 - loss: 109.33\nEpoch: 1 - loss: 102.08\nEpoch: 2 - loss: 97.82\nEpoch: 3 - loss: 95.31\n-------------CYCLE: 52-------------\ngame length: 123.0\nEpoch: 0 - loss: 108.44\nEpoch: 1 - loss: 100.24\nEpoch: 2 - loss: 95.99\nEpoch: 3 - loss: 93.2\n-------------CYCLE: 53-------------\ngame length: 122.0\nEpoch: 0 - loss: 108.67\nEpoch: 1 - loss: 100.71\nEpoch: 2 - loss: 96.62\nEpoch: 3 - loss: 93.74\n-------------CYCLE: 54-------------\ngame length: 122.0\nEpoch: 0 - loss: 109.2\nEpoch: 1 - loss: 3312.71\nEpoch: 2 - loss: 96.95\nEpoch: 3 - loss: 93.19\n-------------CYCLE: 55-------------\ngame length: 123.0\nEpoch: 0 - loss: 109.3\nEpoch: 1 - loss: 101.45\nEpoch: 2 - loss: 97.61\nEpoch: 3 - loss: 94.84\n-------------CYCLE: 56-------------\ngame length: 112.0\nEpoch: 0 - loss: 112.2\nEpoch: 1 - loss: 104.67\nEpoch: 2 - loss: 99.22\nEpoch: 3 - loss: 96.37\n-------------CYCLE: 57-------------\ngame length: 117.0\nEpoch: 0 - loss: 111.47\nEpoch: 1 - loss: 125.65\nEpoch: 2 - loss: 98.97\nEpoch: 3 - loss: 95.97\n-------------CYCLE: 58-------------\ngame length: 112.0\nEpoch: 0 - loss: 112.61\nEpoch: 1 - loss: 104.15\nEpoch: 2 - loss: 99.74\nEpoch: 3 - loss: 97.18\n-------------CYCLE: 59-------------\ngame length: 129.0\nEpoch: 0 - loss: 111.41\nEpoch: 1 - loss: 96.0\nEpoch: 2 - loss: 91.08\nEpoch: 3 - loss: 88.53\n-------------CYCLE: 60-------------\ngame length: 122.0\nEpoch: 0 - loss: 109.19\nEpoch: 1 - loss: 100.82\nEpoch: 2 - loss: 96.41\nEpoch: 3 - loss: 93.47\n-------------CYCLE: 61-------------\ngame length: 119.0\nEpoch: 0 - loss: 109.42\nEpoch: 1 - loss: 98.67\nEpoch: 2 - loss: 94.79\nEpoch: 3 - loss: 91.41\n-------------CYCLE: 62-------------\ngame length: 122.0\nEpoch: 0 - loss: 107.53\nEpoch: 1 - loss: 98.01\nEpoch: 2 - loss: 94.3\nEpoch: 3 - loss: 91.64\n-------------CYCLE: 63-------------\ngame length: 128.0\nEpoch: 0 - loss: 105.72\nEpoch: 1 - loss: 99.56\nEpoch: 2 - loss: 92.95\nEpoch: 3 - loss: 89.95\n-------------CYCLE: 64-------------\ngame length: 127.0\nEpoch: 0 - loss: 106.23\nEpoch: 1 - loss: 109.65\nEpoch: 2 - loss: 91.45\nEpoch: 3 - loss: 88.35\n-------------CYCLE: 65-------------\ngame length: 123.0\nEpoch: 0 - loss: 109.43\nEpoch: 1 - loss: 99.51\nEpoch: 2 - loss: 94.7\nEpoch: 3 - loss: 91.26\n-------------CYCLE: 66-------------\ngame length: 127.0\nEpoch: 0 - loss: 106.54\nEpoch: 1 - loss: 95.97\nEpoch: 2 - loss: 124.88\nEpoch: 3 - loss: 89.15\n-------------CYCLE: 67-------------\ngame length: 128.0\nEpoch: 0 - loss: 106.08\nEpoch: 1 - loss: 5345950720407.61\nEpoch: 2 - loss: 93.02\nEpoch: 3 - loss: 89.85\n-------------CYCLE: 68-------------\ngame length: 130.0\nEpoch: 0 - loss: 355.25\nEpoch: 1 - loss: 94.8\nEpoch: 2 - loss: 90.53\nEpoch: 3 - loss: 88.12\n-------------CYCLE: 69-------------\ngame length: 130.0\nEpoch: 0 - loss: 106.59\nEpoch: 1 - loss: 501.6\nEpoch: 2 - loss: 91.68\nEpoch: 3 - loss: 89.97\n-------------CYCLE: 70-------------\ngame length: 133.0\nEpoch: 0 - loss: 119.09\nEpoch: 1 - loss: 96.03\nEpoch: 2 - loss: 91.6\nEpoch: 3 - loss: 89.27\n-------------CYCLE: 71-------------\ngame length: 135.0\nEpoch: 0 - loss: 104.02\nEpoch: 1 - loss: 94.27\nEpoch: 2 - loss: 154769.66\nEpoch: 3 - loss: 88.72\n-------------CYCLE: 72-------------\ngame length: 136.0\nEpoch: 0 - loss: 6907.52\nEpoch: 1 - loss: 98.44\nEpoch: 2 - loss: 89.76\nEpoch: 3 - loss: 86.77\n-------------CYCLE: 73-------------\ngame length: 134.0\nEpoch: 0 - loss: 102.76\nEpoch: 1 - loss: 80983.2\nEpoch: 2 - loss: 89.85\nEpoch: 3 - loss: 87.03\n-------------CYCLE: 74-------------\ngame length: 143.0\nEpoch: 0 - loss: 101.58\nEpoch: 1 - loss: 356770.31\nEpoch: 2 - loss: 88.2\nEpoch: 3 - loss: 85.25\n-------------CYCLE: 75-------------\ngame length: 144.0\nEpoch: 0 - loss: 101.14\nEpoch: 1 - loss: 89.61\nEpoch: 2 - loss: 85.11\nEpoch: 3 - loss: 82.48\n-------------CYCLE: 76-------------\ngame length: 138.0\nEpoch: 0 - loss: 101.81\nEpoch: 1 - loss: 90.95\nEpoch: 2 - loss: 85.82\nEpoch: 3 - loss: 83.92\n-------------CYCLE: 77-------------\ngame length: 148.0\nEpoch: 0 - loss: 98.45\nEpoch: 1 - loss: 90.0\nEpoch: 2 - loss: 86.1\nEpoch: 3 - loss: 3295615.33\n-------------CYCLE: 78-------------\ngame length: 152.0\nEpoch: 0 - loss: 90985970635.29\nEpoch: 1 - loss: 1154.08\nEpoch: 2 - loss: 84.69\nEpoch: 3 - loss: 158805.1\n-------------CYCLE: 79-------------\ngame length: 162.0\nEpoch: 0 - loss: 24694.24\nEpoch: 1 - loss: 84.05\nEpoch: 2 - loss: 80.57\nEpoch: 3 - loss: 77.28\n-------------CYCLE: 80-------------\ngame length: 146.0\nEpoch: 0 - loss: 103.16\nEpoch: 1 - loss: 89.73\nEpoch: 2 - loss: 658.51\nEpoch: 3 - loss: 83.08\n-------------CYCLE: 81-------------\ngame length: 150.0\nEpoch: 0 - loss: 2.5512623982614487e+21\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/518290801.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_move_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscounted_reward\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n\u001b[0m\u001b[1;32m     30\u001b[0m                                                         \u001b[0mlegal_move_mask\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlegal_move_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                         action = move_tmp)\n","\u001b[0;32m/tmp/ipykernel_31/2263836038.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, legal_move_mask, action)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\"\n\u001b[1;32m     59\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_move_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sample the action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         )\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m     72\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                         \u001b[0;34mf\"({type(value).__name__} of shape {tuple(value.shape)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected parameter logits (Tensor of shape (64, 1, 2)) of distribution Categorical(logits: torch.Size([64, 1, 2])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]]], device='cuda:0', grad_fn=<SubBackward0>)"],"ename":"ValueError","evalue":"Expected parameter logits (Tensor of shape (64, 1, 2)) of distribution Categorical(logits: torch.Size([64, 1, 2])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]],\n\n        [[nan, nan]]], device='cuda:0', grad_fn=<SubBackward0>)","output_type":"error"}],"execution_count":92},{"id":"7e3da580-5a6b-4775-a454-b946cef1ca0f","cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize = (20,5))\nsns.lineplot([i.item() for i in loss_list])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:14:58.357087Z","iopub.status.idle":"2025-04-18T17:14:58.357290Z","shell.execute_reply.started":"2025-04-18T17:14:58.357190Z","shell.execute_reply":"2025-04-18T17:14:58.357199Z"}},"outputs":[],"execution_count":null},{"id":"1a6020b7-a4f7-4921-b808-31bcc1f2cca5","cell_type":"code","source":"N_TRIAL = 10\nN_CYCLE = 20\nLEARNING_RATE_list = [2e-4, 5e-4, 7e-4, 1e-3]\ne_list = [0.1, 0.2, 0.3] #clipping constant\nvalue_coef_list = [0.5, 0.6, 0.7]\nentropy_coef_list = [0.01, 0.02, 0.03]\nparam_list = [LEARNING_RATE_list, e_list, value_coef_list, entropy_coef_list]\nparam_record = []\nrandomized_record = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:03:55.169285Z","iopub.execute_input":"2025-04-18T16:03:55.169546Z","iopub.status.idle":"2025-04-18T16:03:55.173914Z","shell.execute_reply.started":"2025-04-18T16:03:55.169528Z","shell.execute_reply":"2025-04-18T16:03:55.173207Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":26},{"id":"f5c4d184-277c-4072-a47d-591acee9ce07","cell_type":"code","source":"for trial in range(N_TRIAL):\n    \n    model = ppo(N_PLAYER).to(device)\n    \n    while True:\n        random_param_index = [random.choice(range(len(a))) for a in param_list]\n        if random_param_index not in randomized_record:\n            break\n    randomized_record.append(random_param_index)\n    \n    LEARNING_RATE, e, value_coef, entropy_coef = [a[b] for a,b in zip(param_list, random_param_index)]\n    \n    optimizer = Adam(model.parameters(), lr = LEARNING_RATE)\n    param_record.append(\n        {'learning_rate': LEARNING_RATE,\n        'e': e,\n        'value_coef': value_coef,\n        'entropy_coef': entropy_coef,\n       'index': trial\n        }\n    )\n    \n    print(f'learning_rate {LEARNING_RATE} | e: {e} | value_coef: {value_coef} | entropy_coef: {entropy_coef}')  \n    for index in range(N_CYCLE):\n        print(f'-------------CYCLE: {index}-------------')\n    \n        # Rollout\n        training_data = []\n        game_length = []\n        while len(training_data) <= DATA_LENGTH:\n            nothanks = nothanks_ppo()\n            play_buffer = nothanks.rollout(model)\n            training_data_tmp = create_training_data(play_buffer)\n            game_length.append(len(training_data_tmp))\n            training_data.extend(training_data_tmp)\n        print(f'game length: {round(np.mean(game_length),0)}')\n        \n        # create a new data loader\n        train_data = dataset(training_data)\n        dataloader = DataLoader(train_data, **dataloader_params)\n        \n        # Train\n        for epoch in range(N_EPOCH):\n            loss_record = 0\n            for index, (state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward) in enumerate(dataloader):\n                optimizer.zero_grad()\n                _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n                                                        legal_move_mask= legal_move_mask,\n                                                        action = move_tmp)\n                # policy loss\n                # advantage_norm_tmp = advantage_tmp.detach()\n                advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/(advantage_tmp.std() + 1e-8)\n                # print(advantage_norm_tmp.shape)\n                ratio = torch.exp(log_prob_new - log_prob_old).unsqueeze(dim = 1) # pi_new/pi_old\n                surrogate_1 = ratio*advantage_norm_tmp\n                ratio_clamp = torch.clamp(ratio, 1 - e, 1 + e) # clipped ratio\n                surrogate_2 = ratio_clamp*advantage_norm_tmp\n                policy_loss = -torch.min(surrogate_1, surrogate_2).mean() #FIX: is this adv detached? yes\n\n                # value loss\n                value_loss = ((value_new - discounted_reward)**2).mean()\n\n    \n                # entropy loss: to encourage exploration\n                entropy_loss = entropy.mean()\n\n                loss = policy_loss + value_coef * value_loss - entropy_coef * entropy_loss\n                loss_record += loss.item()\n                loss.backward()\n                nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.5) # FIX: check this\n                optimizer.step()\n    \n            print(f'Epoch: {epoch} - loss: {round(loss_record/index,2)}')\n    torch.save(model.state_dict(), f'./hyperparam_tuning_{trial}.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:04:11.595843Z","iopub.execute_input":"2025-04-18T16:04:11.596128Z","iopub.status.idle":"2025-04-18T16:31:14.132640Z","shell.execute_reply.started":"2025-04-18T16:04:11.596109Z","shell.execute_reply":"2025-04-18T16:31:14.132053Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"learning_rate 0.0005 | e: 0.3 | value_coef: 0.5 | entropy_coef: 0.01\n-------------CYCLE: 0-------------\ngame length: 46.0\nEpoch: 0 - loss: 142.29\nEpoch: 1 - loss: 137.67\nEpoch: 2 - loss: 136.62\nEpoch: 3 - loss: 134.96\n-------------CYCLE: 1-------------\ngame length: 63.0\nEpoch: 0 - loss: 125.86\nEpoch: 1 - loss: 125.14\nEpoch: 2 - loss: 124.11\nEpoch: 3 - loss: 123.29\n-------------CYCLE: 2-------------\ngame length: 90.0\nEpoch: 0 - loss: 106.39\nEpoch: 1 - loss: 105.48\nEpoch: 2 - loss: 104.62\nEpoch: 3 - loss: 104.22\n-------------CYCLE: 3-------------\ngame length: 108.0\nEpoch: 0 - loss: 116.81\nEpoch: 1 - loss: 115.81\nEpoch: 2 - loss: 115.0\nEpoch: 3 - loss: 114.72\n-------------CYCLE: 4-------------\ngame length: 99.0\nEpoch: 0 - loss: 111.54\nEpoch: 1 - loss: 110.52\nEpoch: 2 - loss: 110.07\nEpoch: 3 - loss: 109.44\n-------------CYCLE: 5-------------\ngame length: 112.0\nEpoch: 0 - loss: 106.41\nEpoch: 1 - loss: 104.69\nEpoch: 2 - loss: 103.57\nEpoch: 3 - loss: 102.48\n-------------CYCLE: 6-------------\ngame length: 110.0\nEpoch: 0 - loss: 110.48\nEpoch: 1 - loss: 109.11\nEpoch: 2 - loss: 108.57\nEpoch: 3 - loss: 107.48\n-------------CYCLE: 7-------------\ngame length: 103.0\nEpoch: 0 - loss: 111.39\nEpoch: 1 - loss: 109.55\nEpoch: 2 - loss: 108.15\nEpoch: 3 - loss: 107.03\n-------------CYCLE: 8-------------\ngame length: 119.0\nEpoch: 0 - loss: 118.82\nEpoch: 1 - loss: 116.63\nEpoch: 2 - loss: 115.35\nEpoch: 3 - loss: 114.5\n-------------CYCLE: 9-------------\ngame length: 117.0\nEpoch: 0 - loss: 109.82\nEpoch: 1 - loss: 107.51\nEpoch: 2 - loss: 105.81\nEpoch: 3 - loss: 104.73\n-------------CYCLE: 10-------------\ngame length: 122.0\nEpoch: 0 - loss: 109.47\nEpoch: 1 - loss: 105.97\nEpoch: 2 - loss: 104.42\nEpoch: 3 - loss: 102.86\n-------------CYCLE: 11-------------\ngame length: 127.0\nEpoch: 0 - loss: 108.74\nEpoch: 1 - loss: 105.7\nEpoch: 2 - loss: 104.01\nEpoch: 3 - loss: 102.43\n-------------CYCLE: 12-------------\ngame length: 118.0\nEpoch: 0 - loss: 116.39\nEpoch: 1 - loss: 113.87\nEpoch: 2 - loss: 112.66\nEpoch: 3 - loss: 111.46\n-------------CYCLE: 13-------------\ngame length: 128.0\nEpoch: 0 - loss: 114.38\nEpoch: 1 - loss: 111.84\nEpoch: 2 - loss: 109.84\nEpoch: 3 - loss: 108.37\n-------------CYCLE: 14-------------\ngame length: 126.0\nEpoch: 0 - loss: 124.48\nEpoch: 1 - loss: 120.71\nEpoch: 2 - loss: 119.03\nEpoch: 3 - loss: 117.07\n-------------CYCLE: 15-------------\ngame length: 121.0\nEpoch: 0 - loss: 123.48\nEpoch: 1 - loss: 119.96\nEpoch: 2 - loss: 117.53\nEpoch: 3 - loss: 115.95\n-------------CYCLE: 16-------------\ngame length: 117.0\nEpoch: 0 - loss: 119.38\nEpoch: 1 - loss: 115.6\nEpoch: 2 - loss: 113.86\nEpoch: 3 - loss: 111.95\n-------------CYCLE: 17-------------\ngame length: 125.0\nEpoch: 0 - loss: 108.65\nEpoch: 1 - loss: 104.82\nEpoch: 2 - loss: 102.93\nEpoch: 3 - loss: 100.96\n-------------CYCLE: 18-------------\ngame length: 114.0\nEpoch: 0 - loss: 117.06\nEpoch: 1 - loss: 112.46\nEpoch: 2 - loss: 109.95\nEpoch: 3 - loss: 108.28\n-------------CYCLE: 19-------------\ngame length: 112.0\nEpoch: 0 - loss: 112.08\nEpoch: 1 - loss: 108.72\nEpoch: 2 - loss: 106.4\nEpoch: 3 - loss: 105.12\nlearning_rate 0.001 | e: 0.3 | value_coef: 0.7 | entropy_coef: 0.03\n-------------CYCLE: 0-------------\ngame length: 50.0\nEpoch: 0 - loss: 197.42\nEpoch: 1 - loss: 192.65\nEpoch: 2 - loss: 190.39\nEpoch: 3 - loss: 188.18\n-------------CYCLE: 1-------------\ngame length: 67.0\nEpoch: 0 - loss: 155.23\nEpoch: 1 - loss: 152.84\nEpoch: 2 - loss: 151.23\nEpoch: 3 - loss: 150.21\n-------------CYCLE: 2-------------\ngame length: 91.0\nEpoch: 0 - loss: 163.76\nEpoch: 1 - loss: 161.58\nEpoch: 2 - loss: 160.03\nEpoch: 3 - loss: 158.99\n-------------CYCLE: 3-------------\ngame length: 110.0\nEpoch: 0 - loss: 151.81\nEpoch: 1 - loss: 148.69\nEpoch: 2 - loss: 146.32\nEpoch: 3 - loss: 143.75\n-------------CYCLE: 4-------------\ngame length: 100.0\nEpoch: 0 - loss: 171.92\nEpoch: 1 - loss: 167.91\nEpoch: 2 - loss: 166.05\nEpoch: 3 - loss: 163.86\n-------------CYCLE: 5-------------\ngame length: 100.0\nEpoch: 0 - loss: 150.15\nEpoch: 1 - loss: 146.48\nEpoch: 2 - loss: 144.1\nEpoch: 3 - loss: 141.16\n-------------CYCLE: 6-------------\ngame length: 109.0\nEpoch: 0 - loss: 161.71\nEpoch: 1 - loss: 155.64\nEpoch: 2 - loss: 152.34\nEpoch: 3 - loss: 149.08\n-------------CYCLE: 7-------------\ngame length: 96.0\nEpoch: 0 - loss: 157.82\nEpoch: 1 - loss: 151.2\nEpoch: 2 - loss: 147.82\nEpoch: 3 - loss: 144.72\n-------------CYCLE: 8-------------\ngame length: 100.0\nEpoch: 0 - loss: 157.53\nEpoch: 1 - loss: 151.61\nEpoch: 2 - loss: 148.39\nEpoch: 3 - loss: 145.53\n-------------CYCLE: 9-------------\ngame length: 104.0\nEpoch: 0 - loss: 168.24\nEpoch: 1 - loss: 159.94\nEpoch: 2 - loss: 154.94\nEpoch: 3 - loss: 151.14\n-------------CYCLE: 10-------------\ngame length: 102.0\nEpoch: 0 - loss: 146.94\nEpoch: 1 - loss: 141.02\nEpoch: 2 - loss: 137.79\nEpoch: 3 - loss: 135.47\n-------------CYCLE: 11-------------\ngame length: 105.0\nEpoch: 0 - loss: 157.56\nEpoch: 1 - loss: 151.68\nEpoch: 2 - loss: 147.46\nEpoch: 3 - loss: 143.51\n-------------CYCLE: 12-------------\ngame length: 110.0\nEpoch: 0 - loss: 157.15\nEpoch: 1 - loss: 148.67\nEpoch: 2 - loss: 143.57\nEpoch: 3 - loss: 140.25\n-------------CYCLE: 13-------------\ngame length: 111.0\nEpoch: 0 - loss: 160.31\nEpoch: 1 - loss: 153.3\nEpoch: 2 - loss: 149.51\nEpoch: 3 - loss: 146.1\n-------------CYCLE: 14-------------\ngame length: 110.0\nEpoch: 0 - loss: 159.57\nEpoch: 1 - loss: 153.28\nEpoch: 2 - loss: 149.86\nEpoch: 3 - loss: 147.08\n-------------CYCLE: 15-------------\ngame length: 105.0\nEpoch: 0 - loss: 171.53\nEpoch: 1 - loss: 165.31\nEpoch: 2 - loss: 161.24\nEpoch: 3 - loss: 157.86\n-------------CYCLE: 16-------------\ngame length: 103.0\nEpoch: 0 - loss: 152.86\nEpoch: 1 - loss: 146.43\nEpoch: 2 - loss: 141.66\nEpoch: 3 - loss: 138.61\n-------------CYCLE: 17-------------\ngame length: 110.0\nEpoch: 0 - loss: 154.69\nEpoch: 1 - loss: 147.68\nEpoch: 2 - loss: 142.6\nEpoch: 3 - loss: 138.64\n-------------CYCLE: 18-------------\ngame length: 105.0\nEpoch: 0 - loss: 155.37\nEpoch: 1 - loss: 146.58\nEpoch: 2 - loss: 142.07\nEpoch: 3 - loss: 138.58\n-------------CYCLE: 19-------------\ngame length: 112.0\nEpoch: 0 - loss: 158.29\nEpoch: 1 - loss: 149.19\nEpoch: 2 - loss: 144.81\nEpoch: 3 - loss: 141.83\nlearning_rate 0.0005 | e: 0.1 | value_coef: 0.7 | entropy_coef: 0.02\n-------------CYCLE: 0-------------\ngame length: 52.0\nEpoch: 0 - loss: 190.12\nEpoch: 1 - loss: 185.65\nEpoch: 2 - loss: 184.63\nEpoch: 3 - loss: 182.89\n-------------CYCLE: 1-------------\ngame length: 57.0\nEpoch: 0 - loss: 182.18\nEpoch: 1 - loss: 179.94\nEpoch: 2 - loss: 178.91\nEpoch: 3 - loss: 178.22\n-------------CYCLE: 2-------------\ngame length: 60.0\nEpoch: 0 - loss: 174.09\nEpoch: 1 - loss: 172.21\nEpoch: 2 - loss: 171.23\nEpoch: 3 - loss: 169.98\n-------------CYCLE: 3-------------\ngame length: 67.0\nEpoch: 0 - loss: 173.62\nEpoch: 1 - loss: 171.64\nEpoch: 2 - loss: 170.5\nEpoch: 3 - loss: 169.41\n-------------CYCLE: 4-------------\ngame length: 69.0\nEpoch: 0 - loss: 183.75\nEpoch: 1 - loss: 181.76\nEpoch: 2 - loss: 180.4\nEpoch: 3 - loss: 179.27\n-------------CYCLE: 5-------------\ngame length: 74.0\nEpoch: 0 - loss: 149.0\nEpoch: 1 - loss: 147.16\nEpoch: 2 - loss: 145.71\nEpoch: 3 - loss: 144.75\n-------------CYCLE: 6-------------\ngame length: 77.0\nEpoch: 0 - loss: 165.81\nEpoch: 1 - loss: 163.26\nEpoch: 2 - loss: 162.14\nEpoch: 3 - loss: 160.36\n-------------CYCLE: 7-------------\ngame length: 81.0\nEpoch: 0 - loss: 160.81\nEpoch: 1 - loss: 158.25\nEpoch: 2 - loss: 156.78\nEpoch: 3 - loss: 155.25\n-------------CYCLE: 8-------------\ngame length: 83.0\nEpoch: 0 - loss: 161.84\nEpoch: 1 - loss: 159.81\nEpoch: 2 - loss: 158.21\nEpoch: 3 - loss: 157.25\n-------------CYCLE: 9-------------\ngame length: 80.0\nEpoch: 0 - loss: 156.79\nEpoch: 1 - loss: 154.91\nEpoch: 2 - loss: 153.19\nEpoch: 3 - loss: 151.92\n-------------CYCLE: 10-------------\ngame length: 83.0\nEpoch: 0 - loss: 161.28\nEpoch: 1 - loss: 158.36\nEpoch: 2 - loss: 156.17\nEpoch: 3 - loss: 154.2\n-------------CYCLE: 11-------------\ngame length: 81.0\nEpoch: 0 - loss: 158.52\nEpoch: 1 - loss: 155.81\nEpoch: 2 - loss: 153.43\nEpoch: 3 - loss: 152.21\n-------------CYCLE: 12-------------\ngame length: 82.0\nEpoch: 0 - loss: 173.57\nEpoch: 1 - loss: 170.85\nEpoch: 2 - loss: 168.32\nEpoch: 3 - loss: 166.39\n-------------CYCLE: 13-------------\ngame length: 80.0\nEpoch: 0 - loss: 158.46\nEpoch: 1 - loss: 154.25\nEpoch: 2 - loss: 151.77\nEpoch: 3 - loss: 149.41\n-------------CYCLE: 14-------------\ngame length: 85.0\nEpoch: 0 - loss: 149.04\nEpoch: 1 - loss: 144.98\nEpoch: 2 - loss: 142.3\nEpoch: 3 - loss: 139.97\n-------------CYCLE: 15-------------\ngame length: 86.0\nEpoch: 0 - loss: 157.13\nEpoch: 1 - loss: 152.38\nEpoch: 2 - loss: 149.55\nEpoch: 3 - loss: 147.54\n-------------CYCLE: 16-------------\ngame length: 89.0\nEpoch: 0 - loss: 153.36\nEpoch: 1 - loss: 147.0\nEpoch: 2 - loss: 144.2\nEpoch: 3 - loss: 141.74\n-------------CYCLE: 17-------------\ngame length: 97.0\nEpoch: 0 - loss: 161.31\nEpoch: 1 - loss: 156.95\nEpoch: 2 - loss: 154.54\nEpoch: 3 - loss: 151.96\n-------------CYCLE: 18-------------\ngame length: 97.0\nEpoch: 0 - loss: 157.7\nEpoch: 1 - loss: 152.8\nEpoch: 2 - loss: 149.6\nEpoch: 3 - loss: 147.07\n-------------CYCLE: 19-------------\ngame length: 102.0\nEpoch: 0 - loss: 155.14\nEpoch: 1 - loss: 150.52\nEpoch: 2 - loss: 148.02\nEpoch: 3 - loss: 145.42\nlearning_rate 0.0007 | e: 0.2 | value_coef: 0.6 | entropy_coef: 0.03\n-------------CYCLE: 0-------------\ngame length: 47.0\nEpoch: 0 - loss: 165.83\nEpoch: 1 - loss: 161.59\nEpoch: 2 - loss: 160.1\nEpoch: 3 - loss: 158.29\n-------------CYCLE: 1-------------\ngame length: 58.0\nEpoch: 0 - loss: 159.16\nEpoch: 1 - loss: 156.98\nEpoch: 2 - loss: 156.6\nEpoch: 3 - loss: 155.31\n-------------CYCLE: 2-------------\ngame length: 73.0\nEpoch: 0 - loss: 137.46\nEpoch: 1 - loss: 135.61\nEpoch: 2 - loss: 134.73\nEpoch: 3 - loss: 133.6\n-------------CYCLE: 3-------------\ngame length: 73.0\nEpoch: 0 - loss: 135.85\nEpoch: 1 - loss: 134.54\nEpoch: 2 - loss: 133.45\nEpoch: 3 - loss: 132.68\n-------------CYCLE: 4-------------\ngame length: 77.0\nEpoch: 0 - loss: 142.5\nEpoch: 1 - loss: 140.52\nEpoch: 2 - loss: 139.62\nEpoch: 3 - loss: 138.18\n-------------CYCLE: 5-------------\ngame length: 89.0\nEpoch: 0 - loss: 139.36\nEpoch: 1 - loss: 137.27\nEpoch: 2 - loss: 136.01\nEpoch: 3 - loss: 134.56\n-------------CYCLE: 6-------------\ngame length: 89.0\nEpoch: 0 - loss: 142.94\nEpoch: 1 - loss: 141.12\nEpoch: 2 - loss: 139.64\nEpoch: 3 - loss: 137.96\n-------------CYCLE: 7-------------\ngame length: 87.0\nEpoch: 0 - loss: 133.51\nEpoch: 1 - loss: 131.42\nEpoch: 2 - loss: 129.27\nEpoch: 3 - loss: 127.53\n-------------CYCLE: 8-------------\ngame length: 95.0\nEpoch: 0 - loss: 125.2\nEpoch: 1 - loss: 121.59\nEpoch: 2 - loss: 119.7\nEpoch: 3 - loss: 118.5\n-------------CYCLE: 9-------------\ngame length: 100.0\nEpoch: 0 - loss: 119.95\nEpoch: 1 - loss: 116.03\nEpoch: 2 - loss: 113.63\nEpoch: 3 - loss: 111.42\n-------------CYCLE: 10-------------\ngame length: 104.0\nEpoch: 0 - loss: 132.52\nEpoch: 1 - loss: 128.05\nEpoch: 2 - loss: 125.25\nEpoch: 3 - loss: 123.31\n-------------CYCLE: 11-------------\ngame length: 104.0\nEpoch: 0 - loss: 134.94\nEpoch: 1 - loss: 130.09\nEpoch: 2 - loss: 127.01\nEpoch: 3 - loss: 124.5\n-------------CYCLE: 12-------------\ngame length: 101.0\nEpoch: 0 - loss: 134.37\nEpoch: 1 - loss: 130.28\nEpoch: 2 - loss: 127.85\nEpoch: 3 - loss: 125.77\n-------------CYCLE: 13-------------\ngame length: 107.0\nEpoch: 0 - loss: 130.08\nEpoch: 1 - loss: 125.03\nEpoch: 2 - loss: 122.27\nEpoch: 3 - loss: 120.45\n-------------CYCLE: 14-------------\ngame length: 110.0\nEpoch: 0 - loss: 120.8\nEpoch: 1 - loss: 115.8\nEpoch: 2 - loss: 112.56\nEpoch: 3 - loss: 110.36\n-------------CYCLE: 15-------------\ngame length: 106.0\nEpoch: 0 - loss: 133.55\nEpoch: 1 - loss: 128.39\nEpoch: 2 - loss: 125.62\nEpoch: 3 - loss: 122.97\n-------------CYCLE: 16-------------\ngame length: 106.0\nEpoch: 0 - loss: 142.38\nEpoch: 1 - loss: 136.41\nEpoch: 2 - loss: 133.44\nEpoch: 3 - loss: 130.84\n-------------CYCLE: 17-------------\ngame length: 109.0\nEpoch: 0 - loss: 132.18\nEpoch: 1 - loss: 124.86\nEpoch: 2 - loss: 120.66\nEpoch: 3 - loss: 117.6\n-------------CYCLE: 18-------------\ngame length: 105.0\nEpoch: 0 - loss: 136.05\nEpoch: 1 - loss: 129.7\nEpoch: 2 - loss: 127.02\nEpoch: 3 - loss: 123.91\n-------------CYCLE: 19-------------\ngame length: 109.0\nEpoch: 0 - loss: 130.99\nEpoch: 1 - loss: 124.7\nEpoch: 2 - loss: 121.31\nEpoch: 3 - loss: 118.98\nlearning_rate 0.0005 | e: 0.2 | value_coef: 0.6 | entropy_coef: 0.01\n-------------CYCLE: 0-------------\ngame length: 52.0\nEpoch: 0 - loss: 168.59\nEpoch: 1 - loss: 163.77\nEpoch: 2 - loss: 162.9\nEpoch: 3 - loss: 161.85\n-------------CYCLE: 1-------------\ngame length: 61.0\nEpoch: 0 - loss: 150.23\nEpoch: 1 - loss: 148.86\nEpoch: 2 - loss: 147.74\nEpoch: 3 - loss: 146.7\n-------------CYCLE: 2-------------\ngame length: 74.0\nEpoch: 0 - loss: 137.2\nEpoch: 1 - loss: 135.94\nEpoch: 2 - loss: 135.14\nEpoch: 3 - loss: 134.55\n-------------CYCLE: 3-------------\ngame length: 86.0\nEpoch: 0 - loss: 132.43\nEpoch: 1 - loss: 130.96\nEpoch: 2 - loss: 130.04\nEpoch: 3 - loss: 129.34\n-------------CYCLE: 4-------------\ngame length: 90.0\nEpoch: 0 - loss: 143.61\nEpoch: 1 - loss: 142.58\nEpoch: 2 - loss: 141.94\nEpoch: 3 - loss: 141.08\n-------------CYCLE: 5-------------\ngame length: 90.0\nEpoch: 0 - loss: 144.47\nEpoch: 1 - loss: 142.69\nEpoch: 2 - loss: 141.12\nEpoch: 3 - loss: 140.2\n-------------CYCLE: 6-------------\ngame length: 98.0\nEpoch: 0 - loss: 144.13\nEpoch: 1 - loss: 142.26\nEpoch: 2 - loss: 140.67\nEpoch: 3 - loss: 139.46\n-------------CYCLE: 7-------------\ngame length: 97.0\nEpoch: 0 - loss: 134.6\nEpoch: 1 - loss: 132.81\nEpoch: 2 - loss: 131.55\nEpoch: 3 - loss: 130.57\n-------------CYCLE: 8-------------\ngame length: 99.0\nEpoch: 0 - loss: 128.5\nEpoch: 1 - loss: 126.1\nEpoch: 2 - loss: 124.69\nEpoch: 3 - loss: 123.22\n-------------CYCLE: 9-------------\ngame length: 99.0\nEpoch: 0 - loss: 138.27\nEpoch: 1 - loss: 135.93\nEpoch: 2 - loss: 134.54\nEpoch: 3 - loss: 133.15\n-------------CYCLE: 10-------------\ngame length: 99.0\nEpoch: 0 - loss: 132.03\nEpoch: 1 - loss: 129.44\nEpoch: 2 - loss: 127.38\nEpoch: 3 - loss: 125.52\n-------------CYCLE: 11-------------\ngame length: 97.0\nEpoch: 0 - loss: 127.37\nEpoch: 1 - loss: 124.11\nEpoch: 2 - loss: 121.94\nEpoch: 3 - loss: 120.46\n-------------CYCLE: 12-------------\ngame length: 101.0\nEpoch: 0 - loss: 129.34\nEpoch: 1 - loss: 125.45\nEpoch: 2 - loss: 122.86\nEpoch: 3 - loss: 120.66\n-------------CYCLE: 13-------------\ngame length: 115.0\nEpoch: 0 - loss: 132.1\nEpoch: 1 - loss: 127.86\nEpoch: 2 - loss: 125.1\nEpoch: 3 - loss: 122.99\n-------------CYCLE: 14-------------\ngame length: 104.0\nEpoch: 0 - loss: 132.92\nEpoch: 1 - loss: 129.42\nEpoch: 2 - loss: 126.65\nEpoch: 3 - loss: 124.73\n-------------CYCLE: 15-------------\ngame length: 102.0\nEpoch: 0 - loss: 136.55\nEpoch: 1 - loss: 131.61\nEpoch: 2 - loss: 129.29\nEpoch: 3 - loss: 127.15\n-------------CYCLE: 16-------------\ngame length: 104.0\nEpoch: 0 - loss: 131.06\nEpoch: 1 - loss: 127.19\nEpoch: 2 - loss: 124.5\nEpoch: 3 - loss: 122.09\n-------------CYCLE: 17-------------\ngame length: 105.0\nEpoch: 0 - loss: 141.01\nEpoch: 1 - loss: 136.37\nEpoch: 2 - loss: 133.43\nEpoch: 3 - loss: 130.95\n-------------CYCLE: 18-------------\ngame length: 105.0\nEpoch: 0 - loss: 136.13\nEpoch: 1 - loss: 130.62\nEpoch: 2 - loss: 127.55\nEpoch: 3 - loss: 125.86\n-------------CYCLE: 19-------------\ngame length: 116.0\nEpoch: 0 - loss: 140.97\nEpoch: 1 - loss: 136.47\nEpoch: 2 - loss: 134.51\nEpoch: 3 - loss: 132.61\nlearning_rate 0.0005 | e: 0.3 | value_coef: 0.5 | entropy_coef: 0.02\n-------------CYCLE: 0-------------\ngame length: 43.0\nEpoch: 0 - loss: 147.64\nEpoch: 1 - loss: 140.45\nEpoch: 2 - loss: 139.73\nEpoch: 3 - loss: 138.51\n-------------CYCLE: 1-------------\ngame length: 59.0\nEpoch: 0 - loss: 128.0\nEpoch: 1 - loss: 126.7\nEpoch: 2 - loss: 125.88\nEpoch: 3 - loss: 125.24\n-------------CYCLE: 2-------------\ngame length: 77.0\nEpoch: 0 - loss: 118.05\nEpoch: 1 - loss: 116.28\nEpoch: 2 - loss: 115.95\nEpoch: 3 - loss: 115.14\n-------------CYCLE: 3-------------\ngame length: 100.0\nEpoch: 0 - loss: 112.03\nEpoch: 1 - loss: 110.97\nEpoch: 2 - loss: 110.45\nEpoch: 3 - loss: 109.85\n-------------CYCLE: 4-------------\ngame length: 99.0\nEpoch: 0 - loss: 120.32\nEpoch: 1 - loss: 119.05\nEpoch: 2 - loss: 118.71\nEpoch: 3 - loss: 118.4\n-------------CYCLE: 5-------------\ngame length: 98.0\nEpoch: 0 - loss: 99.86\nEpoch: 1 - loss: 98.83\nEpoch: 2 - loss: 98.36\nEpoch: 3 - loss: 97.64\n-------------CYCLE: 6-------------\ngame length: 97.0\nEpoch: 0 - loss: 115.56\nEpoch: 1 - loss: 114.58\nEpoch: 2 - loss: 113.88\nEpoch: 3 - loss: 112.94\n-------------CYCLE: 7-------------\ngame length: 108.0\nEpoch: 0 - loss: 106.33\nEpoch: 1 - loss: 104.71\nEpoch: 2 - loss: 103.84\nEpoch: 3 - loss: 102.78\n-------------CYCLE: 8-------------\ngame length: 106.0\nEpoch: 0 - loss: 102.98\nEpoch: 1 - loss: 101.75\nEpoch: 2 - loss: 100.56\nEpoch: 3 - loss: 99.19\n-------------CYCLE: 9-------------\ngame length: 99.0\nEpoch: 0 - loss: 115.81\nEpoch: 1 - loss: 113.46\nEpoch: 2 - loss: 112.25\nEpoch: 3 - loss: 111.26\n-------------CYCLE: 10-------------\ngame length: 101.0\nEpoch: 0 - loss: 115.85\nEpoch: 1 - loss: 113.51\nEpoch: 2 - loss: 112.26\nEpoch: 3 - loss: 111.16\n-------------CYCLE: 11-------------\ngame length: 102.0\nEpoch: 0 - loss: 112.33\nEpoch: 1 - loss: 109.35\nEpoch: 2 - loss: 107.23\nEpoch: 3 - loss: 106.0\n-------------CYCLE: 12-------------\ngame length: 107.0\nEpoch: 0 - loss: 114.35\nEpoch: 1 - loss: 112.04\nEpoch: 2 - loss: 110.36\nEpoch: 3 - loss: 109.28\n-------------CYCLE: 13-------------\ngame length: 108.0\nEpoch: 0 - loss: 117.15\nEpoch: 1 - loss: 113.92\nEpoch: 2 - loss: 112.11\nEpoch: 3 - loss: 110.7\n-------------CYCLE: 14-------------\ngame length: 104.0\nEpoch: 0 - loss: 125.36\nEpoch: 1 - loss: 121.94\nEpoch: 2 - loss: 119.88\nEpoch: 3 - loss: 118.34\n-------------CYCLE: 15-------------\ngame length: 100.0\nEpoch: 0 - loss: 124.12\nEpoch: 1 - loss: 120.54\nEpoch: 2 - loss: 118.44\nEpoch: 3 - loss: 116.83\n-------------CYCLE: 16-------------\ngame length: 105.0\nEpoch: 0 - loss: 117.13\nEpoch: 1 - loss: 113.12\nEpoch: 2 - loss: 110.77\nEpoch: 3 - loss: 109.22\n-------------CYCLE: 17-------------\ngame length: 108.0\nEpoch: 0 - loss: 108.41\nEpoch: 1 - loss: 105.22\nEpoch: 2 - loss: 103.66\nEpoch: 3 - loss: 101.59\n-------------CYCLE: 18-------------\ngame length: 107.0\nEpoch: 0 - loss: 110.78\nEpoch: 1 - loss: 108.04\nEpoch: 2 - loss: 105.63\nEpoch: 3 - loss: 103.99\n-------------CYCLE: 19-------------\ngame length: 109.0\nEpoch: 0 - loss: 108.43\nEpoch: 1 - loss: 104.07\nEpoch: 2 - loss: 101.49\nEpoch: 3 - loss: 99.68\nlearning_rate 0.0002 | e: 0.2 | value_coef: 0.5 | entropy_coef: 0.01\n-------------CYCLE: 0-------------\ngame length: 45.0\nEpoch: 0 - loss: 144.9\nEpoch: 1 - loss: 135.91\nEpoch: 2 - loss: 135.06\nEpoch: 3 - loss: 134.44\n-------------CYCLE: 1-------------\ngame length: 57.0\nEpoch: 0 - loss: 121.95\nEpoch: 1 - loss: 121.51\nEpoch: 2 - loss: 121.15\nEpoch: 3 - loss: 120.41\n-------------CYCLE: 2-------------\ngame length: 71.0\nEpoch: 0 - loss: 117.84\nEpoch: 1 - loss: 117.54\nEpoch: 2 - loss: 117.51\nEpoch: 3 - loss: 117.12\n-------------CYCLE: 3-------------\ngame length: 77.0\nEpoch: 0 - loss: 112.16\nEpoch: 1 - loss: 111.8\nEpoch: 2 - loss: 111.6\nEpoch: 3 - loss: 111.37\n-------------CYCLE: 4-------------\ngame length: 96.0\nEpoch: 0 - loss: 106.72\nEpoch: 1 - loss: 106.29\nEpoch: 2 - loss: 105.97\nEpoch: 3 - loss: 105.93\n-------------CYCLE: 5-------------\ngame length: 102.0\nEpoch: 0 - loss: 121.4\nEpoch: 1 - loss: 120.47\nEpoch: 2 - loss: 120.05\nEpoch: 3 - loss: 119.68\n-------------CYCLE: 6-------------\ngame length: 102.0\nEpoch: 0 - loss: 110.26\nEpoch: 1 - loss: 109.73\nEpoch: 2 - loss: 109.26\nEpoch: 3 - loss: 109.24\n-------------CYCLE: 7-------------\ngame length: 97.0\nEpoch: 0 - loss: 109.7\nEpoch: 1 - loss: 109.05\nEpoch: 2 - loss: 108.66\nEpoch: 3 - loss: 108.45\n-------------CYCLE: 8-------------\ngame length: 97.0\nEpoch: 0 - loss: 118.4\nEpoch: 1 - loss: 118.12\nEpoch: 2 - loss: 117.62\nEpoch: 3 - loss: 117.72\n-------------CYCLE: 9-------------\ngame length: 99.0\nEpoch: 0 - loss: 113.66\nEpoch: 1 - loss: 113.05\nEpoch: 2 - loss: 112.68\nEpoch: 3 - loss: 112.48\n-------------CYCLE: 10-------------\ngame length: 109.0\nEpoch: 0 - loss: 118.29\nEpoch: 1 - loss: 117.56\nEpoch: 2 - loss: 117.66\nEpoch: 3 - loss: 117.19\n-------------CYCLE: 11-------------\ngame length: 114.0\nEpoch: 0 - loss: 122.3\nEpoch: 1 - loss: 121.6\nEpoch: 2 - loss: 121.17\nEpoch: 3 - loss: 120.81\n-------------CYCLE: 12-------------\ngame length: 107.0\nEpoch: 0 - loss: 106.7\nEpoch: 1 - loss: 106.66\nEpoch: 2 - loss: 106.0\nEpoch: 3 - loss: 105.87\n-------------CYCLE: 13-------------\ngame length: 115.0\nEpoch: 0 - loss: 110.4\nEpoch: 1 - loss: 109.76\nEpoch: 2 - loss: 109.28\nEpoch: 3 - loss: 108.98\n-------------CYCLE: 14-------------\ngame length: 108.0\nEpoch: 0 - loss: 111.05\nEpoch: 1 - loss: 110.47\nEpoch: 2 - loss: 110.2\nEpoch: 3 - loss: 109.84\n-------------CYCLE: 15-------------\ngame length: 112.0\nEpoch: 0 - loss: 109.68\nEpoch: 1 - loss: 109.25\nEpoch: 2 - loss: 108.61\nEpoch: 3 - loss: 108.58\n-------------CYCLE: 16-------------\ngame length: 108.0\nEpoch: 0 - loss: 112.62\nEpoch: 1 - loss: 111.89\nEpoch: 2 - loss: 111.4\nEpoch: 3 - loss: 111.22\n-------------CYCLE: 17-------------\ngame length: 107.0\nEpoch: 0 - loss: 116.14\nEpoch: 1 - loss: 115.51\nEpoch: 2 - loss: 115.35\nEpoch: 3 - loss: 115.08\n-------------CYCLE: 18-------------\ngame length: 112.0\nEpoch: 0 - loss: 108.97\nEpoch: 1 - loss: 108.68\nEpoch: 2 - loss: 108.26\nEpoch: 3 - loss: 107.98\n-------------CYCLE: 19-------------\ngame length: 111.0\nEpoch: 0 - loss: 109.04\nEpoch: 1 - loss: 108.11\nEpoch: 2 - loss: 107.9\nEpoch: 3 - loss: 107.37\nlearning_rate 0.001 | e: 0.3 | value_coef: 0.6 | entropy_coef: 0.01\n-------------CYCLE: 0-------------\ngame length: 47.0\nEpoch: 0 - loss: 168.72\nEpoch: 1 - loss: 165.51\nEpoch: 2 - loss: 163.57\nEpoch: 3 - loss: 161.52\n-------------CYCLE: 1-------------\ngame length: 68.0\nEpoch: 0 - loss: 144.78\nEpoch: 1 - loss: 142.88\nEpoch: 2 - loss: 141.23\nEpoch: 3 - loss: 140.15\n-------------CYCLE: 2-------------\ngame length: 75.0\nEpoch: 0 - loss: 140.78\nEpoch: 1 - loss: 137.59\nEpoch: 2 - loss: 136.09\nEpoch: 3 - loss: 134.96\n-------------CYCLE: 3-------------\ngame length: 92.0\nEpoch: 0 - loss: 135.36\nEpoch: 1 - loss: 133.98\nEpoch: 2 - loss: 133.3\nEpoch: 3 - loss: 131.9\n-------------CYCLE: 4-------------\ngame length: 89.0\nEpoch: 0 - loss: 137.65\nEpoch: 1 - loss: 135.48\nEpoch: 2 - loss: 133.33\nEpoch: 3 - loss: 131.37\n-------------CYCLE: 5-------------\ngame length: 92.0\nEpoch: 0 - loss: 142.69\nEpoch: 1 - loss: 138.46\nEpoch: 2 - loss: 136.73\nEpoch: 3 - loss: 134.54\n-------------CYCLE: 6-------------\ngame length: 91.0\nEpoch: 0 - loss: 142.18\nEpoch: 1 - loss: 138.47\nEpoch: 2 - loss: 135.88\nEpoch: 3 - loss: 132.98\n-------------CYCLE: 7-------------\ngame length: 102.0\nEpoch: 0 - loss: 135.93\nEpoch: 1 - loss: 131.93\nEpoch: 2 - loss: 129.7\nEpoch: 3 - loss: 127.16\n-------------CYCLE: 8-------------\ngame length: 111.0\nEpoch: 0 - loss: 134.85\nEpoch: 1 - loss: 129.59\nEpoch: 2 - loss: 127.27\nEpoch: 3 - loss: 124.52\n-------------CYCLE: 9-------------\ngame length: 115.0\nEpoch: 0 - loss: 124.68\nEpoch: 1 - loss: 120.27\nEpoch: 2 - loss: 117.0\nEpoch: 3 - loss: 114.66\n-------------CYCLE: 10-------------\ngame length: 114.0\nEpoch: 0 - loss: 146.92\nEpoch: 1 - loss: 141.74\nEpoch: 2 - loss: 136.82\nEpoch: 3 - loss: 134.61\n-------------CYCLE: 11-------------\ngame length: 119.0\nEpoch: 0 - loss: 132.57\nEpoch: 1 - loss: 128.04\nEpoch: 2 - loss: 125.36\nEpoch: 3 - loss: 122.66\n-------------CYCLE: 12-------------\ngame length: 116.0\nEpoch: 0 - loss: 143.15\nEpoch: 1 - loss: 137.26\nEpoch: 2 - loss: 133.3\nEpoch: 3 - loss: 130.14\n-------------CYCLE: 13-------------\ngame length: 121.0\nEpoch: 0 - loss: 136.95\nEpoch: 1 - loss: 130.78\nEpoch: 2 - loss: 127.81\nEpoch: 3 - loss: 125.46\n-------------CYCLE: 14-------------\ngame length: 120.0\nEpoch: 0 - loss: 128.77\nEpoch: 1 - loss: 123.71\nEpoch: 2 - loss: 121.21\nEpoch: 3 - loss: 119.02\n-------------CYCLE: 15-------------\ngame length: 112.0\nEpoch: 0 - loss: 145.35\nEpoch: 1 - loss: 139.24\nEpoch: 2 - loss: 136.17\nEpoch: 3 - loss: 133.22\n-------------CYCLE: 16-------------\ngame length: 112.0\nEpoch: 0 - loss: 144.99\nEpoch: 1 - loss: 137.39\nEpoch: 2 - loss: 133.78\nEpoch: 3 - loss: 131.23\n-------------CYCLE: 17-------------\ngame length: 116.0\nEpoch: 0 - loss: 132.61\nEpoch: 1 - loss: 125.11\nEpoch: 2 - loss: 121.02\nEpoch: 3 - loss: 118.39\n-------------CYCLE: 18-------------\ngame length: 128.0\nEpoch: 0 - loss: 135.79\nEpoch: 1 - loss: 127.68\nEpoch: 2 - loss: 123.33\nEpoch: 3 - loss: 120.9\n-------------CYCLE: 19-------------\ngame length: 120.0\nEpoch: 0 - loss: 140.35\nEpoch: 1 - loss: 133.56\nEpoch: 2 - loss: 130.07\nEpoch: 3 - loss: 126.57\nlearning_rate 0.001 | e: 0.2 | value_coef: 0.6 | entropy_coef: 0.02\n-------------CYCLE: 0-------------\ngame length: 52.0\nEpoch: 0 - loss: 162.01\nEpoch: 1 - loss: 159.27\nEpoch: 2 - loss: 157.67\nEpoch: 3 - loss: 155.77\n-------------CYCLE: 1-------------\ngame length: 67.0\nEpoch: 0 - loss: 145.93\nEpoch: 1 - loss: 143.93\nEpoch: 2 - loss: 142.38\nEpoch: 3 - loss: 141.2\n-------------CYCLE: 2-------------\ngame length: 79.0\nEpoch: 0 - loss: 138.57\nEpoch: 1 - loss: 136.63\nEpoch: 2 - loss: 135.66\nEpoch: 3 - loss: 134.64\n-------------CYCLE: 3-------------\ngame length: 88.0\nEpoch: 0 - loss: 132.38\nEpoch: 1 - loss: 130.27\nEpoch: 2 - loss: 129.39\nEpoch: 3 - loss: 128.26\n-------------CYCLE: 4-------------\ngame length: 96.0\nEpoch: 0 - loss: 137.49\nEpoch: 1 - loss: 135.24\nEpoch: 2 - loss: 133.64\nEpoch: 3 - loss: 132.35\n-------------CYCLE: 5-------------\ngame length: 105.0\nEpoch: 0 - loss: 146.72\nEpoch: 1 - loss: 144.5\nEpoch: 2 - loss: 142.37\nEpoch: 3 - loss: 140.49\n-------------CYCLE: 6-------------\ngame length: 106.0\nEpoch: 0 - loss: 135.3\nEpoch: 1 - loss: 131.64\nEpoch: 2 - loss: 130.05\nEpoch: 3 - loss: 127.91\n-------------CYCLE: 7-------------\ngame length: 112.0\nEpoch: 0 - loss: 135.76\nEpoch: 1 - loss: 132.14\nEpoch: 2 - loss: 129.2\nEpoch: 3 - loss: 126.75\n-------------CYCLE: 8-------------\ngame length: 113.0\nEpoch: 0 - loss: 123.96\nEpoch: 1 - loss: 118.11\nEpoch: 2 - loss: 114.23\nEpoch: 3 - loss: 111.85\n-------------CYCLE: 9-------------\ngame length: 115.0\nEpoch: 0 - loss: 136.17\nEpoch: 1 - loss: 130.85\nEpoch: 2 - loss: 127.74\nEpoch: 3 - loss: 124.73\n-------------CYCLE: 10-------------\ngame length: 108.0\nEpoch: 0 - loss: 137.65\nEpoch: 1 - loss: 132.37\nEpoch: 2 - loss: 128.23\nEpoch: 3 - loss: 125.32\n-------------CYCLE: 11-------------\ngame length: 104.0\nEpoch: 0 - loss: 147.04\nEpoch: 1 - loss: 139.18\nEpoch: 2 - loss: 134.91\nEpoch: 3 - loss: 131.43\n-------------CYCLE: 12-------------\ngame length: 105.0\nEpoch: 0 - loss: 135.79\nEpoch: 1 - loss: 129.66\nEpoch: 2 - loss: 126.08\nEpoch: 3 - loss: 122.91\n-------------CYCLE: 13-------------\ngame length: 100.0\nEpoch: 0 - loss: 133.43\nEpoch: 1 - loss: 125.97\nEpoch: 2 - loss: 121.57\nEpoch: 3 - loss: 118.22\n-------------CYCLE: 14-------------\ngame length: 107.0\nEpoch: 0 - loss: 141.77\nEpoch: 1 - loss: 133.02\nEpoch: 2 - loss: 128.86\nEpoch: 3 - loss: 125.33\n-------------CYCLE: 15-------------\ngame length: 120.0\nEpoch: 0 - loss: 138.22\nEpoch: 1 - loss: 130.13\nEpoch: 2 - loss: 125.71\nEpoch: 3 - loss: 122.39\n-------------CYCLE: 16-------------\ngame length: 114.0\nEpoch: 0 - loss: 134.0\nEpoch: 1 - loss: 125.99\nEpoch: 2 - loss: 122.5\nEpoch: 3 - loss: 119.57\n-------------CYCLE: 17-------------\ngame length: 109.0\nEpoch: 0 - loss: 138.57\nEpoch: 1 - loss: 131.23\nEpoch: 2 - loss: 127.21\nEpoch: 3 - loss: 123.99\n-------------CYCLE: 18-------------\ngame length: 113.0\nEpoch: 0 - loss: 137.64\nEpoch: 1 - loss: 127.11\nEpoch: 2 - loss: 122.55\nEpoch: 3 - loss: 119.4\n-------------CYCLE: 19-------------\ngame length: 107.0\nEpoch: 0 - loss: 146.26\nEpoch: 1 - loss: 137.2\nEpoch: 2 - loss: 132.37\nEpoch: 3 - loss: 128.22\nlearning_rate 0.0002 | e: 0.2 | value_coef: 0.6 | entropy_coef: 0.02\n-------------CYCLE: 0-------------\ngame length: 49.0\nEpoch: 0 - loss: 175.9\nEpoch: 1 - loss: 165.7\nEpoch: 2 - loss: 164.72\nEpoch: 3 - loss: 163.76\n-------------CYCLE: 1-------------\ngame length: 61.0\nEpoch: 0 - loss: 149.77\nEpoch: 1 - loss: 149.48\nEpoch: 2 - loss: 149.23\nEpoch: 3 - loss: 148.45\n-------------CYCLE: 2-------------\ngame length: 73.0\nEpoch: 0 - loss: 139.08\nEpoch: 1 - loss: 138.77\nEpoch: 2 - loss: 138.03\nEpoch: 3 - loss: 137.53\n-------------CYCLE: 3-------------\ngame length: 81.0\nEpoch: 0 - loss: 136.74\nEpoch: 1 - loss: 136.16\nEpoch: 2 - loss: 136.21\nEpoch: 3 - loss: 135.45\n-------------CYCLE: 4-------------\ngame length: 84.0\nEpoch: 0 - loss: 141.74\nEpoch: 1 - loss: 141.33\nEpoch: 2 - loss: 140.95\nEpoch: 3 - loss: 140.48\n-------------CYCLE: 5-------------\ngame length: 88.0\nEpoch: 0 - loss: 141.36\nEpoch: 1 - loss: 140.67\nEpoch: 2 - loss: 140.41\nEpoch: 3 - loss: 140.04\n-------------CYCLE: 6-------------\ngame length: 93.0\nEpoch: 0 - loss: 134.35\nEpoch: 1 - loss: 133.84\nEpoch: 2 - loss: 133.42\nEpoch: 3 - loss: 132.93\n-------------CYCLE: 7-------------\ngame length: 94.0\nEpoch: 0 - loss: 136.93\nEpoch: 1 - loss: 136.15\nEpoch: 2 - loss: 135.68\nEpoch: 3 - loss: 135.41\n-------------CYCLE: 8-------------\ngame length: 91.0\nEpoch: 0 - loss: 126.78\nEpoch: 1 - loss: 126.4\nEpoch: 2 - loss: 126.14\nEpoch: 3 - loss: 125.62\n-------------CYCLE: 9-------------\ngame length: 100.0\nEpoch: 0 - loss: 136.99\nEpoch: 1 - loss: 136.56\nEpoch: 2 - loss: 136.01\nEpoch: 3 - loss: 135.85\n-------------CYCLE: 10-------------\ngame length: 99.0\nEpoch: 0 - loss: 134.46\nEpoch: 1 - loss: 134.16\nEpoch: 2 - loss: 133.67\nEpoch: 3 - loss: 133.37\n-------------CYCLE: 11-------------\ngame length: 96.0\nEpoch: 0 - loss: 130.34\nEpoch: 1 - loss: 129.97\nEpoch: 2 - loss: 129.51\nEpoch: 3 - loss: 129.14\n-------------CYCLE: 12-------------\ngame length: 104.0\nEpoch: 0 - loss: 136.34\nEpoch: 1 - loss: 135.95\nEpoch: 2 - loss: 134.99\nEpoch: 3 - loss: 134.77\n-------------CYCLE: 13-------------\ngame length: 105.0\nEpoch: 0 - loss: 133.44\nEpoch: 1 - loss: 132.88\nEpoch: 2 - loss: 132.46\nEpoch: 3 - loss: 132.03\n-------------CYCLE: 14-------------\ngame length: 108.0\nEpoch: 0 - loss: 130.21\nEpoch: 1 - loss: 129.36\nEpoch: 2 - loss: 128.98\nEpoch: 3 - loss: 128.59\n-------------CYCLE: 15-------------\ngame length: 106.0\nEpoch: 0 - loss: 137.73\nEpoch: 1 - loss: 137.21\nEpoch: 2 - loss: 136.7\nEpoch: 3 - loss: 136.04\n-------------CYCLE: 16-------------\ngame length: 105.0\nEpoch: 0 - loss: 130.91\nEpoch: 1 - loss: 130.27\nEpoch: 2 - loss: 129.76\nEpoch: 3 - loss: 129.26\n-------------CYCLE: 17-------------\ngame length: 102.0\nEpoch: 0 - loss: 129.12\nEpoch: 1 - loss: 128.58\nEpoch: 2 - loss: 128.01\nEpoch: 3 - loss: 127.57\n-------------CYCLE: 18-------------\ngame length: 101.0\nEpoch: 0 - loss: 136.44\nEpoch: 1 - loss: 135.72\nEpoch: 2 - loss: 135.56\nEpoch: 3 - loss: 135.22\n-------------CYCLE: 19-------------\ngame length: 102.0\nEpoch: 0 - loss: 132.56\nEpoch: 1 - loss: 131.47\nEpoch: 2 - loss: 131.12\nEpoch: 3 - loss: 130.82\n","output_type":"stream"}],"execution_count":27},{"id":"5303e749-fd00-44c7-a86a-e5b2dd25d6ea","cell_type":"code","source":"param_record","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T02:55:02.112285Z","iopub.execute_input":"2025-04-18T02:55:02.112649Z","iopub.status.idle":"2025-04-18T02:55:02.118025Z","shell.execute_reply.started":"2025-04-18T02:55:02.112627Z","shell.execute_reply":"2025-04-18T02:55:02.117452Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":475,"output_type":"execute_result","data":{"text/plain":"[{'learning_rate': 0.0005,\n  'e': 0.3,\n  'value_coef': 0.7,\n  'entropy_coef': 0.01,\n  'index': 0},\n {'learning_rate': 0.001,\n  'e': 0.2,\n  'value_coef': 0.6,\n  'entropy_coef': 0.01,\n  'index': 1},\n {'learning_rate': 0.0005,\n  'e': 0.3,\n  'value_coef': 0.5,\n  'entropy_coef': 0.03,\n  'index': 2},\n {'learning_rate': 0.0007,\n  'e': 0.1,\n  'value_coef': 0.5,\n  'entropy_coef': 0.03,\n  'index': 3},\n {'learning_rate': 0.0007,\n  'e': 0.1,\n  'value_coef': 0.6,\n  'entropy_coef': 0.01,\n  'index': 4},\n {'learning_rate': 0.001,\n  'e': 0.3,\n  'value_coef': 0.5,\n  'entropy_coef': 0.03,\n  'index': 5},\n {'learning_rate': 0.001,\n  'e': 0.1,\n  'value_coef': 0.5,\n  'entropy_coef': 0.01,\n  'index': 6},\n {'learning_rate': 0.0002,\n  'e': 0.1,\n  'value_coef': 0.6,\n  'entropy_coef': 0.03,\n  'index': 7},\n {'learning_rate': 0.001,\n  'e': 0.2,\n  'value_coef': 0.7,\n  'entropy_coef': 0.03,\n  'index': 8},\n {'learning_rate': 0.0007,\n  'e': 0.3,\n  'value_coef': 0.6,\n  'entropy_coef': 0.02,\n  'index': 9}]"},"metadata":{}}],"execution_count":475},{"id":"9265092f-c09a-4887-9fe9-77a7149f597f","cell_type":"code","source":"# Test nan weight\nmodel = ppo(N_PLAYER).to(device)\nfor epoch in range(N_EPOCH):\n    loss_record = 0\n    for index, (state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward) in enumerate(dataloader):\n        optimizer.zero_grad()\n        _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n                                                legal_move_mask= legal_move_mask,\n                                                action = move_tmp)\n        # policy loss\n        # advantage_norm_tmp = advantage_tmp.detach()\n        advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/(advantage_tmp.std() + 1e-8)\n        print(advantage_tmp.shape)\n        if advantage_norm_tmp.isnan().sum().item():\n            print(advantage_tmp.shape)\n        # print(advantage_norm_tmp.shape)\n        ratio = torch.exp(log_prob_new - log_prob_old).unsqueeze(dim = 1) # pi_new/pi_old\n        surrogate_1 = ratio*advantage_norm_tmp\n        ratio_clamp = torch.clamp(ratio, 1 - e, 1 + e) # clipped ratio\n        surrogate_2 = ratio_clamp*advantage_norm_tmp\n        policy_loss = -torch.min(surrogate_1, surrogate_2).mean() #FIX: is this adv detached? yes\n        \n        # value loss\n        value_loss = ((value_new - discounted_reward)**2).mean()\n\n        # entropy loss: to encourage exploration\n        entropy_loss = entropy.mean()\n\n        loss = policy_loss + value_coef * value_loss - entropy_coef * entropy_loss\n        loss_record += loss.item()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.5) # FIX: check this\n        optimizer.step()\n        \n\n    print(f'Epoch: {epoch} - loss: {round(loss_record/index,2)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T22:37:16.796346Z","iopub.execute_input":"2025-04-17T22:37:16.796729Z","iopub.status.idle":"2025-04-17T22:37:18.653001Z","shell.execute_reply.started":"2025-04-17T22:37:16.796697Z","shell.execute_reply":"2025-04-17T22:37:18.652441Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"torch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([1, 1, 1])\ntorch.Size([1, 1, 1])\nEpoch: 0 - loss: nan\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1957756208.py:11: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n  advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/(advantage_tmp.std() + 1e-8)\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([1, 1, 1])\ntorch.Size([1, 1, 1])\nEpoch: 1 - loss: nan\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([1, 1, 1])\ntorch.Size([1, 1, 1])\nEpoch: 2 - loss: nan\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([1, 1, 1])\ntorch.Size([1, 1, 1])\nEpoch: 3 - loss: nan\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([64, 1, 1])\ntorch.Size([1, 1, 1])\ntorch.Size([1, 1, 1])\nEpoch: 4 - loss: nan\n","output_type":"stream"}],"execution_count":243},{"id":"4942d32e-c8c9-497c-aed6-fa1c62354f76","cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:44:04.807903Z","iopub.execute_input":"2025-04-18T11:44:04.808205Z","iopub.status.idle":"2025-04-18T11:44:05.705726Z","shell.execute_reply.started":"2025-04-18T11:44:04.808177Z","shell.execute_reply":"2025-04-18T11:44:05.705120Z"}},"outputs":[],"execution_count":15},{"id":"4fbb2f0e-fc1e-46b2-bab1-2f1df2ec74fe","cell_type":"code","source":"# policy_loss_log\n# value_loss_log\n# entropy_loss_log\n\nfig, ax = plt.subplots(1,1, figsize = (20,5))\nsns.lineplot([i.item() for i in value_loss_log])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:44:05.706847Z","iopub.execute_input":"2025-04-18T11:44:05.707180Z","iopub.status.idle":"2025-04-18T11:44:05.961262Z","shell.execute_reply.started":"2025-04-18T11:44:05.707163Z","shell.execute_reply":"2025-04-18T11:44:05.960155Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2885564057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue_loss_log\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'value_loss_log' is not defined"],"ename":"NameError","evalue":"name 'value_loss_log' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 2000x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":16},{"id":"be777e5b-c2d6-4e05-bb6d-5f3edda4b323","cell_type":"markdown","source":"# Deploy","metadata":{}},{"id":"d138a360-0b2d-403e-bd90-17070754e5b8","cell_type":"code","source":"import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T18:59:51.514949Z","iopub.execute_input":"2025-04-17T18:59:51.515270Z","iopub.status.idle":"2025-04-17T18:59:51.518812Z","shell.execute_reply.started":"2025-04-17T18:59:51.515252Z","shell.execute_reply":"2025-04-17T18:59:51.517977Z"}},"outputs":[],"execution_count":14},{"id":"518c8d05-6753-46a3-b8a1-31dcca43d558","cell_type":"code","source":"# model = ppo(N_PLAYER).to(device)\n# model.load_state_dict(torch.load('/kaggle/input/ppo_3/pytorch/default/1/model_state_3.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:01:18.217829Z","iopub.execute_input":"2025-04-17T19:01:18.218434Z","iopub.status.idle":"2025-04-17T19:01:18.247698Z","shell.execute_reply.started":"2025-04-17T19:01:18.218412Z","shell.execute_reply":"2025-04-17T19:01:18.247090Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1658644612.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/input/ppo_3/pytorch/default/1/model_state_3.pth'))\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":16},{"id":"f63e88cd-5c9c-45e0-96e7-01aa6d0f9178","cell_type":"code","source":"model = ppo(N_PLAYER).to(device)\npath = f'/kaggle/working/model_new_arc_complex_rwd_50_iter.pth'\nmodel.load_state_dict(torch.load(path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:00:19.418454Z","iopub.execute_input":"2025-04-18T17:00:19.419088Z","iopub.status.idle":"2025-04-18T17:00:19.430583Z","shell.execute_reply.started":"2025-04-18T17:00:19.419068Z","shell.execute_reply":"2025-04-18T17:00:19.429893Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/4181618562.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(path))\n","output_type":"stream"},{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":79},{"id":"570417da-dfd9-4789-a587-e661bd2f148c","cell_type":"code","source":"move_encode = {\"0\": \"pass\",\n                \"1\": \"take\"}\nnothanks = nothanks_ppo()\nhuman_index = 5\n\nwhile nothanks.is_continue:\n    print('------------------------------')\n    print(f'''Card: {nothanks.current_card} | Chip in pot: {nothanks.chip_in_pot} | Player: {nothanks.turn} - {nothanks.players[nothanks.turn]}\\n'''\n)\n    print('------------------------------')\n    if nothanks.turn == human_index:\n        move = move_encode.get(input(\"\"\"Your turn:\n0: pass\n1: take\nEnter here: \"\"\"))\n    else:\n        with torch.no_grad():\n            current_state = torch.tensor(nothanks.encode_state()).to(device)\n            legal_move = nothanks.get_legal_action() # a list \n            legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n            move_raw, log_prob, entropy, value = model.forward(current_state, legal_move_mask)\n            move = nothanks.move_encode.get(move_raw.item())\n    print(f'Move taken: {move}')\n    nothanks.action(move)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:00:36.524726Z","iopub.execute_input":"2025-04-18T17:00:36.524958Z","iopub.status.idle":"2025-04-18T17:00:36.639426Z","shell.execute_reply.started":"2025-04-18T17:00:36.524942Z","shell.execute_reply":"2025-04-18T17:00:36.638782Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"------------------------------\nCard: 30 | Chip in pot: 0 | Player: 0 - Chip: 11 | Card owned: []\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 30 | Chip in pot: 1 | Player: 1 - Chip: 11 | Card owned: []\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 30 | Chip in pot: 2 | Player: 2 - Chip: 11 | Card owned: []\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 30 | Chip in pot: 3 | Player: 0 - Chip: 10 | Card owned: []\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 30 | Chip in pot: 4 | Player: 1 - Chip: 10 | Card owned: []\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 30 | Chip in pot: 5 | Player: 2 - Chip: 10 | Card owned: []\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 8 | Chip in pot: 0 | Player: 2 - Chip: 15 | Card owned: [30]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 8 | Chip in pot: 1 | Player: 0 - Chip: 9 | Card owned: []\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 9 | Chip in pot: 0 | Player: 0 - Chip: 10 | Card owned: [8]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 18 | Chip in pot: 0 | Player: 0 - Chip: 10 | Card owned: [8, 9]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 18 | Chip in pot: 1 | Player: 1 - Chip: 9 | Card owned: []\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 18 | Chip in pot: 2 | Player: 2 - Chip: 14 | Card owned: [30]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 18 | Chip in pot: 3 | Player: 0 - Chip: 9 | Card owned: [8, 9]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 18 | Chip in pot: 4 | Player: 1 - Chip: 8 | Card owned: []\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 19 | Chip in pot: 0 | Player: 1 - Chip: 12 | Card owned: [18]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 19 | Chip in pot: 1 | Player: 2 - Chip: 13 | Card owned: [30]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 34 | Chip in pot: 0 | Player: 2 - Chip: 14 | Card owned: [30, 19]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 34 | Chip in pot: 1 | Player: 0 - Chip: 8 | Card owned: [8, 9]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 34 | Chip in pot: 2 | Player: 1 - Chip: 11 | Card owned: [18]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 34 | Chip in pot: 3 | Player: 2 - Chip: 13 | Card owned: [30, 19]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 34 | Chip in pot: 4 | Player: 0 - Chip: 7 | Card owned: [8, 9]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 26 | Chip in pot: 0 | Player: 0 - Chip: 11 | Card owned: [8, 9, 34]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 26 | Chip in pot: 1 | Player: 1 - Chip: 10 | Card owned: [18]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 26 | Chip in pot: 2 | Player: 2 - Chip: 12 | Card owned: [30, 19]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 24 | Chip in pot: 0 | Player: 2 - Chip: 14 | Card owned: [30, 19, 26]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 24 | Chip in pot: 1 | Player: 0 - Chip: 10 | Card owned: [8, 9, 34]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 24 | Chip in pot: 2 | Player: 1 - Chip: 9 | Card owned: [18]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 24 | Chip in pot: 3 | Player: 2 - Chip: 13 | Card owned: [30, 19, 26]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 24 | Chip in pot: 4 | Player: 0 - Chip: 9 | Card owned: [8, 9, 34]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 20 | Chip in pot: 0 | Player: 0 - Chip: 13 | Card owned: [8, 9, 34, 24]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 20 | Chip in pot: 1 | Player: 1 - Chip: 8 | Card owned: [18]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 20 | Chip in pot: 2 | Player: 2 - Chip: 12 | Card owned: [30, 19, 26]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 20 | Chip in pot: 3 | Player: 0 - Chip: 12 | Card owned: [8, 9, 34, 24]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 20 | Chip in pot: 4 | Player: 1 - Chip: 7 | Card owned: [18]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 12 | Chip in pot: 0 | Player: 1 - Chip: 11 | Card owned: [18, 20]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 12 | Chip in pot: 1 | Player: 2 - Chip: 11 | Card owned: [30, 19, 26]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 12 | Chip in pot: 2 | Player: 0 - Chip: 11 | Card owned: [8, 9, 34, 24]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 12 | Chip in pot: 3 | Player: 1 - Chip: 10 | Card owned: [18, 20]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 3 | Chip in pot: 0 | Player: 1 - Chip: 13 | Card owned: [18, 20, 12]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 3 | Chip in pot: 1 | Player: 2 - Chip: 10 | Card owned: [30, 19, 26]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 3 | Chip in pot: 2 | Player: 0 - Chip: 10 | Card owned: [8, 9, 34, 24]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 11 | Chip in pot: 0 | Player: 0 - Chip: 12 | Card owned: [8, 9, 34, 24, 3]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 31 | Chip in pot: 0 | Player: 0 - Chip: 12 | Card owned: [8, 9, 34, 24, 3, 11]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 31 | Chip in pot: 1 | Player: 1 - Chip: 12 | Card owned: [18, 20, 12]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 31 | Chip in pot: 2 | Player: 2 - Chip: 9 | Card owned: [30, 19, 26]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 31 | Chip in pot: 3 | Player: 0 - Chip: 11 | Card owned: [8, 9, 34, 24, 3, 11]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 31 | Chip in pot: 4 | Player: 1 - Chip: 11 | Card owned: [18, 20, 12]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 10 | Chip in pot: 0 | Player: 1 - Chip: 15 | Card owned: [18, 20, 12, 31]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 10 | Chip in pot: 1 | Player: 2 - Chip: 8 | Card owned: [30, 19, 26]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 15 | Chip in pot: 0 | Player: 2 - Chip: 9 | Card owned: [30, 19, 26, 10]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 15 | Chip in pot: 1 | Player: 0 - Chip: 10 | Card owned: [8, 9, 34, 24, 3, 11]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 15 | Chip in pot: 2 | Player: 1 - Chip: 14 | Card owned: [18, 20, 12, 31]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 14 | Chip in pot: 0 | Player: 1 - Chip: 16 | Card owned: [18, 20, 12, 31, 15]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 13 | Chip in pot: 0 | Player: 1 - Chip: 16 | Card owned: [18, 20, 12, 31, 15, 14]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 16 | Chip in pot: 0 | Player: 1 - Chip: 16 | Card owned: [18, 20, 12, 31, 15, 14, 13]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 22 | Chip in pot: 0 | Player: 1 - Chip: 16 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 1 | Player: 2 - Chip: 8 | Card owned: [30, 19, 26, 10]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 2 | Player: 0 - Chip: 9 | Card owned: [8, 9, 34, 24, 3, 11]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 3 | Player: 1 - Chip: 15 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 4 | Player: 2 - Chip: 7 | Card owned: [30, 19, 26, 10]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 5 | Player: 0 - Chip: 8 | Card owned: [8, 9, 34, 24, 3, 11]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 6 | Player: 1 - Chip: 14 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 7 | Player: 2 - Chip: 6 | Card owned: [30, 19, 26, 10]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 8 | Player: 0 - Chip: 7 | Card owned: [8, 9, 34, 24, 3, 11]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 22 | Chip in pot: 9 | Player: 1 - Chip: 13 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 33 | Chip in pot: 0 | Player: 1 - Chip: 22 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16, 22]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 33 | Chip in pot: 1 | Player: 2 - Chip: 5 | Card owned: [30, 19, 26, 10]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 33 | Chip in pot: 2 | Player: 0 - Chip: 6 | Card owned: [8, 9, 34, 24, 3, 11]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 33 | Chip in pot: 3 | Player: 1 - Chip: 21 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16, 22]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 33 | Chip in pot: 4 | Player: 2 - Chip: 4 | Card owned: [30, 19, 26, 10]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 33 | Chip in pot: 5 | Player: 0 - Chip: 5 | Card owned: [8, 9, 34, 24, 3, 11]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 27 | Chip in pot: 0 | Player: 0 - Chip: 10 | Card owned: [8, 9, 34, 24, 3, 11, 33]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 27 | Chip in pot: 1 | Player: 1 - Chip: 20 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16, 22]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 27 | Chip in pot: 2 | Player: 2 - Chip: 3 | Card owned: [30, 19, 26, 10]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 27 | Chip in pot: 3 | Player: 0 - Chip: 9 | Card owned: [8, 9, 34, 24, 3, 11, 33]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 27 | Chip in pot: 4 | Player: 1 - Chip: 19 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16, 22]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 27 | Chip in pot: 5 | Player: 2 - Chip: 2 | Card owned: [30, 19, 26, 10]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 25 | Chip in pot: 0 | Player: 2 - Chip: 7 | Card owned: [30, 19, 26, 10, 27]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 25 | Chip in pot: 1 | Player: 0 - Chip: 8 | Card owned: [8, 9, 34, 24, 3, 11, 33]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 4 | Chip in pot: 0 | Player: 0 - Chip: 9 | Card owned: [8, 9, 34, 24, 3, 11, 33, 25]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 4 | Chip in pot: 1 | Player: 1 - Chip: 18 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16, 22]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 4 | Chip in pot: 2 | Player: 2 - Chip: 6 | Card owned: [30, 19, 26, 10, 27]\n\n------------------------------\nMove taken: take\n------------------------------\nCard: 21 | Chip in pot: 0 | Player: 2 - Chip: 8 | Card owned: [30, 19, 26, 10, 27, 4]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 21 | Chip in pot: 1 | Player: 0 - Chip: 8 | Card owned: [8, 9, 34, 24, 3, 11, 33, 25]\n\n------------------------------\nMove taken: pass\n------------------------------\nCard: 21 | Chip in pot: 2 | Player: 1 - Chip: 17 | Card owned: [18, 20, 12, 31, 15, 14, 13, 16, 22]\n\n------------------------------\nMove taken: take\n","output_type":"stream"}],"execution_count":84},{"id":"03988333-1df4-4521-8044-1ed1277389ef","cell_type":"code","source":"for player_tmp in nothanks.players:\n    print(player_tmp.calculate_score())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:00:40.225166Z","iopub.execute_input":"2025-04-18T17:00:40.225744Z","iopub.status.idle":"2025-04-18T17:00:40.229595Z","shell.execute_reply.started":"2025-04-18T17:00:40.225725Z","shell.execute_reply":"2025-04-18T17:00:40.228758Z"}},"outputs":[{"name":"stdout","text":"-72\n-62\n-82\n","output_type":"stream"}],"execution_count":85},{"id":"2d8199ca-ec52-4932-bb96-0bb4e41a6fde","cell_type":"code","source":"nothanks.calculate_ranking()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:21:43.022297Z","iopub.execute_input":"2025-04-18T12:21:43.022571Z","iopub.status.idle":"2025-04-18T12:21:43.027880Z","shell.execute_reply.started":"2025-04-18T12:21:43.022550Z","shell.execute_reply":"2025-04-18T12:21:43.027354Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"[-20.0, 20.0, 0.0]"},"metadata":{}}],"execution_count":94},{"id":"c1486fc0-d005-4c10-a130-60365dab6d39","cell_type":"code","source":"import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:08:13.052969Z","iopub.execute_input":"2025-04-17T14:08:13.053261Z","iopub.status.idle":"2025-04-17T14:08:13.056928Z","shell.execute_reply.started":"2025-04-17T14:08:13.053233Z","shell.execute_reply":"2025-04-17T14:08:13.056156Z"}},"outputs":[],"execution_count":94},{"id":"7c761d26-b049-4a7d-b991-ba2e36ebe9ec","cell_type":"code","source":"os.getcwd()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:08:16.257751Z","iopub.execute_input":"2025-04-17T14:08:16.258302Z","iopub.status.idle":"2025-04-17T14:08:16.262669Z","shell.execute_reply.started":"2025-04-17T14:08:16.258280Z","shell.execute_reply":"2025-04-17T14:08:16.261971Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}],"execution_count":95},{"id":"9a662464-e4a7-4a81-bb6c-f9b493c988fa","cell_type":"code","source":"output = os.getcwd()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:09:18.363605Z","iopub.execute_input":"2025-04-17T14:09:18.364142Z","iopub.status.idle":"2025-04-17T14:09:18.367654Z","shell.execute_reply.started":"2025-04-17T14:09:18.364115Z","shell.execute_reply":"2025-04-17T14:09:18.366914Z"}},"outputs":[],"execution_count":96},{"id":"ea2c0a76-3dc3-485a-ac57-186f00e4a06a","cell_type":"code","source":"torch.save(model.state_dict(), './model_new_arc_default_rwd_30_iter.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:42:40.450574Z","iopub.execute_input":"2025-04-18T12:42:40.451273Z","iopub.status.idle":"2025-04-18T12:42:40.458005Z","shell.execute_reply.started":"2025-04-18T12:42:40.451250Z","shell.execute_reply":"2025-04-18T12:42:40.457385Z"}},"outputs":[],"execution_count":111},{"id":"81d6b041-1b94-46b9-b741-f4f36e79bee3","cell_type":"code","source":"torch.log(model.policy(current_state))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:59:54.719232Z","iopub.execute_input":"2025-04-17T04:59:54.719458Z","iopub.status.idle":"2025-04-17T04:59:54.725618Z","shell.execute_reply.started":"2025-04-17T04:59:54.719442Z","shell.execute_reply":"2025-04-17T04:59:54.725126Z"}},"outputs":[{"execution_count":179,"output_type":"execute_result","data":{"text/plain":"tensor([3.2157,    nan], device='cuda:0', grad_fn=<LogBackward0>)"},"metadata":{}}],"execution_count":179},{"id":"429f2c6a-b2d9-4b5f-93e9-4295bf8b3cf6","cell_type":"code","source":"logit = model.get_policy(current_state, legal_move_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T05:00:56.888397Z","iopub.execute_input":"2025-04-17T05:00:56.888964Z","iopub.status.idle":"2025-04-17T05:00:56.893186Z","shell.execute_reply.started":"2025-04-17T05:00:56.888941Z","shell.execute_reply":"2025-04-17T05:00:56.892422Z"}},"outputs":[],"execution_count":183},{"id":"5260b5cd-7708-4e0b-a1ed-c47bef3f2f1a","cell_type":"code","source":"nn.Softmax()(logit)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T05:02:52.974590Z","iopub.execute_input":"2025-04-17T05:02:52.974833Z","iopub.status.idle":"2025-04-17T05:02:52.981578Z","shell.execute_reply.started":"2025-04-17T05:02:52.974816Z","shell.execute_reply":"2025-04-17T05:02:52.980930Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n","output_type":"stream"},{"execution_count":195,"output_type":"execute_result","data":{"text/plain":"tensor([1.0000e+00, 9.3703e-23], device='cuda:0', grad_fn=<SoftmaxBackward0>)"},"metadata":{}}],"execution_count":195},{"id":"0fc26388-778c-4324-9d66-b0af410bb4af","cell_type":"code","source":"prob = Categorical(logits = logit)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T05:00:59.840482Z","iopub.execute_input":"2025-04-17T05:00:59.841276Z","iopub.status.idle":"2025-04-17T05:00:59.845269Z","shell.execute_reply.started":"2025-04-17T05:00:59.841246Z","shell.execute_reply":"2025-04-17T05:00:59.844558Z"}},"outputs":[],"execution_count":185},{"id":"b19ec9d6-5dd7-4c83-95f3-3b88edb61e05","cell_type":"code","source":"move = prob.sample()\nmove","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T05:01:28.391901Z","iopub.execute_input":"2025-04-17T05:01:28.392171Z","iopub.status.idle":"2025-04-17T05:01:28.398012Z","shell.execute_reply.started":"2025-04-17T05:01:28.392155Z","shell.execute_reply":"2025-04-17T05:01:28.397318Z"}},"outputs":[{"execution_count":189,"output_type":"execute_result","data":{"text/plain":"tensor(0, device='cuda:0')"},"metadata":{}}],"execution_count":189},{"id":"e32b0e15-b5b2-4330-88ba-9935285e4b6b","cell_type":"markdown","source":"# Pitting","metadata":{"execution":{"iopub.status.busy":"2025-04-17T05:01:47.951202Z","iopub.execute_input":"2025-04-17T05:01:47.951447Z","iopub.status.idle":"2025-04-17T05:01:47.957353Z","shell.execute_reply.started":"2025-04-17T05:01:47.951429Z","shell.execute_reply":"2025-04-17T05:01:47.956611Z"}}},{"id":"5712bb8e-167c-4d04-9ff8-57580f7258b6","cell_type":"code","source":"import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:53:22.396290Z","iopub.execute_input":"2025-04-18T16:53:22.396905Z","iopub.status.idle":"2025-04-18T16:53:22.399900Z","shell.execute_reply.started":"2025-04-18T16:53:22.396885Z","shell.execute_reply":"2025-04-18T16:53:22.399313Z"}},"outputs":[],"execution_count":52},{"id":"c8de9adc-e99f-4179-a0a3-a0ed7808d4b1","cell_type":"code","source":"model_prefix = 'model_gen_3_default_rwd'\n# model_list = [i for i in os.listdir('/kaggle/working') if i.startswith(model_prefix)]\nmodel_list = ['model_gen_3_default_rwd_50_iter.pth',\n              'model_gen_3_default_rwd_60_iter.pth',\n              'model_gen_3_default_rwd_80_iter.pth',\n              'model_new_arc_complex_rwd_80_iter.pth',\n              'model_new_arc_complex_rwd_50_iter.pth',\n              'model_new_arc_complex_rwd_20_iter.pth',\n             ]\nmodel_name_dict = {a:b for a, b in enumerate(model_list)}\nn_model = len(model_name_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:22:02.756620Z","iopub.execute_input":"2025-04-18T17:22:02.757160Z","iopub.status.idle":"2025-04-18T17:22:02.761474Z","shell.execute_reply.started":"2025-04-18T17:22:02.757139Z","shell.execute_reply":"2025-04-18T17:22:02.760881Z"}},"outputs":[],"execution_count":103},{"id":"46581afe-719a-4403-be80-789a403fd652","cell_type":"code","source":"select_record = {i:0 for i in range(n_model)}\nwin_record = {i:0 for i in range(n_model)}\nmove_encode = {\"0\": \"pass\",\n                \"1\": \"take\"}\n\nn_match = 500","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:22:03.802672Z","iopub.execute_input":"2025-04-18T17:22:03.803281Z","iopub.status.idle":"2025-04-18T17:22:03.806863Z","shell.execute_reply.started":"2025-04-18T17:22:03.803262Z","shell.execute_reply":"2025-04-18T17:22:03.806314Z"}},"outputs":[],"execution_count":104},{"id":"146842f3-3f0b-4bf1-bbbd-b3adbe774589","cell_type":"code","source":"for _ in tqdm(range(n_match)):\n    \n    model_index = random.sample(range(n_model), k = 3)        \n    for index in model_index:\n        select_record[index] += 1\n    model_list = []\n    for index in model_index:\n        model = ppo(N_PLAYER).to(device)\n        path = f'/kaggle/working/{model_name_dict.get(index)}'\n        model.load_state_dict(torch.load(path))\n        model_list.append(model)\n    \n    \n    nothanks = nothanks_ppo()\n    while nothanks.is_continue:\n        with torch.no_grad():\n            current_state = torch.tensor(nothanks.encode_state()).to(device)\n            legal_move = nothanks.get_legal_action() # a list \n            legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n            move_raw, log_prob, entropy, value = model_list[nothanks.turn].forward(current_state, legal_move_mask)\n            move = nothanks.move_encode.get(move_raw.item())\n        nothanks.action(move)    \n    \n    winner_index = np.argmax(nothanks.calculate_ranking())\n    win_record[model_index[winner_index]] += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:22:06.030288Z","iopub.execute_input":"2025-04-18T17:22:06.030551Z","iopub.status.idle":"2025-04-18T17:23:17.150833Z","shell.execute_reply.started":"2025-04-18T17:22:06.030531Z","shell.execute_reply":"2025-04-18T17:23:17.150285Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/500 [00:00<?, ?it/s]/tmp/ipykernel_31/2851337586.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(path))\n100%|| 500/500 [01:11<00:00,  7.03it/s]\n","output_type":"stream"}],"execution_count":105},{"id":"323c13dc-5c0d-45bf-9f1c-dbfbf4044322","cell_type":"code","source":"pd.DataFrame([select_record, win_record]).T\\\n.rename(columns = {0: 'total',\n         1: 'win'\n        })\\\n.assign(win_pct = lambda df: df['win']/df['total'])\\\n.sort_values('win_pct', ascending = False)\\\n.reset_index()\\\n.assign(model_name = lambda df: df['index'].apply(lambda x: model_name_dict.get(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:24:33.974859Z","iopub.execute_input":"2025-04-18T17:24:33.975124Z","iopub.status.idle":"2025-04-18T17:24:33.987574Z","shell.execute_reply.started":"2025-04-18T17:24:33.975105Z","shell.execute_reply":"2025-04-18T17:24:33.987008Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"   index  total  win   win_pct                             model_name\n0      1    236   97  0.411017    model_gen_3_default_rwd_60_iter.pth\n1      0    248   97  0.391129    model_gen_3_default_rwd_50_iter.pth\n2      3    245   85  0.346939  model_new_arc_complex_rwd_80_iter.pth\n3      2    265   89  0.335849    model_gen_3_default_rwd_80_iter.pth\n4      5    242   64  0.264463  model_new_arc_complex_rwd_20_iter.pth\n5      4    264   68  0.257576  model_new_arc_complex_rwd_50_iter.pth","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>total</th>\n      <th>win</th>\n      <th>win_pct</th>\n      <th>model_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>236</td>\n      <td>97</td>\n      <td>0.411017</td>\n      <td>model_gen_3_default_rwd_60_iter.pth</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>248</td>\n      <td>97</td>\n      <td>0.391129</td>\n      <td>model_gen_3_default_rwd_50_iter.pth</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>245</td>\n      <td>85</td>\n      <td>0.346939</td>\n      <td>model_new_arc_complex_rwd_80_iter.pth</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>265</td>\n      <td>89</td>\n      <td>0.335849</td>\n      <td>model_gen_3_default_rwd_80_iter.pth</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>242</td>\n      <td>64</td>\n      <td>0.264463</td>\n      <td>model_new_arc_complex_rwd_20_iter.pth</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>264</td>\n      <td>68</td>\n      <td>0.257576</td>\n      <td>model_new_arc_complex_rwd_50_iter.pth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":111},{"id":"eeed3bb5-42e0-4051-9466-0d8343e62414","cell_type":"code","source":"model_name_dict.get(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:23:51.052221Z","iopub.execute_input":"2025-04-18T17:23:51.052482Z","iopub.status.idle":"2025-04-18T17:23:51.058132Z","shell.execute_reply.started":"2025-04-18T17:23:51.052463Z","shell.execute_reply":"2025-04-18T17:23:51.057270Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"'model_new_arc_complex_rwd_80_iter.pth'"},"metadata":{}}],"execution_count":109},{"id":"3913ec79-ea22-4658-b880-755cd5e3145e","cell_type":"code","source":"param_record[4]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:36:09.234917Z","iopub.execute_input":"2025-04-18T16:36:09.235401Z","iopub.status.idle":"2025-04-18T16:36:09.240122Z","shell.execute_reply.started":"2025-04-18T16:36:09.235378Z","shell.execute_reply":"2025-04-18T16:36:09.239529Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.0005,\n 'e': 0.2,\n 'value_coef': 0.6,\n 'entropy_coef': 0.01,\n 'index': 4}"},"metadata":{}}],"execution_count":35},{"id":"94a6a648-307e-40e3-b753-603b74add55c","cell_type":"code","source":"param_record","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:36:14.235242Z","iopub.execute_input":"2025-04-18T16:36:14.235801Z","iopub.status.idle":"2025-04-18T16:36:14.240870Z","shell.execute_reply.started":"2025-04-18T16:36:14.235781Z","shell.execute_reply":"2025-04-18T16:36:14.240318Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'learning_rate': 0.0005,\n  'e': 0.3,\n  'value_coef': 0.5,\n  'entropy_coef': 0.01,\n  'index': 0},\n {'learning_rate': 0.001,\n  'e': 0.3,\n  'value_coef': 0.7,\n  'entropy_coef': 0.03,\n  'index': 1},\n {'learning_rate': 0.0005,\n  'e': 0.1,\n  'value_coef': 0.7,\n  'entropy_coef': 0.02,\n  'index': 2},\n {'learning_rate': 0.0007,\n  'e': 0.2,\n  'value_coef': 0.6,\n  'entropy_coef': 0.03,\n  'index': 3},\n {'learning_rate': 0.0005,\n  'e': 0.2,\n  'value_coef': 0.6,\n  'entropy_coef': 0.01,\n  'index': 4},\n {'learning_rate': 0.0005,\n  'e': 0.3,\n  'value_coef': 0.5,\n  'entropy_coef': 0.02,\n  'index': 5},\n {'learning_rate': 0.0002,\n  'e': 0.2,\n  'value_coef': 0.5,\n  'entropy_coef': 0.01,\n  'index': 6},\n {'learning_rate': 0.001,\n  'e': 0.3,\n  'value_coef': 0.6,\n  'entropy_coef': 0.01,\n  'index': 7},\n {'learning_rate': 0.001,\n  'e': 0.2,\n  'value_coef': 0.6,\n  'entropy_coef': 0.02,\n  'index': 8},\n {'learning_rate': 0.0002,\n  'e': 0.2,\n  'value_coef': 0.6,\n  'entropy_coef': 0.02,\n  'index': 9}]"},"metadata":{}}],"execution_count":36},{"id":"7b3b0a4d-4686-458e-a4c2-d3d0f0bd4661","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}