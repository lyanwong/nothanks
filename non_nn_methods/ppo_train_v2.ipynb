{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a345ea-dd69-438d-accc-1eeb4fe996c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:30.825721Z",
     "iopub.status.busy": "2025-04-19T14:23:30.825449Z",
     "iopub.status.idle": "2025-04-19T14:23:30.855348Z",
     "shell.execute_reply": "2025-04-19T14:23:30.854653Z",
     "shell.execute_reply.started": "2025-04-19T14:23:30.825700Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dda7e44-ac20-4ee9-9ae5-772c0944474a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:37.274309Z",
     "iopub.status.busy": "2025-04-19T14:23:37.273941Z",
     "iopub.status.idle": "2025-04-19T14:23:37.359716Z",
     "shell.execute_reply": "2025-04-19T14:23:37.358942Z",
     "shell.execute_reply.started": "2025-04-19T14:23:37.274288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de52ca57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:37.360952Z",
     "iopub.status.busy": "2025-04-19T14:23:37.360644Z",
     "iopub.status.idle": "2025-04-19T14:23:37.384876Z",
     "shell.execute_reply": "2025-04-19T14:23:37.384206Z",
     "shell.execute_reply.started": "2025-04-19T14:23:37.360921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8fdb3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43a060",
   "metadata": {},
   "source": [
    "## Gen 3 - 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435fe918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:37.386940Z",
     "iopub.status.busy": "2025-04-19T14:23:37.386266Z",
     "iopub.status.idle": "2025-04-19T14:23:37.393813Z",
     "shell.execute_reply": "2025-04-19T14:23:37.393174Z",
     "shell.execute_reply.started": "2025-04-19T14:23:37.386916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ppo(nn.Module):\n",
    "    def __init__(self, n_player, n_card = 33):\n",
    "        super().__init__()\n",
    "        self.n_action = 2\n",
    "        self.n_card = n_card\n",
    "        self.n_player = n_player\n",
    "        self.n_param_per_player = self.n_card + 1 # 33 cards + 1 number of chips\n",
    "        self.n_state_param = self.n_card*2 + 5 # 33 for flipped card, 33 for remain card, 1 for chip in pot, 1 for number of cards remained, 1 for good card self, 1 for good card other, 1 for chipinpot/current\n",
    "        self.input_dim = self.n_player*self.n_param_per_player + self.n_state_param\n",
    "        \n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, self.n_action)\n",
    "            )\n",
    "        \n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, 1)\n",
    "            )\n",
    "    \n",
    "    def get_policy(self, X, legal_move_mask):\n",
    "        \"\"\"Mask the legal output\n",
    "        legal_move_mask: boolean tensor, True for masked\"\"\"\n",
    "        logit = self.policy(X)\n",
    "        logit_masked = logit.masked_fill(legal_move_mask, float('-inf'))\n",
    "        return logit_masked\n",
    "\n",
    "    def forward(self, X, legal_move_mask, action = None):\n",
    "        \"\"\"Get value, probability\n",
    "        legal_move_mask: boolean tensor\n",
    "        action: tensor(1) Integer. This is the old sampled action. If none will do sampling\n",
    "        \"\"\"\n",
    "        logit = self.get_policy(X, legal_move_mask)\n",
    "        prob = Categorical(logits = logit)\n",
    "        if action == None:\n",
    "            action = prob.sample() # sample the action\n",
    "        log_prob = prob.log_prob(action) # this will be used for surrogate loss (log(a) - log(b) = log(a/b))\n",
    "        value = self.value(X)\n",
    "\n",
    "        return action, log_prob, prob.entropy(), value # sampled action, log probability of it, its entropy,value from value network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb0f1b",
   "metadata": {},
   "source": [
    "## Gen 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3e7c35-ac68-437f-83b4-35e4136280ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:37.394959Z",
     "iopub.status.busy": "2025-04-19T14:23:37.394733Z",
     "iopub.status.idle": "2025-04-19T14:23:37.408767Z",
     "shell.execute_reply": "2025-04-19T14:23:37.408093Z",
     "shell.execute_reply.started": "2025-04-19T14:23:37.394938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gen 4 - collapsing opponents\n",
    "\n",
    "class ppo_gen_4(ppo):\n",
    "    def __init__(self, n_player, n_card = 33):\n",
    "        super().__init__(n_player, n_card)\n",
    "        # self.n_action = 2\n",
    "        # self.n_card = n_card\n",
    "        # self.n_player = n_player\n",
    "        self.n_param_per_player = self.n_card + 1 # 33 cards + 1 number of chips\n",
    "        self.n_state_param = self.n_card*2 + 5 # 33 for flipped card, 33 for remain card, 1 for chip in pot, 1 for number of cards remained, 1 for good card self, 1 for good card other, 1 for chipinpot/current\n",
    "        self.input_dim = 2*self.n_param_per_player + self.n_state_param # 2 because 1 for self, 1 for opponents\n",
    "        \n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, self.n_action)\n",
    "            )\n",
    "        \n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, 1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be023fba",
   "metadata": {},
   "source": [
    "## Gen 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3934f4-a83d-4421-ad1d-128468a1f4fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:38.775214Z",
     "iopub.status.busy": "2025-04-19T14:23:38.774945Z",
     "iopub.status.idle": "2025-04-19T14:23:38.780307Z",
     "shell.execute_reply": "2025-04-19T14:23:38.779521Z",
     "shell.execute_reply.started": "2025-04-19T14:23:38.775194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Flatten_custom(nn.Module):\n",
    "    def __init__(self, start_dim_batch: int = 1, start_dim_unbatch: int = 0, end_dim: int = -1) -> None:\n",
    "        super().__init__()\n",
    "        self.start_dim_batch = start_dim_batch\n",
    "        self.start_dim_unbatch = start_dim_unbatch\n",
    "        self.end_dim = end_dim\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 4:\n",
    "            return x.flatten(self.start_dim_batch, self.end_dim)\n",
    "        else:\n",
    "            return x.flatten(self.start_dim_unbatch, self.end_dim)\n",
    "\n",
    "flatten_custom  = Flatten_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e1918-0b96-4ae6-a3d8-4d0de3530ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:39.527734Z",
     "iopub.status.busy": "2025-04-19T14:23:39.527483Z",
     "iopub.status.idle": "2025-04-19T14:23:39.539268Z",
     "shell.execute_reply": "2025-04-19T14:23:39.538520Z",
     "shell.execute_reply.started": "2025-04-19T14:23:39.527713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ppo_gen_5(ppo):\n",
    "    def __init__(self, n_player, n_card = 33):\n",
    "        super().__init__(n_player, n_card)\n",
    "        self.in_channel = n_player + 2 # 1 for flipped card, 1 for remaining cards\n",
    "        self.out_channel = 16\n",
    "        self.n_state_param = n_player + 5 # 1 for chip in pot, 1 for number of cards remained, 1 for good card self, 1 for good card other, 1 for chipinpot/current\n",
    "        self.flatten_dimension = 512 # hard code\n",
    "        self.gen = 5\n",
    "        self.flatten_custom = Flatten_custom()\n",
    "\n",
    "        \n",
    "        self.cnn_policy = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels = self.in_channel,\n",
    "            out_channels = self.out_channel,\n",
    "            kernel_size = (1, 3)\n",
    "            ),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            Flatten_custom()\n",
    "        )\n",
    "\n",
    "        self.linear_state_policy = nn.Sequential(\n",
    "            nn.Linear(self.n_state_param, 16),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "        )\n",
    "        \n",
    "        self.ff_policy = nn.Sequential(\n",
    "            nn.Linear(self.flatten_dimension, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, self.n_action)\n",
    "            )\n",
    "        \n",
    "        self.cnn_value = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels = self.in_channel,\n",
    "            out_channels = self.out_channel,\n",
    "            kernel_size = (1, 3)\n",
    "            ),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            Flatten_custom()\n",
    "        )\n",
    "\n",
    "        self.linear_state_value = nn.Linear(self.n_state_param, 16)\n",
    "\n",
    "        self.ff_value = nn.Sequential(\n",
    "            nn.Linear(self.flatten_dimension, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, 1)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward_concat(self, x_card, x_state, cnn_layer, linear_layer):\n",
    "        x_card_flat = cnn_layer(x_card)\n",
    "        x_state_flat = linear_layer(x_state)\n",
    "        if len(x_card_flat.shape) == 1:\n",
    "            dim = 0\n",
    "        else:\n",
    "            dim = 1\n",
    "        return torch.cat([x_card_flat, x_state_flat], dim = dim)\n",
    "\n",
    "    def get_policy(self, x_card, x_state, legal_move_mask):\n",
    "        \"\"\"Mask the legal output\n",
    "        legal_move_mask: boolean tensor, True for masked\"\"\"\n",
    "        policy_concat = self.forward_concat(x_card, x_state, self.cnn_policy, self.linear_state_policy) # flattened + concat\n",
    "        logit = self.ff_policy(policy_concat)\n",
    "        logit_masked = logit.masked_fill(legal_move_mask, float('-inf'))\n",
    "        return logit_masked\n",
    "\n",
    "    def get_value(self, x_card, x_state):\n",
    "        value_concat = self.forward_concat(x_card, x_state, self.cnn_value, self.linear_state_value) # flattened + concat\n",
    "        value = self.ff_value(value_concat)\n",
    "        return value\n",
    "\n",
    "    def forward(self, x_card, x_state, legal_move_mask, action = None):\n",
    "        \"\"\"Get value, probability\n",
    "        legal_move_mask: boolean tensor\n",
    "        action: tensor(1) Integer. This is the old sampled action. If none will do sampling\n",
    "        \"\"\"\n",
    "        logit = self.get_policy(x_card, x_state, legal_move_mask)\n",
    "        prob = Categorical(logits = logit)\n",
    "        if action == None:\n",
    "            action = prob.sample() # sample the action\n",
    "        log_prob = prob.log_prob(action) # this will be used for surrogate loss (log(a) - log(b) = log(a/b))\n",
    "\n",
    "        value = self.get_value(x_card, x_state)\n",
    "        \n",
    "        return action, log_prob, prob.entropy(), value # sampled action, log probability of it, its entropy,value from value network\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1257888",
   "metadata": {},
   "source": [
    "# Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22836843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:24:54.382889Z",
     "iopub.status.busy": "2025-04-19T14:24:54.382306Z",
     "iopub.status.idle": "2025-04-19T14:24:54.491367Z",
     "shell.execute_reply": "2025-04-19T14:24:54.490645Z",
     "shell.execute_reply.started": "2025-04-19T14:24:54.382859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class nothanks_ppo(game):\n",
    "    def __init__(self, card = None):\n",
    "        super().__init__(card)\n",
    "        self.move_encode = {0: 'pass',\n",
    "                            1: 'take'\n",
    "                            }\n",
    "        \n",
    "    def rotate_player(self, turn):\n",
    "        player_list = list(range(self.n_player))\n",
    "        return player_list[turn:] + player_list[:turn]\n",
    "        \n",
    "        \n",
    "    def get_state(self):\n",
    "        # Get info about the state to save it\n",
    "        player_info = []\n",
    "        for player in self.players:\n",
    "            player_info.append((player.card, player.chip))\n",
    "        return player_info, self.turn, self.remain_card, self.chip_in_pot, self.current_card\n",
    "\n",
    "    def get_state_gen_3_5(self):\n",
    "        \"\"\"rotate player\"\"\"\n",
    "        player_info = []\n",
    "        player_list = self.rotate_player(self.turn)\n",
    "        for player_index in player_list:\n",
    "            player = self.players[player_index]\n",
    "            player_info.append((player.card, player.chip))\n",
    "        return player_info, self.turn, self.remain_card, self.chip_in_pot, self.current_card\n",
    "\n",
    "    def get_state_gen_4(self):\n",
    "        \"\"\"Rotate player + Collapse opponents\"\"\"\n",
    "        player_info = []\n",
    "        player_list = self.rotate_player(self.turn)\n",
    "\n",
    "        # self\n",
    "        player_index = player_list[0]\n",
    "        player = self.players[player_index]\n",
    "        player_info.append((player.card, player.chip))\n",
    "\n",
    "        #opponent\n",
    "        opponent_card = []\n",
    "        min_chip = 100\n",
    "        for player_index in player_list[1:]:\n",
    "            player = self.players[player_index]\n",
    "            opponent_card.extend(player.card)\n",
    "            if player.chip < min_chip:\n",
    "                min_chip = player.chip\n",
    "        player_info.append((opponent_card, min_chip))\n",
    "        return player_info, self.turn, self.remain_card, self.chip_in_pot, self.current_card\n",
    "        \n",
    "    \n",
    "    def encode_card(self, card_list: list) -> list:\n",
    "        \"\"\"Encode the card list to binaries\"\"\"\n",
    "        encode = [0]* len(self.full_deck)\n",
    "        for card in card_list:\n",
    "            encode[card - self.min_card] = 1\n",
    "        return encode\n",
    "    \n",
    "    # def encode_turn(self, turn) -> list:\n",
    "    #     return [1 if i == turn else 0 for i in range(self.n_player)]\n",
    "\n",
    "    def check_favorable_self(self):\n",
    "        player_tmp = self.players[self.turn]\n",
    "        if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def check_favorable_other(self):\n",
    "        other_player = [player_tmp for index, player_tmp in enumerate(self.players) if index != self.turn]\n",
    "        check = []\n",
    "        for player_tmp in other_player:\n",
    "            if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n",
    "                check.append(1)\n",
    "            else:\n",
    "                check.append(0)\n",
    "        return max(check)\n",
    "        \n",
    "    \n",
    "    def encode_state(self, func):\n",
    "        \"\"\"Feature engineering here\"\"\"\n",
    "        player_info, turn, remain_card, chip_in_pot, current_card = func()\n",
    "        result = []\n",
    "        for player_card, chip in player_info:\n",
    "            chip_tmp = chip/max(self.full_deck)\n",
    "            card_tmp = self.encode_card(player_card)\n",
    "            \n",
    "            result.extend(card_tmp)\n",
    "            result.append(chip_tmp)\n",
    "        \n",
    "        # result.extend(self.encode_turn(self.turn))\n",
    "        result.extend(self.encode_card([current_card]))\n",
    "        result.append(chip_in_pot/max(self.full_deck))\n",
    "        result.extend(self.encode_card(remain_card))\n",
    "        result.append((len(self.remain_card) - self.n_remove_card)/(len(self.full_deck) - self.n_remove_card))\n",
    "        result.append(self.check_favorable_self())\n",
    "\n",
    "        #new\n",
    "        result.append(self.check_favorable_other())\n",
    "        result.append(chip_in_pot/self.current_card)\n",
    "        # player_a, chip_a, ..., player_n, chip_n, turn, current_card, chip, remain_card, n_legal_remain_card, good card self, good card opponent, chip_in_pot/current_card\n",
    "        return result\n",
    "\n",
    "    def encode_state_gen_5(self):\n",
    "        \"\"\"Feature engineering here\"\"\"\n",
    "        # player_info, turn, remain_card, chip_in_pot, current_card = self.get_state()\n",
    "        player_info, turn, remain_card, chip_in_pot, current_card = self.get_state_gen_3_5()\n",
    "        \n",
    "\n",
    "        x_card = [self.encode_card(player_card) for player_card, _ in player_info]\n",
    "        x_card.append(self.encode_card([current_card]))\n",
    "        x_card.append(self.encode_card(remain_card))\n",
    "        \n",
    "        x_state = [chip/max(self.full_deck) for _, chip in player_info]\n",
    "        x_state.append(chip_in_pot/max(self.full_deck))\n",
    "        x_state.append((len(self.remain_card) - self.n_remove_card)/(len(self.full_deck) - self.n_remove_card))\n",
    "        x_state.append(self.check_favorable_self())\n",
    "        x_state.append(self.check_favorable_other())\n",
    "        x_state.append(chip_in_pot/self.current_card)\n",
    "        \n",
    "        # player_a, chip_a, ..., player_n, chip_n, turn, current_card, chip, remain_card, n_legal_remain_card, good card self, good card opponent, chip_in_pot/current_card\n",
    "        return x_card, x_state\n",
    "\n",
    "    \n",
    "    def calculate_reward_2(self, action):\n",
    "        player_tmp = self.players[self.turn]\n",
    "        \n",
    "        if action == 'pass':\n",
    "            # pass over half of the card value and the card is favorable is bad, punish for being too greedy\n",
    "            if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n",
    "                if self.chip_in_pot >= self.current_card//2:\n",
    "                    return -3\n",
    "            return -0.2  # light discouragement to avoid infinite pass\n",
    "    \n",
    "        if action == 'take':\n",
    "            \n",
    "            # Penalize taking too late or too early\n",
    "            if player_tmp.chip == 0:\n",
    "                return -2\n",
    "            if self.chip_in_pot == 0:\n",
    "                return -2\n",
    "                \n",
    "            reward = 0\n",
    "\n",
    "            # Reward for taking early in the game\n",
    "            if self.chip_in_pot < self.current_card and len(player_tmp.card) < 4:\n",
    "                reward += (self.chip_in_pot / (self.current_card + 1)) * 3\n",
    "    \n",
    "            # Encourage sequential cards\n",
    "            if any(abs(self.current_card - card_tmp) <= 3 for card_tmp in player_tmp.card):\n",
    "                reward += 2\n",
    "    \n",
    "            # Penalty for taking later in the game\n",
    "            distance_threshold = 4\n",
    "            if len(player_tmp.card) > 4:\n",
    "                dist = min(abs(self.current_card - c) for c in player_tmp.card)\n",
    "                if dist > distance_threshold:\n",
    "                    reward -= (dist - distance_threshold) * 0.5\n",
    "            return reward\n",
    "    \n",
    "    def calculate_reward_3(self, action):\n",
    "        return 0\n",
    "                \n",
    "    def reward_func(self, move):\n",
    "        return self.calculate_reward_3(move)\n",
    "                \n",
    "    def rollout(self, model, func, n_game = None):\n",
    "        \"\"\"Play games, save state\n",
    "        Need to get the turn\n",
    "        \"\"\"\n",
    "        random_chance = 0.99\n",
    "        # FIX: need to send 1 terminal state for each player:\n",
    "        playing_buffer = {i: [] for i in range(self.n_player)}\n",
    "        i = 0\n",
    "        while self.is_continue:\n",
    "            current_state = torch.tensor(self.encode_state(func)).to(device)\n",
    "            legal_move = self.get_legal_action() # a list \n",
    "            legal_move_mask = torch.tensor([False if move in legal_move else True for move in self.move_encode.values()]).to(device)\n",
    "            random_move = None\n",
    "            if random.random() > random_chance:\n",
    "                random_move = torch.tensor(random.choice([0 if move == 'pass' else 1 for move in legal_move])).to(device)\n",
    "            with torch.no_grad():\n",
    "                move_raw, log_prob, entropy, value = model.forward(current_state, legal_move_mask, random_move)\n",
    "            move = self.move_encode.get(move_raw.item())\n",
    "            reward = torch.tensor([self.reward_func(move)]).to(device)\n",
    "            playing_buffer[self.turn].append([current_state, move_raw, legal_move_mask, log_prob, value, reward]) # if this change, need to change the hard code\n",
    "            # move\n",
    "            self.is_continue = self.action(move)\n",
    "        final_reward = self.calculate_ranking()\n",
    "\n",
    "        for player in range(self.n_player):\n",
    "            playing_buffer[player].append([None, None, None, None, None, final_reward[player]])  # if this change, need to change the hard code\n",
    "            # playing_buffer[player].append([None, None, None, None, None, -self.players[player].calculate_score() ])  # if this change, need to change the hard code\n",
    "        return playing_buffer\n",
    "\n",
    "    def rollout_gen_5(self, model, n_game = None):\n",
    "        \"\"\"Play games, save state\n",
    "        Need to get the turn\n",
    "        \"\"\"\n",
    "        random_chance = 0.99\n",
    "        # FIX: need to send 1 terminal state for each player:\n",
    "        playing_buffer = {i: [] for i in range(self.n_player)}\n",
    "        i = 0\n",
    "        while self.is_continue:\n",
    "            \n",
    "            x_card, x_state = self.encode_state_gen_5()\n",
    "            # print(torch.Tensor(x_card).shape)\n",
    "            x_card = torch.Tensor(x_card).unsqueeze(1).to(device) #1 for 5,33 -> 5,1,33 | 0 for 5,1,33 -> 1,5,1,33\n",
    "            x_state = torch.tensor(x_state).to(device) # 8 to 1,8\n",
    "            # print(x_card.shape)\n",
    "            # print(x_state.shape)\n",
    "            legal_move = self.get_legal_action() # a list \n",
    "            legal_move_mask = torch.tensor([False if move in legal_move else True for move in self.move_encode.values()]).to(device)\n",
    "            # print(legal_move_mask.shape)\n",
    "            random_move = None\n",
    "            if random.random() > random_chance:\n",
    "                random_move = torch.tensor(random.choice([0 if move == 'pass' else 1 for move in legal_move])).to(device)\n",
    "            with torch.no_grad():\n",
    "                move_raw, log_prob, entropy, value = model.forward(x_card, x_state, legal_move_mask, random_move)\n",
    "            move = self.move_encode.get(move_raw.item())\n",
    "            reward = torch.tensor([self.reward_func(move)]).to(device)\n",
    "            playing_buffer[self.turn].append([x_card,x_state, move_raw, legal_move_mask, log_prob, value, reward]) # if this change, need to change the hard code\n",
    "            # move\n",
    "            self.is_continue = self.action(move)\n",
    "        final_reward = self.calculate_ranking()\n",
    "\n",
    "        for player in range(self.n_player):\n",
    "            playing_buffer[player].append([None, None, None, None, None, None, final_reward[player]])  # if this change, need to change the hard code\n",
    "            # playing_buffer[player].append([None, None, None, None, None, -self.players[player].calculate_score() ])  # if this change, need to change the hard code\n",
    "        return playing_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf9b07",
   "metadata": {},
   "source": [
    "# Calculate targets & create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e455da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:12:11.757281Z",
     "iopub.status.busy": "2025-04-19T13:12:11.756946Z",
     "iopub.status.idle": "2025-04-19T13:12:11.763786Z",
     "shell.execute_reply": "2025-04-19T13:12:11.762800Z",
     "shell.execute_reply.started": "2025-04-19T13:12:11.757256Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gen 4\n",
    "\n",
    "def create_training_data(play_buffer, gamma = 0.99, reward_index = -1):\n",
    "    \"\"\"\n",
    "    gamma: discount constant\n",
    "    reward_index: index of reward returned in the play buffer\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for _, player_data in play_buffer.items():\n",
    "        discounted_reward = player_data[-1][reward_index] # take the reward of the last stage. At the end of the game, all players receive 1 more step containing the final reward (final rank)\n",
    "        for index in reversed(range(len(player_data) - 1)): # go from back to front, skip the final step\n",
    "\n",
    "            state_tmp, move_tmp, legal_move_mask, log_prob_tmp, value_tmp, reward_tmp = player_data[index]\n",
    "            \n",
    "            # discounted reward\n",
    "            discounted_reward = reward_tmp + discounted_reward*gamma\n",
    "\n",
    "            #advantage\n",
    "            advantage_tmp = discounted_reward - value_tmp\n",
    "            # advantage_target = [advantage_tmp] + advantage_target # need to detach this at policy loss\n",
    "\n",
    "            # policy_old = [policy_tmp] + policy_old # need to detach this at policy loss\n",
    "            training_data.append([state_tmp, move_tmp, legal_move_mask, log_prob_tmp, advantage_tmp, discounted_reward]) #state, action, sampled action, advantage, discounted_reward (aka return)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "326a5b4a-200b-4eba-b1fb-05d386948757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:04.711132Z",
     "iopub.status.busy": "2025-04-19T14:25:04.710401Z",
     "iopub.status.idle": "2025-04-19T14:25:04.715990Z",
     "shell.execute_reply": "2025-04-19T14:25:04.715145Z",
     "shell.execute_reply.started": "2025-04-19T14:25:04.711098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gen 5\n",
    "def create_training_data_gen_5(play_buffer, gamma = 0.99, reward_index = -1):\n",
    "    \"\"\"\n",
    "    gamma: discount constant\n",
    "    reward_index: index of reward returned in the play buffer\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for _, player_data in play_buffer.items():\n",
    "        discounted_reward = player_data[-1][reward_index] # take the reward of the last stage. At the end of the game, all players receive 1 more step containing the final reward (final rank)\n",
    "        for index in reversed(range(len(player_data) - 1)): # go from back to front, skip the final step\n",
    "\n",
    "            x_card_tmp, x_state_tmp, move_tmp, legal_move_mask, log_prob_tmp, value_tmp, reward_tmp = player_data[index]\n",
    "            \n",
    "            # discounted reward\n",
    "            discounted_reward = reward_tmp + discounted_reward*gamma\n",
    "\n",
    "            #advantage\n",
    "            advantage_tmp = discounted_reward - value_tmp\n",
    "            # advantage_target = [advantage_tmp] + advantage_target # need to detach this at policy loss\n",
    "\n",
    "            # policy_old = [policy_tmp] + policy_old # need to detach this at policy loss\n",
    "            training_data.append([x_card_tmp, x_state_tmp, move_tmp, legal_move_mask, log_prob_tmp, advantage_tmp, discounted_reward]) #state, action, sampled action, advantage, discounted_reward (aka return)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09062f4",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11afd372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:11.056561Z",
     "iopub.status.busy": "2025-04-19T14:25:11.056301Z",
     "iopub.status.idle": "2025-04-19T14:25:11.060775Z",
     "shell.execute_reply": "2025-04-19T14:25:11.060102Z",
     "shell.execute_reply.started": "2025-04-19T14:25:11.056541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b299655d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:11.158941Z",
     "iopub.status.busy": "2025-04-19T14:25:11.158363Z",
     "iopub.status.idle": "2025-04-19T14:25:11.162512Z",
     "shell.execute_reply": "2025-04-19T14:25:11.161883Z",
     "shell.execute_reply.started": "2025-04-19T14:25:11.158922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch_data):\n",
    "    result = []\n",
    "    for index, item in enumerate(zip(*batch_data)):\n",
    "        # result.append(torch.stack(item).unsqueeze(dim = 1))\n",
    "        result.append(torch.stack(item))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "731b7a50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:59:00.730931Z",
     "iopub.status.busy": "2025-04-19T13:59:00.730598Z",
     "iopub.status.idle": "2025-04-19T13:59:00.735483Z",
     "shell.execute_reply": "2025-04-19T13:59:00.734535Z",
     "shell.execute_reply.started": "2025-04-19T13:59:00.730909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 4,\n",
    "          'shuffle': True,\n",
    "          'collate_fn': collate_fn\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958f39a",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd3a2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIAL = 10\n",
    "N_CYCLE = 20\n",
    "N_PLAYER = 3\n",
    "BATCH_SIZE = 64\n",
    "DATA_LENGTH = 5000\n",
    "N_EPOCH = 4\n",
    "GEN = 5\n",
    "LEARNING_RATE_list = [2e-4, 5e-4, 7e-4, 1e-3]\n",
    "e_list = [0.1, 0.2, 0.3] #clipping constant\n",
    "value_coef_list = [0.5, 0.6, 0.7]\n",
    "entropy_coef_list = [0.01, 0.02, 0.03]\n",
    "param_list = [LEARNING_RATE_list, e_list, value_coef_list, entropy_coef_list]\n",
    "param_record = []\n",
    "randomized_record = []\n",
    "\n",
    "dataloader_params = {'batch_size': BATCH_SIZE,\n",
    "          'shuffle': True,\n",
    "          'drop_last': True, # drop the last batch where the size could be 1\n",
    "          'collate_fn': collate_fn\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08cea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.0005 | e: 0.1 | value_coef: 0.5 | entropy_coef: 0.03\n",
      "-------------CYCLE: 0-------------\n",
      "game length: 50.0\n",
      "tensor(-0.3953, grad_fn=<NegBackward0>) tensor(0.3444, grad_fn=<MeanBackward0>) tensor(0.6926, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4269, grad_fn=<NegBackward0>) tensor(0.2662, grad_fn=<MeanBackward0>) tensor(0.6900, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4161, grad_fn=<NegBackward0>) tensor(0.2455, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3757, grad_fn=<NegBackward0>) tensor(0.1869, grad_fn=<MeanBackward0>) tensor(0.6850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4951, grad_fn=<NegBackward0>) tensor(0.1822, grad_fn=<MeanBackward0>) tensor(0.6839, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4704, grad_fn=<NegBackward0>) tensor(0.1428, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4222, grad_fn=<NegBackward0>) tensor(0.1682, grad_fn=<MeanBackward0>) tensor(0.6857, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5345, grad_fn=<NegBackward0>) tensor(0.1428, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3702, grad_fn=<NegBackward0>) tensor(0.2469, grad_fn=<MeanBackward0>) tensor(0.6841, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4377, grad_fn=<NegBackward0>) tensor(0.2260, grad_fn=<MeanBackward0>) tensor(0.6840, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4314, grad_fn=<NegBackward0>) tensor(0.2145, grad_fn=<MeanBackward0>) tensor(0.6841, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4640, grad_fn=<NegBackward0>) tensor(0.1810, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4705, grad_fn=<NegBackward0>) tensor(0.1868, grad_fn=<MeanBackward0>) tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4616, grad_fn=<NegBackward0>) tensor(0.1579, grad_fn=<MeanBackward0>) tensor(0.6883, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4835, grad_fn=<NegBackward0>) tensor(0.1976, grad_fn=<MeanBackward0>) tensor(0.6889, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3893, grad_fn=<NegBackward0>) tensor(0.1315, grad_fn=<MeanBackward0>) tensor(0.6888, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4077, grad_fn=<NegBackward0>) tensor(0.1864, grad_fn=<MeanBackward0>) tensor(0.6882, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4419, grad_fn=<NegBackward0>) tensor(0.1703, grad_fn=<MeanBackward0>) tensor(0.6872, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4846, grad_fn=<NegBackward0>) tensor(0.1643, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4751, grad_fn=<NegBackward0>) tensor(0.2154, grad_fn=<MeanBackward0>) tensor(0.6822, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3386, grad_fn=<NegBackward0>) tensor(0.1669, grad_fn=<MeanBackward0>) tensor(0.6819, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4899, grad_fn=<NegBackward0>) tensor(0.1791, grad_fn=<MeanBackward0>) tensor(0.6824, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3361, grad_fn=<NegBackward0>) tensor(0.1785, grad_fn=<MeanBackward0>) tensor(0.6839, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4175, grad_fn=<NegBackward0>) tensor(0.1650, grad_fn=<MeanBackward0>) tensor(0.6857, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3987, grad_fn=<NegBackward0>) tensor(0.1888, grad_fn=<MeanBackward0>) tensor(0.6869, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4293, grad_fn=<NegBackward0>) tensor(0.1675, grad_fn=<MeanBackward0>) tensor(0.6880, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3679, grad_fn=<NegBackward0>) tensor(0.1386, grad_fn=<MeanBackward0>) tensor(0.6890, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3639, grad_fn=<NegBackward0>) tensor(0.1740, grad_fn=<MeanBackward0>) tensor(0.6895, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3664, grad_fn=<NegBackward0>) tensor(0.1442, grad_fn=<MeanBackward0>) tensor(0.6902, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3824, grad_fn=<NegBackward0>) tensor(0.1568, grad_fn=<MeanBackward0>) tensor(0.6906, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4101, grad_fn=<NegBackward0>) tensor(0.1692, grad_fn=<MeanBackward0>) tensor(0.6905, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4110, grad_fn=<NegBackward0>) tensor(0.1499, grad_fn=<MeanBackward0>) tensor(0.6902, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4211, grad_fn=<NegBackward0>) tensor(0.1660, grad_fn=<MeanBackward0>) tensor(0.6895, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4480, grad_fn=<NegBackward0>) tensor(0.1662, grad_fn=<MeanBackward0>) tensor(0.6887, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4141, grad_fn=<NegBackward0>) tensor(0.1425, grad_fn=<MeanBackward0>) tensor(0.6877, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3804, grad_fn=<NegBackward0>) tensor(0.1538, grad_fn=<MeanBackward0>) tensor(0.6872, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4374, grad_fn=<NegBackward0>) tensor(0.2024, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4623, grad_fn=<NegBackward0>) tensor(0.1775, grad_fn=<MeanBackward0>) tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3655, grad_fn=<NegBackward0>) tensor(0.1404, grad_fn=<MeanBackward0>) tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4093, grad_fn=<NegBackward0>) tensor(0.1404, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4697, grad_fn=<NegBackward0>) tensor(0.1672, grad_fn=<MeanBackward0>) tensor(0.6835, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3830, grad_fn=<NegBackward0>) tensor(0.1435, grad_fn=<MeanBackward0>) tensor(0.6838, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3939, grad_fn=<NegBackward0>) tensor(0.1582, grad_fn=<MeanBackward0>) tensor(0.6838, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4640, grad_fn=<NegBackward0>) tensor(0.1665, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4904, grad_fn=<NegBackward0>) tensor(0.1612, grad_fn=<MeanBackward0>) tensor(0.6855, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4651, grad_fn=<NegBackward0>) tensor(0.1489, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4835, grad_fn=<NegBackward0>) tensor(0.1440, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4155, grad_fn=<NegBackward0>) tensor(0.1648, grad_fn=<MeanBackward0>) tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4883, grad_fn=<NegBackward0>) tensor(0.1584, grad_fn=<MeanBackward0>) tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5326, grad_fn=<NegBackward0>) tensor(0.1614, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4445, grad_fn=<NegBackward0>) tensor(0.1594, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4515, grad_fn=<NegBackward0>) tensor(0.1501, grad_fn=<MeanBackward0>) tensor(0.6839, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3880, grad_fn=<NegBackward0>) tensor(0.1592, grad_fn=<MeanBackward0>) tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4409, grad_fn=<NegBackward0>) tensor(0.1554, grad_fn=<MeanBackward0>) tensor(0.6850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4628, grad_fn=<NegBackward0>) tensor(0.1695, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4435, grad_fn=<NegBackward0>) tensor(0.1527, grad_fn=<MeanBackward0>) tensor(0.6840, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5256, grad_fn=<NegBackward0>) tensor(0.1802, grad_fn=<MeanBackward0>) tensor(0.6840, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4093, grad_fn=<NegBackward0>) tensor(0.1344, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4484, grad_fn=<NegBackward0>) tensor(0.1640, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4543, grad_fn=<NegBackward0>) tensor(0.1546, grad_fn=<MeanBackward0>) tensor(0.6849, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4856, grad_fn=<NegBackward0>) tensor(0.1577, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4813, grad_fn=<NegBackward0>) tensor(0.1392, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4146, grad_fn=<NegBackward0>) tensor(0.1406, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4624, grad_fn=<NegBackward0>) tensor(0.1273, grad_fn=<MeanBackward0>) tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4656, grad_fn=<NegBackward0>) tensor(0.1312, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4823, grad_fn=<NegBackward0>) tensor(0.1215, grad_fn=<MeanBackward0>) tensor(0.6842, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4556, grad_fn=<NegBackward0>) tensor(0.1302, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4150, grad_fn=<NegBackward0>) tensor(0.1167, grad_fn=<MeanBackward0>) tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4141, grad_fn=<NegBackward0>) tensor(0.1148, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4026, grad_fn=<NegBackward0>) tensor(0.1374, grad_fn=<MeanBackward0>) tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5049, grad_fn=<NegBackward0>) tensor(0.1318, grad_fn=<MeanBackward0>) tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3969, grad_fn=<NegBackward0>) tensor(0.1111, grad_fn=<MeanBackward0>) tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3740, grad_fn=<NegBackward0>) tensor(0.1350, grad_fn=<MeanBackward0>) tensor(0.6873, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4316, grad_fn=<NegBackward0>) tensor(0.1292, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3789, grad_fn=<NegBackward0>) tensor(0.1226, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4126, grad_fn=<NegBackward0>) tensor(0.1194, grad_fn=<MeanBackward0>) tensor(0.6858, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3591, grad_fn=<NegBackward0>) tensor(0.0923, grad_fn=<MeanBackward0>) tensor(0.6848, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5135, grad_fn=<NegBackward0>) tensor(0.1361, grad_fn=<MeanBackward0>) tensor(0.6852, grad_fn=<MeanBackward0>)\n",
      "Epoch: 0 - loss: -0.38\n",
      "tensor(-0.4622, grad_fn=<NegBackward0>) tensor(0.1267, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4531, grad_fn=<NegBackward0>) tensor(0.1305, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4411, grad_fn=<NegBackward0>) tensor(0.1356, grad_fn=<MeanBackward0>) tensor(0.6838, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4180, grad_fn=<NegBackward0>) tensor(0.1145, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3819, grad_fn=<NegBackward0>) tensor(0.1151, grad_fn=<MeanBackward0>) tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5550, grad_fn=<NegBackward0>) tensor(0.1230, grad_fn=<MeanBackward0>) tensor(0.6848, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5995, grad_fn=<NegBackward0>) tensor(0.1128, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3559, grad_fn=<NegBackward0>) tensor(0.1283, grad_fn=<MeanBackward0>) tensor(0.6842, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4500, grad_fn=<NegBackward0>) tensor(0.1218, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4802, grad_fn=<NegBackward0>) tensor(0.1267, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4802, grad_fn=<NegBackward0>) tensor(0.1159, grad_fn=<MeanBackward0>) tensor(0.6849, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4236, grad_fn=<NegBackward0>) tensor(0.0703, grad_fn=<MeanBackward0>) tensor(0.6849, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4051, grad_fn=<NegBackward0>) tensor(0.0982, grad_fn=<MeanBackward0>) tensor(0.6852, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4386, grad_fn=<NegBackward0>) tensor(0.0944, grad_fn=<MeanBackward0>) tensor(0.6855, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4257, grad_fn=<NegBackward0>) tensor(0.1198, grad_fn=<MeanBackward0>) tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4034, grad_fn=<NegBackward0>) tensor(0.0999, grad_fn=<MeanBackward0>) tensor(0.6848, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4160, grad_fn=<NegBackward0>) tensor(0.0883, grad_fn=<MeanBackward0>) tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5052, grad_fn=<NegBackward0>) tensor(0.1027, grad_fn=<MeanBackward0>) tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3750, grad_fn=<NegBackward0>) tensor(0.1093, grad_fn=<MeanBackward0>) tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4156, grad_fn=<NegBackward0>) tensor(0.0848, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3514, grad_fn=<NegBackward0>) tensor(0.1044, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3925, grad_fn=<NegBackward0>) tensor(0.1195, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4474, grad_fn=<NegBackward0>) tensor(0.1108, grad_fn=<MeanBackward0>) tensor(0.6862, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3811, grad_fn=<NegBackward0>) tensor(0.1004, grad_fn=<MeanBackward0>) tensor(0.6855, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4545, grad_fn=<NegBackward0>) tensor(0.1027, grad_fn=<MeanBackward0>) tensor(0.6846, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3867, grad_fn=<NegBackward0>) tensor(0.1087, grad_fn=<MeanBackward0>) tensor(0.6842, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4565, grad_fn=<NegBackward0>) tensor(0.1056, grad_fn=<MeanBackward0>) tensor(0.6850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3613, grad_fn=<NegBackward0>) tensor(0.1169, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3469, grad_fn=<NegBackward0>) tensor(0.1109, grad_fn=<MeanBackward0>) tensor(0.6867, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3984, grad_fn=<NegBackward0>) tensor(0.1146, grad_fn=<MeanBackward0>) tensor(0.6872, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3864, grad_fn=<NegBackward0>) tensor(0.0861, grad_fn=<MeanBackward0>) tensor(0.6878, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4784, grad_fn=<NegBackward0>) tensor(0.1052, grad_fn=<MeanBackward0>) tensor(0.6883, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4899, grad_fn=<NegBackward0>) tensor(0.0862, grad_fn=<MeanBackward0>) tensor(0.6883, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3638, grad_fn=<NegBackward0>) tensor(0.1030, grad_fn=<MeanBackward0>) tensor(0.6879, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4501, grad_fn=<NegBackward0>) tensor(0.1089, grad_fn=<MeanBackward0>) tensor(0.6868, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5140, grad_fn=<NegBackward0>) tensor(0.0902, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3368, grad_fn=<NegBackward0>) tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.6837, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4958, grad_fn=<NegBackward0>) tensor(0.1042, grad_fn=<MeanBackward0>) tensor(0.6829, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4589, grad_fn=<NegBackward0>) tensor(0.0941, grad_fn=<MeanBackward0>) tensor(0.6835, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4903, grad_fn=<NegBackward0>) tensor(0.1083, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3975, grad_fn=<NegBackward0>) tensor(0.1153, grad_fn=<MeanBackward0>) tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4007, grad_fn=<NegBackward0>) tensor(0.1293, grad_fn=<MeanBackward0>) tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3659, grad_fn=<NegBackward0>) tensor(0.0915, grad_fn=<MeanBackward0>) tensor(0.6868, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3798, grad_fn=<NegBackward0>) tensor(0.0810, grad_fn=<MeanBackward0>) tensor(0.6880, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4736, grad_fn=<NegBackward0>) tensor(0.0946, grad_fn=<MeanBackward0>) tensor(0.6885, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4618, grad_fn=<NegBackward0>) tensor(0.1041, grad_fn=<MeanBackward0>) tensor(0.6892, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4435, grad_fn=<NegBackward0>) tensor(0.0925, grad_fn=<MeanBackward0>) tensor(0.6896, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4309, grad_fn=<NegBackward0>) tensor(0.0942, grad_fn=<MeanBackward0>) tensor(0.6894, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4455, grad_fn=<NegBackward0>) tensor(0.1175, grad_fn=<MeanBackward0>) tensor(0.6895, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4464, grad_fn=<NegBackward0>) tensor(0.1116, grad_fn=<MeanBackward0>) tensor(0.6894, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4866, grad_fn=<NegBackward0>) tensor(0.0683, grad_fn=<MeanBackward0>) tensor(0.6890, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4776, grad_fn=<NegBackward0>) tensor(0.0738, grad_fn=<MeanBackward0>) tensor(0.6882, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4780, grad_fn=<NegBackward0>) tensor(0.1223, grad_fn=<MeanBackward0>) tensor(0.6873, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5127, grad_fn=<NegBackward0>) tensor(0.0954, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4616, grad_fn=<NegBackward0>) tensor(0.1053, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4540, grad_fn=<NegBackward0>) tensor(0.1121, grad_fn=<MeanBackward0>) tensor(0.6833, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4101, grad_fn=<NegBackward0>) tensor(0.1170, grad_fn=<MeanBackward0>) tensor(0.6831, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4662, grad_fn=<NegBackward0>) tensor(0.0926, grad_fn=<MeanBackward0>) tensor(0.6835, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3807, grad_fn=<NegBackward0>) tensor(0.1018, grad_fn=<MeanBackward0>) tensor(0.6840, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4158, grad_fn=<NegBackward0>) tensor(0.0853, grad_fn=<MeanBackward0>) tensor(0.6855, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3832, grad_fn=<NegBackward0>) tensor(0.1015, grad_fn=<MeanBackward0>) tensor(0.6857, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3982, grad_fn=<NegBackward0>) tensor(0.1178, grad_fn=<MeanBackward0>) tensor(0.6869, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4846, grad_fn=<NegBackward0>) tensor(0.1250, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3908, grad_fn=<NegBackward0>) tensor(0.1062, grad_fn=<MeanBackward0>) tensor(0.6866, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5825, grad_fn=<NegBackward0>) tensor(0.0900, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4588, grad_fn=<NegBackward0>) tensor(0.1012, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5025, grad_fn=<NegBackward0>) tensor(0.1237, grad_fn=<MeanBackward0>) tensor(0.6848, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3402, grad_fn=<NegBackward0>) tensor(0.1384, grad_fn=<MeanBackward0>) tensor(0.6836, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5193, grad_fn=<NegBackward0>) tensor(0.0707, grad_fn=<MeanBackward0>) tensor(0.6828, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2633, grad_fn=<NegBackward0>) tensor(0.0980, grad_fn=<MeanBackward0>) tensor(0.6822, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4925, grad_fn=<NegBackward0>) tensor(0.0897, grad_fn=<MeanBackward0>) tensor(0.6822, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4125, grad_fn=<NegBackward0>) tensor(0.0990, grad_fn=<MeanBackward0>) tensor(0.6830, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4655, grad_fn=<NegBackward0>) tensor(0.1311, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4017, grad_fn=<NegBackward0>) tensor(0.0839, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4327, grad_fn=<NegBackward0>) tensor(0.0766, grad_fn=<MeanBackward0>) tensor(0.6866, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3536, grad_fn=<NegBackward0>) tensor(0.1076, grad_fn=<MeanBackward0>) tensor(0.6870, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4376, grad_fn=<NegBackward0>) tensor(0.1070, grad_fn=<MeanBackward0>) tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4378, grad_fn=<NegBackward0>) tensor(0.0891, grad_fn=<MeanBackward0>) tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "Epoch: 1 - loss: -0.41\n",
      "tensor(-0.4720, grad_fn=<NegBackward0>) tensor(0.0971, grad_fn=<MeanBackward0>) tensor(0.6873, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5028, grad_fn=<NegBackward0>) tensor(0.0867, grad_fn=<MeanBackward0>) tensor(0.6870, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3536, grad_fn=<NegBackward0>) tensor(0.0725, grad_fn=<MeanBackward0>) tensor(0.6868, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4177, grad_fn=<NegBackward0>) tensor(0.0646, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3494, grad_fn=<NegBackward0>) tensor(0.0939, grad_fn=<MeanBackward0>) tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4103, grad_fn=<NegBackward0>) tensor(0.1121, grad_fn=<MeanBackward0>) tensor(0.6838, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3576, grad_fn=<NegBackward0>) tensor(0.0809, grad_fn=<MeanBackward0>) tensor(0.6837, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4461, grad_fn=<NegBackward0>) tensor(0.1091, grad_fn=<MeanBackward0>) tensor(0.6835, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4025, grad_fn=<NegBackward0>) tensor(0.0931, grad_fn=<MeanBackward0>) tensor(0.6840, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3465, grad_fn=<NegBackward0>) tensor(0.1020, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4841, grad_fn=<NegBackward0>) tensor(0.0767, grad_fn=<MeanBackward0>) tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3893, grad_fn=<NegBackward0>) tensor(0.0824, grad_fn=<MeanBackward0>) tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4256, grad_fn=<NegBackward0>) tensor(0.1025, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4429, grad_fn=<NegBackward0>) tensor(0.0809, grad_fn=<MeanBackward0>) tensor(0.6866, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4190, grad_fn=<NegBackward0>) tensor(0.0985, grad_fn=<MeanBackward0>) tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5651, grad_fn=<NegBackward0>) tensor(0.0857, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3808, grad_fn=<NegBackward0>) tensor(0.0822, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3609, grad_fn=<NegBackward0>) tensor(0.0868, grad_fn=<MeanBackward0>) tensor(0.6858, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4262, grad_fn=<NegBackward0>) tensor(0.0570, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4813, grad_fn=<NegBackward0>) tensor(0.1080, grad_fn=<MeanBackward0>) tensor(0.6857, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4613, grad_fn=<NegBackward0>) tensor(0.0965, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4946, grad_fn=<NegBackward0>) tensor(0.1021, grad_fn=<MeanBackward0>) tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3645, grad_fn=<NegBackward0>) tensor(0.0831, grad_fn=<MeanBackward0>) tensor(0.6842, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3668, grad_fn=<NegBackward0>) tensor(0.0941, grad_fn=<MeanBackward0>) tensor(0.6842, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4382, grad_fn=<NegBackward0>) tensor(0.0828, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4387, grad_fn=<NegBackward0>) tensor(0.0927, grad_fn=<MeanBackward0>) tensor(0.6852, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4285, grad_fn=<NegBackward0>) tensor(0.0793, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4477, grad_fn=<NegBackward0>) tensor(0.0779, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5016, grad_fn=<NegBackward0>) tensor(0.0849, grad_fn=<MeanBackward0>) tensor(0.6870, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3514, grad_fn=<NegBackward0>) tensor(0.1001, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4933, grad_fn=<NegBackward0>) tensor(0.0864, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4438, grad_fn=<NegBackward0>) tensor(0.0567, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5052, grad_fn=<NegBackward0>) tensor(0.1019, grad_fn=<MeanBackward0>) tensor(0.6853, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4439, grad_fn=<NegBackward0>) tensor(0.0690, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4671, grad_fn=<NegBackward0>) tensor(0.0671, grad_fn=<MeanBackward0>) tensor(0.6839, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3499, grad_fn=<NegBackward0>) tensor(0.0722, grad_fn=<MeanBackward0>) tensor(0.6841, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4515, grad_fn=<NegBackward0>) tensor(0.0978, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4451, grad_fn=<NegBackward0>) tensor(0.0856, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4903, grad_fn=<NegBackward0>) tensor(0.0807, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4963, grad_fn=<NegBackward0>) tensor(0.0968, grad_fn=<MeanBackward0>) tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4899, grad_fn=<NegBackward0>) tensor(0.0788, grad_fn=<MeanBackward0>) tensor(0.6855, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4500, grad_fn=<NegBackward0>) tensor(0.0871, grad_fn=<MeanBackward0>) tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4657, grad_fn=<NegBackward0>) tensor(0.0983, grad_fn=<MeanBackward0>) tensor(0.6849, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3665, grad_fn=<NegBackward0>) tensor(0.0878, grad_fn=<MeanBackward0>) tensor(0.6852, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4395, grad_fn=<NegBackward0>) tensor(0.0818, grad_fn=<MeanBackward0>) tensor(0.6849, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5039, grad_fn=<NegBackward0>) tensor(0.1142, grad_fn=<MeanBackward0>) tensor(0.6850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4922, grad_fn=<NegBackward0>) tensor(0.0879, grad_fn=<MeanBackward0>) tensor(0.6852, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2792, grad_fn=<NegBackward0>) tensor(0.0693, grad_fn=<MeanBackward0>) tensor(0.6853, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4211, grad_fn=<NegBackward0>) tensor(0.0721, grad_fn=<MeanBackward0>) tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3661, grad_fn=<NegBackward0>) tensor(0.0928, grad_fn=<MeanBackward0>) tensor(0.6858, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4931, grad_fn=<NegBackward0>) tensor(0.0856, grad_fn=<MeanBackward0>) tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4681, grad_fn=<NegBackward0>) tensor(0.0811, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4276, grad_fn=<NegBackward0>) tensor(0.0845, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4660, grad_fn=<NegBackward0>) tensor(0.0868, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4715, grad_fn=<NegBackward0>) tensor(0.0755, grad_fn=<MeanBackward0>) tensor(0.6868, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3604, grad_fn=<NegBackward0>) tensor(0.0980, grad_fn=<MeanBackward0>) tensor(0.6870, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4064, grad_fn=<NegBackward0>) tensor(0.0642, grad_fn=<MeanBackward0>) tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4271, grad_fn=<NegBackward0>) tensor(0.0755, grad_fn=<MeanBackward0>) tensor(0.6876, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4637, grad_fn=<NegBackward0>) tensor(0.0753, grad_fn=<MeanBackward0>) tensor(0.6881, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4177, grad_fn=<NegBackward0>) tensor(0.0945, grad_fn=<MeanBackward0>) tensor(0.6887, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4104, grad_fn=<NegBackward0>) tensor(0.0918, grad_fn=<MeanBackward0>) tensor(0.6888, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4576, grad_fn=<NegBackward0>) tensor(0.0723, grad_fn=<MeanBackward0>) tensor(0.6892, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4604, grad_fn=<NegBackward0>) tensor(0.0981, grad_fn=<MeanBackward0>) tensor(0.6892, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5107, grad_fn=<NegBackward0>) tensor(0.0870, grad_fn=<MeanBackward0>) tensor(0.6891, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3927, grad_fn=<NegBackward0>) tensor(0.0857, grad_fn=<MeanBackward0>) tensor(0.6889, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3645, grad_fn=<NegBackward0>) tensor(0.0870, grad_fn=<MeanBackward0>) tensor(0.6882, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4043, grad_fn=<NegBackward0>) tensor(0.0896, grad_fn=<MeanBackward0>) tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4658, grad_fn=<NegBackward0>) tensor(0.0815, grad_fn=<MeanBackward0>) tensor(0.6862, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4915, grad_fn=<NegBackward0>) tensor(0.0899, grad_fn=<MeanBackward0>) tensor(0.6850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4962, grad_fn=<NegBackward0>) tensor(0.0887, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4027, grad_fn=<NegBackward0>) tensor(0.0650, grad_fn=<MeanBackward0>) tensor(0.6846, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3735, grad_fn=<NegBackward0>) tensor(0.0750, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4444, grad_fn=<NegBackward0>) tensor(0.0796, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3887, grad_fn=<NegBackward0>) tensor(0.0885, grad_fn=<MeanBackward0>) tensor(0.6853, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4504, grad_fn=<NegBackward0>) tensor(0.0890, grad_fn=<MeanBackward0>) tensor(0.6855, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4596, grad_fn=<NegBackward0>) tensor(0.0943, grad_fn=<MeanBackward0>) tensor(0.6862, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5777, grad_fn=<NegBackward0>) tensor(0.0782, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3979, grad_fn=<NegBackward0>) tensor(0.0805, grad_fn=<MeanBackward0>) tensor(0.6857, grad_fn=<MeanBackward0>)\n",
      "Epoch: 2 - loss: -0.42\n",
      "tensor(-0.4170, grad_fn=<NegBackward0>) tensor(0.0687, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4039, grad_fn=<NegBackward0>) tensor(0.0685, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4158, grad_fn=<NegBackward0>) tensor(0.0643, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3440, grad_fn=<NegBackward0>) tensor(0.0575, grad_fn=<MeanBackward0>) tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3848, grad_fn=<NegBackward0>) tensor(0.0824, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5042, grad_fn=<NegBackward0>) tensor(0.1212, grad_fn=<MeanBackward0>) tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5358, grad_fn=<NegBackward0>) tensor(0.1000, grad_fn=<MeanBackward0>) tensor(0.6880, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4801, grad_fn=<NegBackward0>) tensor(0.0972, grad_fn=<MeanBackward0>) tensor(0.6886, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4257, grad_fn=<NegBackward0>) tensor(0.0787, grad_fn=<MeanBackward0>) tensor(0.6883, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4654, grad_fn=<NegBackward0>) tensor(0.0986, grad_fn=<MeanBackward0>) tensor(0.6882, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4775, grad_fn=<NegBackward0>) tensor(0.0764, grad_fn=<MeanBackward0>) tensor(0.6875, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4072, grad_fn=<NegBackward0>) tensor(0.0651, grad_fn=<MeanBackward0>) tensor(0.6867, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4120, grad_fn=<NegBackward0>) tensor(0.0595, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4737, grad_fn=<NegBackward0>) tensor(0.0756, grad_fn=<MeanBackward0>) tensor(0.6850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5097, grad_fn=<NegBackward0>) tensor(0.0929, grad_fn=<MeanBackward0>) tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4637, grad_fn=<NegBackward0>) tensor(0.0857, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5190, grad_fn=<NegBackward0>) tensor(0.0716, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4919, grad_fn=<NegBackward0>) tensor(0.0881, grad_fn=<MeanBackward0>) tensor(0.6862, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5632, grad_fn=<NegBackward0>) tensor(0.0900, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4708, grad_fn=<NegBackward0>) tensor(0.0709, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4012, grad_fn=<NegBackward0>) tensor(0.0662, grad_fn=<MeanBackward0>) tensor(0.6865, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4384, grad_fn=<NegBackward0>) tensor(0.0811, grad_fn=<MeanBackward0>) tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4178, grad_fn=<NegBackward0>) tensor(0.0860, grad_fn=<MeanBackward0>) tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4341, grad_fn=<NegBackward0>) tensor(0.1168, grad_fn=<MeanBackward0>) tensor(0.6855, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3781, grad_fn=<NegBackward0>) tensor(0.0759, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3331, grad_fn=<NegBackward0>) tensor(0.0672, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5081, grad_fn=<NegBackward0>) tensor(0.0680, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4553, grad_fn=<NegBackward0>) tensor(0.0775, grad_fn=<MeanBackward0>) tensor(0.6861, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3968, grad_fn=<NegBackward0>) tensor(0.0701, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4221, grad_fn=<NegBackward0>) tensor(0.0814, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4347, grad_fn=<NegBackward0>) tensor(0.0874, grad_fn=<MeanBackward0>) tensor(0.6843, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5545, grad_fn=<NegBackward0>) tensor(0.0683, grad_fn=<MeanBackward0>) tensor(0.6842, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4189, grad_fn=<NegBackward0>) tensor(0.0600, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5149, grad_fn=<NegBackward0>) tensor(0.0782, grad_fn=<MeanBackward0>) tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4073, grad_fn=<NegBackward0>) tensor(0.0674, grad_fn=<MeanBackward0>) tensor(0.6852, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3765, grad_fn=<NegBackward0>) tensor(0.0701, grad_fn=<MeanBackward0>) tensor(0.6857, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5020, grad_fn=<NegBackward0>) tensor(0.0790, grad_fn=<MeanBackward0>) tensor(0.6857, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3439, grad_fn=<NegBackward0>) tensor(0.0703, grad_fn=<MeanBackward0>) tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3789, grad_fn=<NegBackward0>) tensor(0.0716, grad_fn=<MeanBackward0>) tensor(0.6847, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4049, grad_fn=<NegBackward0>) tensor(0.0857, grad_fn=<MeanBackward0>) tensor(0.6838, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3640, grad_fn=<NegBackward0>) tensor(0.0482, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4311, grad_fn=<NegBackward0>) tensor(0.0601, grad_fn=<MeanBackward0>) tensor(0.6862, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4085, grad_fn=<NegBackward0>) tensor(0.0681, grad_fn=<MeanBackward0>) tensor(0.6875, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4511, grad_fn=<NegBackward0>) tensor(0.0785, grad_fn=<MeanBackward0>) tensor(0.6881, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5635, grad_fn=<NegBackward0>) tensor(0.0612, grad_fn=<MeanBackward0>) tensor(0.6890, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4251, grad_fn=<NegBackward0>) tensor(0.0736, grad_fn=<MeanBackward0>) tensor(0.6898, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4136, grad_fn=<NegBackward0>) tensor(0.0855, grad_fn=<MeanBackward0>) tensor(0.6902, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3589, grad_fn=<NegBackward0>) tensor(0.1100, grad_fn=<MeanBackward0>) tensor(0.6904, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4883, grad_fn=<NegBackward0>) tensor(0.0868, grad_fn=<MeanBackward0>) tensor(0.6907, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3831, grad_fn=<NegBackward0>) tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.6910, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4346, grad_fn=<NegBackward0>) tensor(0.0680, grad_fn=<MeanBackward0>) tensor(0.6908, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4250, grad_fn=<NegBackward0>) tensor(0.0640, grad_fn=<MeanBackward0>) tensor(0.6905, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4070, grad_fn=<NegBackward0>) tensor(0.0729, grad_fn=<MeanBackward0>) tensor(0.6904, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3703, grad_fn=<NegBackward0>) tensor(0.0659, grad_fn=<MeanBackward0>) tensor(0.6909, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4376, grad_fn=<NegBackward0>) tensor(0.0572, grad_fn=<MeanBackward0>) tensor(0.6906, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4646, grad_fn=<NegBackward0>) tensor(0.0740, grad_fn=<MeanBackward0>) tensor(0.6900, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5095, grad_fn=<NegBackward0>) tensor(0.0784, grad_fn=<MeanBackward0>) tensor(0.6899, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4837, grad_fn=<NegBackward0>) tensor(0.0652, grad_fn=<MeanBackward0>) tensor(0.6880, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3928, grad_fn=<NegBackward0>) tensor(0.0732, grad_fn=<MeanBackward0>) tensor(0.6862, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4589, grad_fn=<NegBackward0>) tensor(0.0773, grad_fn=<MeanBackward0>) tensor(0.6835, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4512, grad_fn=<NegBackward0>) tensor(0.0918, grad_fn=<MeanBackward0>) tensor(0.6828, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4970, grad_fn=<NegBackward0>) tensor(0.0732, grad_fn=<MeanBackward0>) tensor(0.6815, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4044, grad_fn=<NegBackward0>) tensor(0.0663, grad_fn=<MeanBackward0>) tensor(0.6814, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3631, grad_fn=<NegBackward0>) tensor(0.0537, grad_fn=<MeanBackward0>) tensor(0.6817, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4667, grad_fn=<NegBackward0>) tensor(0.0582, grad_fn=<MeanBackward0>) tensor(0.6839, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5423, grad_fn=<NegBackward0>) tensor(0.0820, grad_fn=<MeanBackward0>) tensor(0.6859, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4533, grad_fn=<NegBackward0>) tensor(0.0495, grad_fn=<MeanBackward0>) tensor(0.6868, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3840, grad_fn=<NegBackward0>) tensor(0.0739, grad_fn=<MeanBackward0>) tensor(0.6875, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4010, grad_fn=<NegBackward0>) tensor(0.0771, grad_fn=<MeanBackward0>) tensor(0.6878, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3870, grad_fn=<NegBackward0>) tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.6874, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3915, grad_fn=<NegBackward0>) tensor(0.0343, grad_fn=<MeanBackward0>) tensor(0.6878, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4254, grad_fn=<NegBackward0>) tensor(0.0867, grad_fn=<MeanBackward0>) tensor(0.6871, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3406, grad_fn=<NegBackward0>) tensor(0.0633, grad_fn=<MeanBackward0>) tensor(0.6863, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4203, grad_fn=<NegBackward0>) tensor(0.0745, grad_fn=<MeanBackward0>) tensor(0.6864, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4460, grad_fn=<NegBackward0>) tensor(0.0592, grad_fn=<MeanBackward0>) tensor(0.6860, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3637, grad_fn=<NegBackward0>) tensor(0.0731, grad_fn=<MeanBackward0>) tensor(0.6856, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4102, grad_fn=<NegBackward0>) tensor(0.0714, grad_fn=<MeanBackward0>) tensor(0.6849, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3652, grad_fn=<NegBackward0>) tensor(0.0664, grad_fn=<MeanBackward0>) tensor(0.6849, grad_fn=<MeanBackward0>)\n",
      "Epoch: 3 - loss: -0.42\n",
      "-------------CYCLE: 1-------------\n",
      "game length: 54.0\n",
      "tensor(-0.0486, grad_fn=<NegBackward0>) tensor(0.1435, grad_fn=<MeanBackward0>) tensor(0.6853, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0193, grad_fn=<NegBackward0>) tensor(0.1613, grad_fn=<MeanBackward0>) tensor(0.6850, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0388, grad_fn=<NegBackward0>) tensor(0.1835, grad_fn=<MeanBackward0>) tensor(0.6845, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0176, grad_fn=<NegBackward0>) tensor(0.1538, grad_fn=<MeanBackward0>) tensor(0.6837, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0942, grad_fn=<NegBackward0>) tensor(0.1372, grad_fn=<MeanBackward0>) tensor(0.6835, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0041, grad_fn=<NegBackward0>) tensor(0.1284, grad_fn=<MeanBackward0>) tensor(0.6833, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1597, grad_fn=<NegBackward0>) tensor(0.1344, grad_fn=<MeanBackward0>) tensor(0.6830, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0734, grad_fn=<NegBackward0>) tensor(0.1876, grad_fn=<MeanBackward0>) tensor(0.6822, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0670, grad_fn=<NegBackward0>) tensor(0.1404, grad_fn=<MeanBackward0>) tensor(0.6818, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0997, grad_fn=<NegBackward0>) tensor(0.1614, grad_fn=<MeanBackward0>) tensor(0.6814, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0181, grad_fn=<NegBackward0>) tensor(0.1464, grad_fn=<MeanBackward0>) tensor(0.6805, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1350, grad_fn=<NegBackward0>) tensor(0.1460, grad_fn=<MeanBackward0>) tensor(0.6794, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0109, grad_fn=<NegBackward0>) tensor(0.1786, grad_fn=<MeanBackward0>) tensor(0.6682, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0056, grad_fn=<NegBackward0>) tensor(0.2034, grad_fn=<MeanBackward0>) tensor(0.6773, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0834, grad_fn=<NegBackward0>) tensor(0.1067, grad_fn=<MeanBackward0>) tensor(0.6760, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0023, grad_fn=<NegBackward0>) tensor(0.1308, grad_fn=<MeanBackward0>) tensor(0.6732, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0374, grad_fn=<NegBackward0>) tensor(0.1556, grad_fn=<MeanBackward0>) tensor(0.6693, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0699, grad_fn=<NegBackward0>) tensor(0.1488, grad_fn=<MeanBackward0>) tensor(0.6671, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0118, grad_fn=<NegBackward0>) tensor(0.1246, grad_fn=<MeanBackward0>) tensor(0.6653, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1475, grad_fn=<NegBackward0>) tensor(0.1735, grad_fn=<MeanBackward0>) tensor(0.6655, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0032, grad_fn=<NegBackward0>) tensor(0.1458, grad_fn=<MeanBackward0>) tensor(0.6644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0158, grad_fn=<NegBackward0>) tensor(0.1254, grad_fn=<MeanBackward0>) tensor(0.6657, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0032, grad_fn=<NegBackward0>) tensor(0.1409, grad_fn=<MeanBackward0>) tensor(0.6666, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0059, grad_fn=<NegBackward0>) tensor(0.1293, grad_fn=<MeanBackward0>) tensor(0.6706, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0651, grad_fn=<NegBackward0>) tensor(0.1352, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0326, grad_fn=<NegBackward0>) tensor(0.1412, grad_fn=<MeanBackward0>) tensor(0.6749, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0048, grad_fn=<NegBackward0>) tensor(0.1113, grad_fn=<MeanBackward0>) tensor(0.6750, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1121, grad_fn=<NegBackward0>) tensor(0.1390, grad_fn=<MeanBackward0>) tensor(0.6747, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0082, grad_fn=<NegBackward0>) tensor(0.1062, grad_fn=<MeanBackward0>) tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0034, grad_fn=<NegBackward0>) tensor(0.1105, grad_fn=<MeanBackward0>) tensor(0.6746, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0410, grad_fn=<NegBackward0>) tensor(0.1515, grad_fn=<MeanBackward0>) tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0290, grad_fn=<NegBackward0>) tensor(0.0808, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0543, grad_fn=<NegBackward0>) tensor(0.1282, grad_fn=<MeanBackward0>) tensor(0.6734, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1007, grad_fn=<NegBackward0>) tensor(0.1271, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1237, grad_fn=<NegBackward0>) tensor(0.1179, grad_fn=<MeanBackward0>) tensor(0.6675, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0363, grad_fn=<NegBackward0>) tensor(0.1268, grad_fn=<MeanBackward0>) tensor(0.6637, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0676, grad_fn=<NegBackward0>) tensor(0.1212, grad_fn=<MeanBackward0>) tensor(0.6625, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0360, grad_fn=<NegBackward0>) tensor(0.1155, grad_fn=<MeanBackward0>) tensor(0.6621, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0344, grad_fn=<NegBackward0>) tensor(0.1304, grad_fn=<MeanBackward0>) tensor(0.6636, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0311, grad_fn=<NegBackward0>) tensor(0.1266, grad_fn=<MeanBackward0>) tensor(0.6664, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0379, grad_fn=<NegBackward0>) tensor(0.1245, grad_fn=<MeanBackward0>) tensor(0.6686, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0758, grad_fn=<NegBackward0>) tensor(0.1348, grad_fn=<MeanBackward0>) tensor(0.6717, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0209, grad_fn=<NegBackward0>) tensor(0.1068, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0331, grad_fn=<NegBackward0>) tensor(0.1130, grad_fn=<MeanBackward0>) tensor(0.6748, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1048, grad_fn=<NegBackward0>) tensor(0.1224, grad_fn=<MeanBackward0>) tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0601, grad_fn=<NegBackward0>) tensor(0.1036, grad_fn=<MeanBackward0>) tensor(0.6759, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1042, grad_fn=<NegBackward0>) tensor(0.0943, grad_fn=<MeanBackward0>) tensor(0.6752, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0787, grad_fn=<NegBackward0>) tensor(0.1034, grad_fn=<MeanBackward0>) tensor(0.6748, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0407, grad_fn=<NegBackward0>) tensor(0.1214, grad_fn=<MeanBackward0>) tensor(0.6746, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0215, grad_fn=<NegBackward0>) tensor(0.1003, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0607, grad_fn=<NegBackward0>) tensor(0.1406, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0487, grad_fn=<NegBackward0>) tensor(0.0803, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0027, grad_fn=<NegBackward0>) tensor(0.1270, grad_fn=<MeanBackward0>) tensor(0.6692, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0084, grad_fn=<NegBackward0>) tensor(0.1196, grad_fn=<MeanBackward0>) tensor(0.6672, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0238, grad_fn=<NegBackward0>) tensor(0.1217, grad_fn=<MeanBackward0>) tensor(0.6664, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0396, grad_fn=<NegBackward0>) tensor(0.0959, grad_fn=<MeanBackward0>) tensor(0.6667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0028, grad_fn=<NegBackward0>) tensor(0.1063, grad_fn=<MeanBackward0>) tensor(0.6670, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0650, grad_fn=<NegBackward0>) tensor(0.1078, grad_fn=<MeanBackward0>) tensor(0.6692, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1082, grad_fn=<NegBackward0>) tensor(0.0887, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0146, grad_fn=<NegBackward0>) tensor(0.1096, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1127, grad_fn=<NegBackward0>) tensor(0.0791, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0178, grad_fn=<NegBackward0>) tensor(0.1088, grad_fn=<MeanBackward0>) tensor(0.6709, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0152, grad_fn=<NegBackward0>) tensor(0.0972, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0673, grad_fn=<NegBackward0>) tensor(0.1173, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0014, grad_fn=<NegBackward0>) tensor(0.0974, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0009, grad_fn=<NegBackward0>) tensor(0.1110, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0186, grad_fn=<NegBackward0>) tensor(0.0864, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0684, grad_fn=<NegBackward0>) tensor(0.1036, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0428, grad_fn=<NegBackward0>) tensor(0.0858, grad_fn=<MeanBackward0>) tensor(0.6710, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0417, grad_fn=<NegBackward0>) tensor(0.0715, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0003, grad_fn=<NegBackward0>) tensor(0.0927, grad_fn=<MeanBackward0>) tensor(0.6706, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0270, grad_fn=<NegBackward0>) tensor(0.0717, grad_fn=<MeanBackward0>) tensor(0.6693, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0334, grad_fn=<NegBackward0>) tensor(0.0747, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0393, grad_fn=<NegBackward0>) tensor(0.0981, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0100, grad_fn=<NegBackward0>) tensor(0.1051, grad_fn=<MeanBackward0>) tensor(0.6685, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1068, grad_fn=<NegBackward0>) tensor(0.0980, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1025, grad_fn=<NegBackward0>) tensor(0.0994, grad_fn=<MeanBackward0>) tensor(0.6682, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0424, grad_fn=<NegBackward0>) tensor(0.0853, grad_fn=<MeanBackward0>) tensor(0.6662, grad_fn=<MeanBackward0>)\n",
      "Epoch: 0 - loss: 0.02\n",
      "tensor(0.0686, grad_fn=<NegBackward0>) tensor(0.1234, grad_fn=<MeanBackward0>) tensor(0.6671, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0637, grad_fn=<NegBackward0>) tensor(0.0797, grad_fn=<MeanBackward0>) tensor(0.6667, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0971, grad_fn=<NegBackward0>) tensor(0.0850, grad_fn=<MeanBackward0>) tensor(0.6667, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0462, grad_fn=<NegBackward0>) tensor(0.1086, grad_fn=<MeanBackward0>) tensor(0.6680, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0206, grad_fn=<NegBackward0>) tensor(0.0851, grad_fn=<MeanBackward0>) tensor(0.6680, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0533, grad_fn=<NegBackward0>) tensor(0.0960, grad_fn=<MeanBackward0>) tensor(0.6690, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0062, grad_fn=<NegBackward0>) tensor(0.0903, grad_fn=<MeanBackward0>) tensor(0.6696, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<NegBackward0>) tensor(0.0771, grad_fn=<MeanBackward0>) tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0175, grad_fn=<NegBackward0>) tensor(0.0953, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1402, grad_fn=<NegBackward0>) tensor(0.0934, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0209, grad_fn=<NegBackward0>) tensor(0.0810, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0577, grad_fn=<NegBackward0>) tensor(0.0751, grad_fn=<MeanBackward0>) tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0706, grad_fn=<NegBackward0>) tensor(0.0900, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0328, grad_fn=<NegBackward0>) tensor(0.0938, grad_fn=<MeanBackward0>) tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0138, grad_fn=<NegBackward0>) tensor(0.0767, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0097, grad_fn=<NegBackward0>) tensor(0.0752, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0722, grad_fn=<NegBackward0>) tensor(0.0597, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0889, grad_fn=<NegBackward0>) tensor(0.0879, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0476, grad_fn=<NegBackward0>) tensor(0.0864, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0208, grad_fn=<NegBackward0>) tensor(0.0689, grad_fn=<MeanBackward0>) tensor(0.6724, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0645, grad_fn=<NegBackward0>) tensor(0.0823, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0402, grad_fn=<NegBackward0>) tensor(0.0832, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0621, grad_fn=<NegBackward0>) tensor(0.0852, grad_fn=<MeanBackward0>) tensor(0.6692, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0451, grad_fn=<NegBackward0>) tensor(0.0711, grad_fn=<MeanBackward0>) tensor(0.6684, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0006, grad_fn=<NegBackward0>) tensor(0.0754, grad_fn=<MeanBackward0>) tensor(0.6674, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0117, grad_fn=<NegBackward0>) tensor(0.0782, grad_fn=<MeanBackward0>) tensor(0.6569, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0433, grad_fn=<NegBackward0>) tensor(0.0825, grad_fn=<MeanBackward0>) tensor(0.6680, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0129, grad_fn=<NegBackward0>) tensor(0.0849, grad_fn=<MeanBackward0>) tensor(0.6695, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0408, grad_fn=<NegBackward0>) tensor(0.0743, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0404, grad_fn=<NegBackward0>) tensor(0.0834, grad_fn=<MeanBackward0>) tensor(0.6724, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0249, grad_fn=<NegBackward0>) tensor(0.0729, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0551, grad_fn=<NegBackward0>) tensor(0.0829, grad_fn=<MeanBackward0>) tensor(0.6741, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0713, grad_fn=<NegBackward0>) tensor(0.1028, grad_fn=<MeanBackward0>) tensor(0.6736, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1206, grad_fn=<NegBackward0>) tensor(0.0801, grad_fn=<MeanBackward0>) tensor(0.6732, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0053, grad_fn=<NegBackward0>) tensor(0.0651, grad_fn=<MeanBackward0>) tensor(0.6731, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0603, grad_fn=<NegBackward0>) tensor(0.0846, grad_fn=<MeanBackward0>) tensor(0.6708, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0125, grad_fn=<NegBackward0>) tensor(0.0761, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0863, grad_fn=<NegBackward0>) tensor(0.0746, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0400, grad_fn=<NegBackward0>) tensor(0.0882, grad_fn=<MeanBackward0>) tensor(0.6686, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0544, grad_fn=<NegBackward0>) tensor(0.0662, grad_fn=<MeanBackward0>) tensor(0.6692, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0605, grad_fn=<NegBackward0>) tensor(0.0886, grad_fn=<MeanBackward0>) tensor(0.6702, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1055, grad_fn=<NegBackward0>) tensor(0.0910, grad_fn=<MeanBackward0>) tensor(0.6698, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1047, grad_fn=<NegBackward0>) tensor(0.0870, grad_fn=<MeanBackward0>) tensor(0.6708, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0242, grad_fn=<NegBackward0>) tensor(0.0782, grad_fn=<MeanBackward0>) tensor(0.6697, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0137, grad_fn=<NegBackward0>) tensor(0.0949, grad_fn=<MeanBackward0>) tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0754, grad_fn=<NegBackward0>) tensor(0.0591, grad_fn=<MeanBackward0>) tensor(0.6704, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1185, grad_fn=<NegBackward0>) tensor(0.0751, grad_fn=<MeanBackward0>) tensor(0.6706, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0350, grad_fn=<NegBackward0>) tensor(0.0810, grad_fn=<MeanBackward0>) tensor(0.6687, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0273, grad_fn=<NegBackward0>) tensor(0.0881, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1122, grad_fn=<NegBackward0>) tensor(0.0965, grad_fn=<MeanBackward0>) tensor(0.6708, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1376, grad_fn=<NegBackward0>) tensor(0.0859, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0187, grad_fn=<NegBackward0>) tensor(0.0825, grad_fn=<MeanBackward0>) tensor(0.6724, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0034, grad_fn=<NegBackward0>) tensor(0.0738, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0068, grad_fn=<NegBackward0>) tensor(0.0725, grad_fn=<MeanBackward0>) tensor(0.6750, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0707, grad_fn=<NegBackward0>) tensor(0.0758, grad_fn=<MeanBackward0>) tensor(0.6758, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0292, grad_fn=<NegBackward0>) tensor(0.0673, grad_fn=<MeanBackward0>) tensor(0.6763, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0470, grad_fn=<NegBackward0>) tensor(0.0878, grad_fn=<MeanBackward0>) tensor(0.6778, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0332, grad_fn=<NegBackward0>) tensor(0.0910, grad_fn=<MeanBackward0>) tensor(0.6775, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0133, grad_fn=<NegBackward0>) tensor(0.0719, grad_fn=<MeanBackward0>) tensor(0.6770, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0577, grad_fn=<NegBackward0>) tensor(0.0878, grad_fn=<MeanBackward0>) tensor(0.6784, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0083, grad_fn=<NegBackward0>) tensor(0.0859, grad_fn=<MeanBackward0>) tensor(0.6792, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0869, grad_fn=<NegBackward0>) tensor(0.0960, grad_fn=<MeanBackward0>) tensor(0.6781, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0454, grad_fn=<NegBackward0>) tensor(0.0566, grad_fn=<MeanBackward0>) tensor(0.6759, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0574, grad_fn=<NegBackward0>) tensor(0.0653, grad_fn=<MeanBackward0>) tensor(0.6767, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0446, grad_fn=<NegBackward0>) tensor(0.0892, grad_fn=<MeanBackward0>) tensor(0.6747, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0257, grad_fn=<NegBackward0>) tensor(0.0931, grad_fn=<MeanBackward0>) tensor(0.6729, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0772, grad_fn=<NegBackward0>) tensor(0.0931, grad_fn=<MeanBackward0>) tensor(0.6702, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0254, grad_fn=<NegBackward0>) tensor(0.0571, grad_fn=<MeanBackward0>) tensor(0.6680, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0524, grad_fn=<NegBackward0>) tensor(0.0913, grad_fn=<MeanBackward0>) tensor(0.6675, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0849, grad_fn=<NegBackward0>) tensor(0.0909, grad_fn=<MeanBackward0>) tensor(0.6669, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0610, grad_fn=<NegBackward0>) tensor(0.0988, grad_fn=<MeanBackward0>) tensor(0.6663, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0418, grad_fn=<NegBackward0>) tensor(0.0677, grad_fn=<MeanBackward0>) tensor(0.6672, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0104, grad_fn=<NegBackward0>) tensor(0.0530, grad_fn=<MeanBackward0>) tensor(0.6684, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0281, grad_fn=<NegBackward0>) tensor(0.0689, grad_fn=<MeanBackward0>) tensor(0.6708, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1008, grad_fn=<NegBackward0>) tensor(0.0939, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0941, grad_fn=<NegBackward0>) tensor(0.0775, grad_fn=<MeanBackward0>) tensor(0.6727, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0648, grad_fn=<NegBackward0>) tensor(0.0740, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0318, grad_fn=<NegBackward0>) tensor(0.0846, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "Epoch: 1 - loss: -0.0\n",
      "tensor(-0.0897, grad_fn=<NegBackward0>) tensor(0.0657, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0587, grad_fn=<NegBackward0>) tensor(0.0668, grad_fn=<MeanBackward0>) tensor(0.6699, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, grad_fn=<NegBackward0>) tensor(0.0515, grad_fn=<MeanBackward0>) tensor(0.6694, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0178, grad_fn=<NegBackward0>) tensor(0.0601, grad_fn=<MeanBackward0>) tensor(0.6695, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1121, grad_fn=<NegBackward0>) tensor(0.0778, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0015, grad_fn=<NegBackward0>) tensor(0.0806, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0773, grad_fn=<NegBackward0>) tensor(0.0912, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0299, grad_fn=<NegBackward0>) tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.6715, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0390, grad_fn=<NegBackward0>) tensor(0.0793, grad_fn=<MeanBackward0>) tensor(0.6698, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0289, grad_fn=<NegBackward0>) tensor(0.0809, grad_fn=<MeanBackward0>) tensor(0.6687, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0420, grad_fn=<NegBackward0>) tensor(0.0770, grad_fn=<MeanBackward0>) tensor(0.6692, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1175, grad_fn=<NegBackward0>) tensor(0.0519, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0488, grad_fn=<NegBackward0>) tensor(0.0622, grad_fn=<MeanBackward0>) tensor(0.6699, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0627, grad_fn=<NegBackward0>) tensor(0.0555, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0876, grad_fn=<NegBackward0>) tensor(0.0807, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0279, grad_fn=<NegBackward0>) tensor(0.0617, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1045, grad_fn=<NegBackward0>) tensor(0.0845, grad_fn=<MeanBackward0>) tensor(0.6728, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1175, grad_fn=<NegBackward0>) tensor(0.0598, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0234, grad_fn=<NegBackward0>) tensor(0.0961, grad_fn=<MeanBackward0>) tensor(0.6728, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0217, grad_fn=<NegBackward0>) tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0112, grad_fn=<NegBackward0>) tensor(0.0580, grad_fn=<MeanBackward0>) tensor(0.6709, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0367, grad_fn=<NegBackward0>) tensor(0.0494, grad_fn=<MeanBackward0>) tensor(0.6683, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0025, grad_fn=<NegBackward0>) tensor(0.0554, grad_fn=<MeanBackward0>) tensor(0.6690, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0859, grad_fn=<NegBackward0>) tensor(0.0636, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0228, grad_fn=<NegBackward0>) tensor(0.0481, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0126, grad_fn=<NegBackward0>) tensor(0.0679, grad_fn=<MeanBackward0>) tensor(0.6704, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0998, grad_fn=<NegBackward0>) tensor(0.0907, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0197, grad_fn=<NegBackward0>) tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.6745, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0928, grad_fn=<NegBackward0>) tensor(0.0433, grad_fn=<MeanBackward0>) tensor(0.6746, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0058, grad_fn=<NegBackward0>) tensor(0.0571, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0287, grad_fn=<NegBackward0>) tensor(0.0638, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0814, grad_fn=<NegBackward0>) tensor(0.0439, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0848, grad_fn=<NegBackward0>) tensor(0.0718, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0797, grad_fn=<NegBackward0>) tensor(0.0698, grad_fn=<MeanBackward0>) tensor(0.6702, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0455, grad_fn=<NegBackward0>) tensor(0.0663, grad_fn=<MeanBackward0>) tensor(0.6680, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0034, grad_fn=<NegBackward0>) tensor(0.0632, grad_fn=<MeanBackward0>) tensor(0.6644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0496, grad_fn=<NegBackward0>) tensor(0.0652, grad_fn=<MeanBackward0>) tensor(0.6673, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0087, grad_fn=<NegBackward0>) tensor(0.0581, grad_fn=<MeanBackward0>) tensor(0.6682, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0247, grad_fn=<NegBackward0>) tensor(0.0531, grad_fn=<MeanBackward0>) tensor(0.6675, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0338, grad_fn=<NegBackward0>) tensor(0.0635, grad_fn=<MeanBackward0>) tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0058, grad_fn=<NegBackward0>) tensor(0.0655, grad_fn=<MeanBackward0>) tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0433, grad_fn=<NegBackward0>) tensor(0.0441, grad_fn=<MeanBackward0>) tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0870, grad_fn=<NegBackward0>) tensor(0.0538, grad_fn=<MeanBackward0>) tensor(0.6763, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0250, grad_fn=<NegBackward0>) tensor(0.0522, grad_fn=<MeanBackward0>) tensor(0.6787, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0276, grad_fn=<NegBackward0>) tensor(0.0647, grad_fn=<MeanBackward0>) tensor(0.6786, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0143, grad_fn=<NegBackward0>) tensor(0.0628, grad_fn=<MeanBackward0>) tensor(0.6784, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0701, grad_fn=<NegBackward0>) tensor(0.0409, grad_fn=<MeanBackward0>) tensor(0.6785, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0010, grad_fn=<NegBackward0>) tensor(0.0445, grad_fn=<MeanBackward0>) tensor(0.6779, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, grad_fn=<NegBackward0>) tensor(0.0645, grad_fn=<MeanBackward0>) tensor(0.6767, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0950, grad_fn=<NegBackward0>) tensor(0.0668, grad_fn=<MeanBackward0>) tensor(0.6780, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0162, grad_fn=<NegBackward0>) tensor(0.0871, grad_fn=<MeanBackward0>) tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0884, grad_fn=<NegBackward0>) tensor(0.0577, grad_fn=<MeanBackward0>) tensor(0.6736, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0258, grad_fn=<NegBackward0>) tensor(0.0513, grad_fn=<MeanBackward0>) tensor(0.6731, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0636, grad_fn=<NegBackward0>) tensor(0.0520, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0278, grad_fn=<NegBackward0>) tensor(0.0543, grad_fn=<MeanBackward0>) tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0136, grad_fn=<NegBackward0>) tensor(0.0569, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0302, grad_fn=<NegBackward0>) tensor(0.0528, grad_fn=<MeanBackward0>) tensor(0.6709, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0830, grad_fn=<NegBackward0>) tensor(0.0604, grad_fn=<MeanBackward0>) tensor(0.6684, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0437, grad_fn=<NegBackward0>) tensor(0.0348, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0428, grad_fn=<NegBackward0>) tensor(0.0598, grad_fn=<MeanBackward0>) tensor(0.6690, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0206, grad_fn=<NegBackward0>) tensor(0.0488, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0199, grad_fn=<NegBackward0>) tensor(0.0512, grad_fn=<MeanBackward0>) tensor(0.6702, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0129, grad_fn=<NegBackward0>) tensor(0.0410, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0892, grad_fn=<NegBackward0>) tensor(0.0525, grad_fn=<MeanBackward0>) tensor(0.6701, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0721, grad_fn=<NegBackward0>) tensor(0.0701, grad_fn=<MeanBackward0>) tensor(0.6725, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0611, grad_fn=<NegBackward0>) tensor(0.0758, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0396, grad_fn=<NegBackward0>) tensor(0.0427, grad_fn=<MeanBackward0>) tensor(0.6609, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0760, grad_fn=<NegBackward0>) tensor(0.0505, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0888, grad_fn=<NegBackward0>) tensor(0.0410, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0141, grad_fn=<NegBackward0>) tensor(0.0703, grad_fn=<MeanBackward0>) tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1327, grad_fn=<NegBackward0>) tensor(0.0525, grad_fn=<MeanBackward0>) tensor(0.6737, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0661, grad_fn=<NegBackward0>) tensor(0.0393, grad_fn=<MeanBackward0>) tensor(0.6741, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0741, grad_fn=<NegBackward0>) tensor(0.0610, grad_fn=<MeanBackward0>) tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0486, grad_fn=<NegBackward0>) tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.6734, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0125, grad_fn=<NegBackward0>) tensor(0.0372, grad_fn=<MeanBackward0>) tensor(0.6706, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0179, grad_fn=<NegBackward0>) tensor(0.0479, grad_fn=<MeanBackward0>) tensor(0.6685, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0076, grad_fn=<NegBackward0>) tensor(0.0572, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0055, grad_fn=<NegBackward0>) tensor(0.0576, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "Epoch: 2 - loss: -0.02\n",
      "tensor(0.0733, grad_fn=<NegBackward0>) tensor(0.0385, grad_fn=<MeanBackward0>) tensor(0.6678, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0779, grad_fn=<NegBackward0>) tensor(0.0454, grad_fn=<MeanBackward0>) tensor(0.6710, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0683, grad_fn=<NegBackward0>) tensor(0.0586, grad_fn=<MeanBackward0>) tensor(0.6702, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0152, grad_fn=<NegBackward0>) tensor(0.0470, grad_fn=<MeanBackward0>) tensor(0.6702, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0037, grad_fn=<NegBackward0>) tensor(0.0556, grad_fn=<MeanBackward0>) tensor(0.6731, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0415, grad_fn=<NegBackward0>) tensor(0.0486, grad_fn=<MeanBackward0>) tensor(0.6715, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0353, grad_fn=<NegBackward0>) tensor(0.0587, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0415, grad_fn=<NegBackward0>) tensor(0.0375, grad_fn=<MeanBackward0>) tensor(0.6741, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0180, grad_fn=<NegBackward0>) tensor(0.0641, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0761, grad_fn=<NegBackward0>) tensor(0.0685, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0251, grad_fn=<NegBackward0>) tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0733, grad_fn=<NegBackward0>) tensor(0.0613, grad_fn=<MeanBackward0>) tensor(0.6730, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0390, grad_fn=<NegBackward0>) tensor(0.0421, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0005, grad_fn=<NegBackward0>) tensor(0.0667, grad_fn=<MeanBackward0>) tensor(0.6726, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0029, grad_fn=<NegBackward0>) tensor(0.0384, grad_fn=<MeanBackward0>) tensor(0.6693, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0230, grad_fn=<NegBackward0>) tensor(0.0596, grad_fn=<MeanBackward0>) tensor(0.6729, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0172, grad_fn=<NegBackward0>) tensor(0.0630, grad_fn=<MeanBackward0>) tensor(0.6710, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0486, grad_fn=<NegBackward0>) tensor(0.0473, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1060, grad_fn=<NegBackward0>) tensor(0.0514, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0288, grad_fn=<NegBackward0>) tensor(0.0554, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0318, grad_fn=<NegBackward0>) tensor(0.0632, grad_fn=<MeanBackward0>) tensor(0.6725, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0817, grad_fn=<NegBackward0>) tensor(0.0591, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0421, grad_fn=<NegBackward0>) tensor(0.0384, grad_fn=<MeanBackward0>) tensor(0.6724, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0086, grad_fn=<NegBackward0>) tensor(0.0393, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0960, grad_fn=<NegBackward0>) tensor(0.0553, grad_fn=<MeanBackward0>) tensor(0.6737, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0837, grad_fn=<NegBackward0>) tensor(0.0401, grad_fn=<MeanBackward0>) tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0847, grad_fn=<NegBackward0>) tensor(0.0330, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0111, grad_fn=<NegBackward0>) tensor(0.0497, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0333, grad_fn=<NegBackward0>) tensor(0.0642, grad_fn=<MeanBackward0>) tensor(0.6706, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0486, grad_fn=<NegBackward0>) tensor(0.0621, grad_fn=<MeanBackward0>) tensor(0.6701, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0171, grad_fn=<NegBackward0>) tensor(0.0620, grad_fn=<MeanBackward0>) tensor(0.6689, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0653, grad_fn=<NegBackward0>) tensor(0.0532, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0360, grad_fn=<NegBackward0>) tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.6562, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0942, grad_fn=<NegBackward0>) tensor(0.0420, grad_fn=<MeanBackward0>) tensor(0.6648, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0649, grad_fn=<NegBackward0>) tensor(0.0414, grad_fn=<MeanBackward0>) tensor(0.6662, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0019, grad_fn=<NegBackward0>) tensor(0.0505, grad_fn=<MeanBackward0>) tensor(0.6683, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, grad_fn=<NegBackward0>) tensor(0.0464, grad_fn=<MeanBackward0>) tensor(0.6706, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0708, grad_fn=<NegBackward0>) tensor(0.0563, grad_fn=<MeanBackward0>) tensor(0.6764, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0786, grad_fn=<NegBackward0>) tensor(0.0376, grad_fn=<MeanBackward0>) tensor(0.6774, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0043, grad_fn=<NegBackward0>) tensor(0.0553, grad_fn=<MeanBackward0>) tensor(0.6824, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0671, grad_fn=<NegBackward0>) tensor(0.0484, grad_fn=<MeanBackward0>) tensor(0.6825, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0006, grad_fn=<NegBackward0>) tensor(0.0460, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0685, grad_fn=<NegBackward0>) tensor(0.0551, grad_fn=<MeanBackward0>) tensor(0.6854, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0284, grad_fn=<NegBackward0>) tensor(0.0441, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0048, grad_fn=<NegBackward0>) tensor(0.0572, grad_fn=<MeanBackward0>) tensor(0.6848, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0404, grad_fn=<NegBackward0>) tensor(0.0361, grad_fn=<MeanBackward0>) tensor(0.6828, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0216, grad_fn=<NegBackward0>) tensor(0.0403, grad_fn=<MeanBackward0>) tensor(0.6800, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0557, grad_fn=<NegBackward0>) tensor(0.0291, grad_fn=<MeanBackward0>) tensor(0.6790, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0335, grad_fn=<NegBackward0>) tensor(0.0306, grad_fn=<MeanBackward0>) tensor(0.6759, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0709, grad_fn=<NegBackward0>) tensor(0.0404, grad_fn=<MeanBackward0>) tensor(0.6763, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0256, grad_fn=<NegBackward0>) tensor(0.0450, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0212, grad_fn=<NegBackward0>) tensor(0.0205, grad_fn=<MeanBackward0>) tensor(0.6696, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0406, grad_fn=<NegBackward0>) tensor(0.0392, grad_fn=<MeanBackward0>) tensor(0.6678, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0333, grad_fn=<NegBackward0>) tensor(0.0341, grad_fn=<MeanBackward0>) tensor(0.6638, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0650, grad_fn=<NegBackward0>) tensor(0.0370, grad_fn=<MeanBackward0>) tensor(0.6674, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0797, grad_fn=<NegBackward0>) tensor(0.0314, grad_fn=<MeanBackward0>) tensor(0.6665, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0488, grad_fn=<NegBackward0>) tensor(0.0520, grad_fn=<MeanBackward0>) tensor(0.6697, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0005, grad_fn=<NegBackward0>) tensor(0.0632, grad_fn=<MeanBackward0>) tensor(0.6698, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1284, grad_fn=<NegBackward0>) tensor(0.0377, grad_fn=<MeanBackward0>) tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0475, grad_fn=<NegBackward0>) tensor(0.0664, grad_fn=<MeanBackward0>) tensor(0.6768, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0542, grad_fn=<NegBackward0>) tensor(0.0401, grad_fn=<MeanBackward0>) tensor(0.6800, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0678, grad_fn=<NegBackward0>) tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.6784, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0073, grad_fn=<NegBackward0>) tensor(0.0513, grad_fn=<MeanBackward0>) tensor(0.6793, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0639, grad_fn=<NegBackward0>) tensor(0.0256, grad_fn=<MeanBackward0>) tensor(0.6800, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0561, grad_fn=<NegBackward0>) tensor(0.0304, grad_fn=<MeanBackward0>) tensor(0.6784, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1229, grad_fn=<NegBackward0>) tensor(0.0356, grad_fn=<MeanBackward0>) tensor(0.6793, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0196, grad_fn=<NegBackward0>) tensor(0.0362, grad_fn=<MeanBackward0>) tensor(0.6798, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0230, grad_fn=<NegBackward0>) tensor(0.0472, grad_fn=<MeanBackward0>) tensor(0.6790, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0973, grad_fn=<NegBackward0>) tensor(0.0494, grad_fn=<MeanBackward0>) tensor(0.6750, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0822, grad_fn=<NegBackward0>) tensor(0.0460, grad_fn=<MeanBackward0>) tensor(0.6764, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0326, grad_fn=<NegBackward0>) tensor(0.0235, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0102, grad_fn=<NegBackward0>) tensor(0.0311, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0466, grad_fn=<NegBackward0>) tensor(0.0330, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0241, grad_fn=<NegBackward0>) tensor(0.0389, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0104, grad_fn=<NegBackward0>) tensor(0.0531, grad_fn=<MeanBackward0>) tensor(0.6717, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0067, grad_fn=<NegBackward0>) tensor(0.0524, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0546, grad_fn=<NegBackward0>) tensor(0.0322, grad_fn=<MeanBackward0>) tensor(0.6704, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0560, grad_fn=<NegBackward0>) tensor(0.0359, grad_fn=<MeanBackward0>) tensor(0.6726, grad_fn=<MeanBackward0>)\n",
      "Epoch: 3 - loss: -0.02\n",
      "-------------CYCLE: 2-------------\n",
      "game length: 59.0\n",
      "tensor(0.0453, grad_fn=<NegBackward0>) tensor(0.1670, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0732, grad_fn=<NegBackward0>) tensor(0.1693, grad_fn=<MeanBackward0>) tensor(0.6727, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0138, grad_fn=<NegBackward0>) tensor(0.1584, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0339, grad_fn=<NegBackward0>) tensor(0.1666, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0515, grad_fn=<NegBackward0>) tensor(0.1208, grad_fn=<MeanBackward0>) tensor(0.6684, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0114, grad_fn=<NegBackward0>) tensor(0.1474, grad_fn=<MeanBackward0>) tensor(0.6681, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0399, grad_fn=<NegBackward0>) tensor(0.1537, grad_fn=<MeanBackward0>) tensor(0.6635, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0572, grad_fn=<NegBackward0>) tensor(0.1347, grad_fn=<MeanBackward0>) tensor(0.6616, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0778, grad_fn=<NegBackward0>) tensor(0.1349, grad_fn=<MeanBackward0>) tensor(0.6408, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0778, grad_fn=<NegBackward0>) tensor(0.1221, grad_fn=<MeanBackward0>) tensor(0.6492, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0998, grad_fn=<NegBackward0>) tensor(0.0928, grad_fn=<MeanBackward0>) tensor(0.6464, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0676, grad_fn=<NegBackward0>) tensor(0.1092, grad_fn=<MeanBackward0>) tensor(0.6454, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0313, grad_fn=<NegBackward0>) tensor(0.1692, grad_fn=<MeanBackward0>) tensor(0.6458, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0633, grad_fn=<NegBackward0>) tensor(0.1340, grad_fn=<MeanBackward0>) tensor(0.6492, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0722, grad_fn=<NegBackward0>) tensor(0.1219, grad_fn=<MeanBackward0>) tensor(0.6519, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0475, grad_fn=<NegBackward0>) tensor(0.1081, grad_fn=<MeanBackward0>) tensor(0.6585, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0088, grad_fn=<NegBackward0>) tensor(0.1285, grad_fn=<MeanBackward0>) tensor(0.6498, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0542, grad_fn=<NegBackward0>) tensor(0.1344, grad_fn=<MeanBackward0>) tensor(0.6607, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0256, grad_fn=<NegBackward0>) tensor(0.1078, grad_fn=<MeanBackward0>) tensor(0.6647, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0090, grad_fn=<NegBackward0>) tensor(0.1090, grad_fn=<MeanBackward0>) tensor(0.6656, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0665, grad_fn=<NegBackward0>) tensor(0.1144, grad_fn=<MeanBackward0>) tensor(0.6557, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0814, grad_fn=<NegBackward0>) tensor(0.1092, grad_fn=<MeanBackward0>) tensor(0.6652, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0475, grad_fn=<NegBackward0>) tensor(0.1317, grad_fn=<MeanBackward0>) tensor(0.6499, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0560, grad_fn=<NegBackward0>) tensor(0.1188, grad_fn=<MeanBackward0>) tensor(0.6607, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0378, grad_fn=<NegBackward0>) tensor(0.1451, grad_fn=<MeanBackward0>) tensor(0.6592, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0726, grad_fn=<NegBackward0>) tensor(0.1019, grad_fn=<MeanBackward0>) tensor(0.6467, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0257, grad_fn=<NegBackward0>) tensor(0.0841, grad_fn=<MeanBackward0>) tensor(0.6499, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0174, grad_fn=<NegBackward0>) tensor(0.1299, grad_fn=<MeanBackward0>) tensor(0.6441, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0070, grad_fn=<NegBackward0>) tensor(0.0852, grad_fn=<MeanBackward0>) tensor(0.6452, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0402, grad_fn=<NegBackward0>) tensor(0.1118, grad_fn=<MeanBackward0>) tensor(0.6438, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0109, grad_fn=<NegBackward0>) tensor(0.0912, grad_fn=<MeanBackward0>) tensor(0.6500, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0663, grad_fn=<NegBackward0>) tensor(0.1108, grad_fn=<MeanBackward0>) tensor(0.6514, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1162, grad_fn=<NegBackward0>) tensor(0.1006, grad_fn=<MeanBackward0>) tensor(0.6532, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0601, grad_fn=<NegBackward0>) tensor(0.0932, grad_fn=<MeanBackward0>) tensor(0.6526, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0838, grad_fn=<NegBackward0>) tensor(0.0960, grad_fn=<MeanBackward0>) tensor(0.6584, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0978, grad_fn=<NegBackward0>) tensor(0.0902, grad_fn=<MeanBackward0>) tensor(0.6597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1552, grad_fn=<NegBackward0>) tensor(0.0907, grad_fn=<MeanBackward0>) tensor(0.6601, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0561, grad_fn=<NegBackward0>) tensor(0.0971, grad_fn=<MeanBackward0>) tensor(0.6568, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0592, grad_fn=<NegBackward0>) tensor(0.1022, grad_fn=<MeanBackward0>) tensor(0.6598, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0226, grad_fn=<NegBackward0>) tensor(0.0888, grad_fn=<MeanBackward0>) tensor(0.6553, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0154, grad_fn=<NegBackward0>) tensor(0.0805, grad_fn=<MeanBackward0>) tensor(0.6537, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0489, grad_fn=<NegBackward0>) tensor(0.0958, grad_fn=<MeanBackward0>) tensor(0.6537, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0041, grad_fn=<NegBackward0>) tensor(0.1063, grad_fn=<MeanBackward0>) tensor(0.6533, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0067, grad_fn=<NegBackward0>) tensor(0.0734, grad_fn=<MeanBackward0>) tensor(0.6543, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0025, grad_fn=<NegBackward0>) tensor(0.1034, grad_fn=<MeanBackward0>) tensor(0.6572, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0411, grad_fn=<NegBackward0>) tensor(0.1053, grad_fn=<MeanBackward0>) tensor(0.6576, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0370, grad_fn=<NegBackward0>) tensor(0.1145, grad_fn=<MeanBackward0>) tensor(0.6603, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0367, grad_fn=<NegBackward0>) tensor(0.0644, grad_fn=<MeanBackward0>) tensor(0.6586, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m             loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     90\u001b[0m             nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;66;03m# FIX: check this\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m             \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(loss_record\u001b[38;5;241m/\u001b[39mindex,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./ppo_weight/hyperparam_tuning_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    235\u001b[0m         group,\n\u001b[0;32m    236\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m         state_steps,\n\u001b[0;32m    242\u001b[0m     )\n\u001b[1;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\adam.py:476\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    474\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 476\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    478\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for trial in range(N_TRIAL):\n",
    "    if GEN in [3, 3.5]:\n",
    "        model = ppo(N_PLAYER).to(device)\n",
    "    elif GEN == 4:\n",
    "        model = ppo_gen_4(N_PLAYER).to(device)\n",
    "    elif GEN == 5:\n",
    "        model = ppo_gen_5(N_PLAYER).to(device)\n",
    "\n",
    "    while True:\n",
    "        random_param_index = [random.choice(range(len(a))) for a in param_list]\n",
    "        if random_param_index not in randomized_record:\n",
    "            break\n",
    "    randomized_record.append(random_param_index)\n",
    "    \n",
    "    LEARNING_RATE, e, value_coef, entropy_coef = [a[b] for a,b in zip(param_list, random_param_index)]\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    param_record.append(\n",
    "        {'learning_rate': LEARNING_RATE,\n",
    "        'e': e,\n",
    "        'value_coef': value_coef,\n",
    "        'entropy_coef': entropy_coef,\n",
    "       'index': trial\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f'learning_rate {LEARNING_RATE} | e: {e} | value_coef: {value_coef} | entropy_coef: {entropy_coef}')  \n",
    "    for cycle in range(N_CYCLE):\n",
    "        print(f'-------------CYCLE: {cycle}-------------')\n",
    "    \n",
    "        # Rollout\n",
    "        training_data = []\n",
    "        game_length = []\n",
    "        while len(training_data) <= DATA_LENGTH:\n",
    "            nothanks = nothanks_ppo()\n",
    "            if GEN == 3:\n",
    "                play_buffer = nothanks.rollout(model, nothanks.get_state)\n",
    "                training_data_tmp = create_training_data(play_buffer)\n",
    "            elif GEN == 3.5:\n",
    "                play_buffer = nothanks.rollout(model, nothanks.get_state_gen_3_5)\n",
    "                training_data_tmp = create_training_data(play_buffer)\n",
    "            elif GEN == 5:\n",
    "                play_buffer = nothanks.rollout_gen_5(model)\n",
    "                training_data_tmp = create_training_data_gen_5(play_buffer)\n",
    "\n",
    "            game_length.append(len(training_data_tmp))\n",
    "            training_data.extend(training_data_tmp)\n",
    "        print(f'game length: {round(np.mean(game_length),0)}')\n",
    "        \n",
    "        # create a new data loader\n",
    "        train_data = dataset(training_data)\n",
    "        dataloader = DataLoader(train_data, **dataloader_params)\n",
    "        \n",
    "        # Train\n",
    "        for epoch in range(N_EPOCH):\n",
    "            loss_record = 0\n",
    "            for index, input_data in enumerate(dataloader):\n",
    "                if GEN == 5:\n",
    "                    x_card_tmp, x_state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = input_data\n",
    "                else:\n",
    "                    state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = input_data\n",
    "                optimizer.zero_grad()\n",
    "                if GEN == 5:\n",
    "                    _, log_prob_new, entropy, value_new = model.forward(x_card_tmp, \n",
    "                                                                        x_state_tmp,\n",
    "                                                                        legal_move_mask= legal_move_mask,\n",
    "                                                                        action = move_tmp)\n",
    "                else:\n",
    "                    _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n",
    "                                                            legal_move_mask= legal_move_mask,\n",
    "                                                            action = move_tmp)\n",
    "                # policy loss\n",
    "                # advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/(advantage_tmp.std() + 1e-8)\n",
    "                ratio = torch.exp(log_prob_new - log_prob_old).unsqueeze(dim = 1) # pi_new/pi_old\n",
    "                surrogate_1 = ratio*advantage_tmp\n",
    "                ratio_clamp = torch.clamp(ratio, 1 - e, 1 + e) # clipped ratio\n",
    "                surrogate_2 = ratio_clamp*advantage_tmp\n",
    "                policy_loss = -torch.min(surrogate_1, surrogate_2).mean() #FIX: is this adv detached? yes\n",
    "\n",
    "                # value loss\n",
    "                value_loss = ((value_new - discounted_reward)**2).mean()\n",
    "    \n",
    "                # entropy loss: to encourage exploration\n",
    "                entropy_loss = entropy.mean()\n",
    "                print(policy_loss, value_loss, entropy_loss)\n",
    "                loss = policy_loss + value_coef * value_loss - entropy_coef * entropy_loss\n",
    "                loss_record += loss.item()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.5) # FIX: check this\n",
    "                optimizer.step()\n",
    "    \n",
    "            print(f'Epoch: {epoch} - loss: {round(loss_record/index,2)}')\n",
    "    torch.save(model.state_dict(), f'./ppo_weight/hyperparam_tuning_{trial}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14dede",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b65913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:21.547192Z",
     "iopub.status.busy": "2025-04-19T14:25:21.546930Z",
     "iopub.status.idle": "2025-04-19T14:25:23.870722Z",
     "shell.execute_reply": "2025-04-19T14:25:23.870144Z",
     "shell.execute_reply.started": "2025-04-19T14:25:21.547173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 5e-4\n",
    "N_PLAYER = 3\n",
    "DATA_LENGTH = 5000\n",
    "N_CYCLE = 100\n",
    "N_EPOCH = 4\n",
    "GEN = 5\n",
    "e = 0.3 #clipping constant\n",
    "value_coef = 0.7\n",
    "entropy_coef = 0.03\n",
    "\n",
    "if GEN in [3, 3.5]:\n",
    "    model = ppo(N_PLAYER).to(device)\n",
    "elif GEN == 4:\n",
    "    model = ppo_gen_4(N_PLAYER).to(device)\n",
    "elif GEN == 5:\n",
    "    model = ppo_gen_5(N_PLAYER).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('./weight/hyperparam_tuning_0.pth'))\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f1f115b-092d-4c1d-9d68-b3adf6c29654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:23.872798Z",
     "iopub.status.busy": "2025-04-19T14:25:23.871909Z",
     "iopub.status.idle": "2025-04-19T14:25:23.875858Z",
     "shell.execute_reply": "2025-04-19T14:25:23.875216Z",
     "shell.execute_reply.started": "2025-04-19T14:25:23.872778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataloader_params = {'batch_size': BATCH_SIZE,\n",
    "          'shuffle': True,\n",
    "          'drop_last': True, # drop the last batch where the size could be 1\n",
    "          'collate_fn': collate_fn\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0bb4c8d-8159-4073-b1aa-46d9b022bc69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:23.876853Z",
     "iopub.status.busy": "2025-04-19T14:25:23.876586Z",
     "iopub.status.idle": "2025-04-19T14:25:23.893971Z",
     "shell.execute_reply": "2025-04-19T14:25:23.893337Z",
     "shell.execute_reply.started": "2025-04-19T14:25:23.876837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "game_length_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8f888",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-19T14:32:17.616228Z",
     "iopub.status.busy": "2025-04-19T14:32:17.615489Z",
     "iopub.status.idle": "2025-04-19T14:39:12.141346Z",
     "shell.execute_reply": "2025-04-19T14:39:12.140429Z",
     "shell.execute_reply.started": "2025-04-19T14:32:17.616194Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_flag = 1\n",
    "\n",
    "for cycle in range(N_CYCLE):\n",
    "    print(f'-------------CYCLE: {cycle}-------------')\n",
    "\n",
    "    # Rollout\n",
    "    training_data = []\n",
    "    game_length = []\n",
    "    while len(training_data) <= DATA_LENGTH:\n",
    "        nothanks = nothanks_ppo()\n",
    "\n",
    "        if GEN == 3:\n",
    "            play_buffer = nothanks.rollout(model, nothanks.get_state)\n",
    "            training_data_tmp = create_training_data(play_buffer)\n",
    "        elif GEN == 3.5:\n",
    "            play_buffer = nothanks.rollout(model, nothanks.get_state_gen_3_5)\n",
    "            training_data_tmp = create_training_data(play_buffer)\n",
    "        elif GEN == 5:\n",
    "            play_buffer = nothanks.rollout_gen_5(model)\n",
    "            training_data_tmp = create_training_data_gen_5(play_buffer)\n",
    "\n",
    "        game_length.append(len(training_data_tmp))\n",
    "        training_data.extend(training_data_tmp)\n",
    "    print(f'game length: {round(np.mean(game_length),0)}')\n",
    "    game_length_list.append(round(np.mean(game_length),0))\n",
    "    \n",
    "    # create a new data loader\n",
    "    train_data = dataset(training_data)\n",
    "    dataloader = DataLoader(train_data, **dataloader_params)\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(N_EPOCH):\n",
    "        loss_record = 0\n",
    "        # for index, (state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward) in enumerate(dataloader):\n",
    "        for index, input_data in enumerate(dataloader):\n",
    "            if GEN == 5:\n",
    "                x_card_tmp, x_state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = input_data\n",
    "            else:\n",
    "                state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = input_data\n",
    "            optimizer.zero_grad()\n",
    "            if GEN == 5:\n",
    "                _, log_prob_new, entropy, value_new = model.forward(x_card_tmp, \n",
    "                                                                    x_state_tmp,\n",
    "                                                                    legal_move_mask= legal_move_mask,\n",
    "                                                                    action = move_tmp)\n",
    "            else:\n",
    "                _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n",
    "                                                        legal_move_mask= legal_move_mask,\n",
    "                                                        action = move_tmp)\n",
    "            \n",
    "            # policy loss\n",
    "            # advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/(advantage_tmp.std() + 1e-8)\n",
    "            ratio = torch.exp(log_prob_new - log_prob_old).unsqueeze(dim = 1) # pi_new/pi_old\n",
    "            surrogate_1 = ratio*advantage_tmp\n",
    "            ratio_clamp = torch.clamp(ratio, 1 - e, 1 + e) # clipped ratio\n",
    "            surrogate_2 = ratio_clamp*advantage_tmp\n",
    "            policy_loss = -torch.min(surrogate_1, surrogate_2).mean() #FIX: is this adv detached? yes\n",
    "\n",
    "            # value loss\n",
    "            value_loss = ((value_new - discounted_reward)**2).mean()\n",
    "\n",
    "            # entropy loss: to encourage exploration\n",
    "            entropy_loss = entropy.mean()\n",
    "\n",
    "            loss = policy_loss + value_coef * value_loss - entropy_coef * entropy_loss\n",
    "            loss_record += loss.item()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.5) # FIX: check this\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch} - loss: {round(loss_record/index,2)}')\n",
    "        loss_list.append(loss_record//index)\n",
    "    torch.save(model.state_dict(), './ppo_weight/model_state_tmp.pth')\n",
    "    if cycle % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'./ppo_weight/model_local_gen_{GEN}_default_rwd_{cycle}_iter.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3da580-5a6b-4775-a454-b946cef1ca0f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T05:12:36.624295Z",
     "iopub.status.idle": "2025-04-19T05:12:36.624660Z",
     "shell.execute_reply": "2025-04-19T05:12:36.624486Z",
     "shell.execute_reply.started": "2025-04-19T05:12:36.624470Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "sns.lineplot([i.item() for i in loss_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "sns.lineplot([i.item() for i in game_length_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be777e5b-c2d6-4e05-bb6d-5f3edda4b323",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138a360-0b2d-403e-bd90-17070754e5b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T05:12:36.634967Z",
     "iopub.status.idle": "2025-04-19T05:12:36.635219Z",
     "shell.execute_reply": "2025-04-19T05:12:36.635115Z",
     "shell.execute_reply.started": "2025-04-19T05:12:36.635100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f63e88cd-5c9c-45e0-96e7-01aa6d0f9178",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T05:12:36.637541Z",
     "iopub.status.idle": "2025-04-19T05:12:36.637828Z",
     "shell.execute_reply": "2025-04-19T05:12:36.637681Z",
     "shell.execute_reply.started": "2025-04-19T05:12:36.637666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f'./ppo_weight/trained_model/model_gen_5_default_rwd_57_iter.pth'\n",
    "\n",
    "\n",
    "\n",
    "if 'gen_3' in path:\n",
    "    model = ppo(N_PLAYER).to(device)\n",
    "    GEN = 3\n",
    "    if 'gen_3_5' in path:\n",
    "        GEN = 3.5\n",
    "elif 'gen_4' in path:\n",
    "    model = ppo_gen_4(N_PLAYER).to(device)\n",
    "    GEN = 4\n",
    "elif 'gen_5' in path:\n",
    "    model = ppo_gen_5(N_PLAYER).to(device)\n",
    "    GEN = 5\n",
    "\n",
    "model.load_state_dict(torch.load(path, map_location = torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ea02b",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570417da-dfd9-4789-a587-e661bd2f148c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-19T14:04:19.116939Z",
     "iopub.status.busy": "2025-04-19T14:04:19.116634Z",
     "iopub.status.idle": "2025-04-19T14:04:19.142878Z",
     "shell.execute_reply": "2025-04-19T14:04:19.141450Z",
     "shell.execute_reply.started": "2025-04-19T14:04:19.116918Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "move_encode = {\"0\": \"pass\",\n",
    "                \"1\": \"take\"}\n",
    "nothanks = nothanks_ppo()\n",
    "human_index = 5\n",
    "\n",
    "while nothanks.is_continue:\n",
    "    print('------------------------------')\n",
    "    print(f'''Card: {nothanks.current_card} | Chip in pot: {nothanks.chip_in_pot} | Player: {nothanks.turn} - {nothanks.players[nothanks.turn]}\\n'''\n",
    ")\n",
    "    print('------------------------------')\n",
    "    if nothanks.turn == human_index:\n",
    "        move = move_encode.get(input(\"\"\"Your turn:\n",
    "0: pass\n",
    "1: take\n",
    "Enter here: \"\"\"))\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            if GEN != 5:\n",
    "                if GEN == 3:\n",
    "                    current_state = torch.tensor(nothanks.encode_state(nothanks.get_state)).to(device)\n",
    "                elif GEN in (3.5, 4):\n",
    "                    current_state = torch.tensor(nothanks.encode_state(nothanks.get_state_gen_3_5)).to(device)                    \n",
    "                legal_move = nothanks.get_legal_action() # a list \n",
    "                legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n",
    "                move_raw, log_prob, entropy, value = model.forward(current_state, legal_move_mask)\n",
    "            else:\n",
    "                x_card, x_state = nothanks.encode_state_gen_5()\n",
    "                x_card = torch.Tensor(x_card).unsqueeze(1).to(device) #1 for 5,33 -> 5,1,33 | 0 for 5,1,33 -> 1,5,1,33\n",
    "                x_state = torch.tensor(x_state).to(device) # 8 to 1,8\n",
    "                legal_move = nothanks.get_legal_action() # a list \n",
    "                legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n",
    "                move_raw, log_prob, entropy, value = model.forward(x_card, x_state, legal_move_mask)\n",
    "            move = nothanks.move_encode.get(move_raw.item())\n",
    "\n",
    "    print(f'Move taken: {move}')\n",
    "    nothanks.action(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e0c7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 3, 5, 26, 24, 12, 6, 11, 22]\n",
      "[33, 35, 30, 9, 10, 15, 14, 8, 32, 34]\n",
      "[19, 18, 28, 20, 17]\n"
     ]
    }
   ],
   "source": [
    "# End-game hand\n",
    "for player_tmp in nothanks.players:\n",
    "    print(player_tmp.card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03988333-1df4-4521-8044-1ed1277389ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:31:39.917479Z",
     "iopub.status.busy": "2025-04-19T14:31:39.917278Z",
     "iopub.status.idle": "2025-04-19T14:31:39.920866Z",
     "shell.execute_reply": "2025-04-19T14:31:39.920171Z",
     "shell.execute_reply.started": "2025-04-19T14:31:39.917463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-60\n",
      "-57\n",
      "-44\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "for player_tmp in nothanks.players:\n",
    "    print(player_tmp.calculate_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d8199ca-ec52-4932-bb96-0bb4e41a6fde",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T05:12:36.641368Z",
     "iopub.status.idle": "2025-04-19T05:12:36.641555Z",
     "shell.execute_reply": "2025-04-19T05:12:36.641473Z",
     "shell.execute_reply.started": "2025-04-19T05:12:36.641465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(-20.0), np.float64(0.0), np.float64(20.0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking - endgame reward\n",
    "nothanks.calculate_ranking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b0e15-b5b2-4330-88ba-9935285e4b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T05:01:47.951447Z",
     "iopub.status.busy": "2025-04-17T05:01:47.951202Z",
     "iopub.status.idle": "2025-04-17T05:01:47.957353Z",
     "shell.execute_reply": "2025-04-17T05:01:47.956611Z",
     "shell.execute_reply.started": "2025-04-17T05:01:47.951429Z"
    }
   },
   "source": [
    "# Pitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8de9adc-e99f-4179-a0a3-a0ed7808d4b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:39:31.144708Z",
     "iopub.status.busy": "2025-04-19T14:39:31.144481Z",
     "iopub.status.idle": "2025-04-19T14:39:31.149432Z",
     "shell.execute_reply": "2025-04-19T14:39:31.148762Z",
     "shell.execute_reply.started": "2025-04-19T14:39:31.144692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_prefix = 'model_gen_5_5_default_rwd'\n",
    "# model_prefix = 'hyperparam_tuning_'\n",
    "model_list = [i for i in os.listdir('./ppo_weight/trained_model/') if i.startswith(model_prefix)]\n",
    "# model_list = ['model_gen_3_default_rwd_50_iter.pth',\n",
    "#               'model_gen_3_default_rwd_60_iter.pth',\n",
    "#               'model_gen_3_default_rwd_80_iter.pth',\n",
    "#              ]\n",
    "model_name_dict = {a:b for a, b in enumerate(model_list)}\n",
    "n_model = len(model_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46581afe-719a-4403-be80-789a403fd652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:39:31.904229Z",
     "iopub.status.busy": "2025-04-19T14:39:31.904054Z",
     "iopub.status.idle": "2025-04-19T14:39:31.907857Z",
     "shell.execute_reply": "2025-04-19T14:39:31.907219Z",
     "shell.execute_reply.started": "2025-04-19T14:39:31.904215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "select_record = {i:0 for i in range(n_model)}\n",
    "win_record = {i:0 for i in range(n_model)}\n",
    "move_encode = {\"0\": \"pass\",\n",
    "                \"1\": \"take\"}\n",
    "\n",
    "n_match = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4881e608",
   "metadata": {},
   "source": [
    "## Pitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "146842f3-3f0b-4bf1-bbbd-b3adbe774589",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-19T14:19:45.452643Z",
     "iopub.status.busy": "2025-04-19T14:19:45.452292Z",
     "iopub.status.idle": "2025-04-19T14:19:45.486778Z",
     "shell.execute_reply": "2025-04-19T14:19:45.485411Z",
     "shell.execute_reply.started": "2025-04-19T14:19:45.452619Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:01<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(n_match)):\n",
    "    \n",
    "    model_index = random.sample(range(n_model), k = 3)        \n",
    "    for index in model_index:\n",
    "        select_record[index] += 1\n",
    "    model_list = []\n",
    "    for index in model_index:\n",
    "        path = f'./ppo_weight/trained_model/{model_name_dict.get(index)}'\n",
    "        if 'gen_3' in path:\n",
    "            model = ppo(N_PLAYER).to(device)\n",
    "            GEN = 3\n",
    "            if 'gen_3_5' in path:\n",
    "                GEN = 3.5\n",
    "        elif 'gen_4' in path:\n",
    "            model = ppo_gen_4(N_PLAYER).to(device)\n",
    "            GEN = 4\n",
    "        elif 'gen_5' in path:\n",
    "            model = ppo_gen_5(N_PLAYER).to(device)\n",
    "            GEN = 5\n",
    "        \n",
    "        model.load_state_dict(torch.load(path, map_location = torch.device(device)))\n",
    "        model_list.append(model)\n",
    "    \n",
    "    \n",
    "    nothanks = nothanks_ppo()\n",
    "    while nothanks.is_continue:\n",
    "        with torch.no_grad():\n",
    "            if GEN != 5:\n",
    "                if GEN == 3:\n",
    "                    current_state = torch.tensor(nothanks.encode_state(nothanks.get_state)).to(device)\n",
    "                elif GEN in (3.5, 4):\n",
    "                    current_state = torch.tensor(nothanks.encode_state(nothanks.get_state_gen_3_5)).to(device)                    \n",
    "                legal_move = nothanks.get_legal_action() # a list \n",
    "                legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n",
    "                move_raw, log_prob, entropy, value = model.forward(current_state, legal_move_mask)\n",
    "            else:\n",
    "                x_card, x_state = nothanks.encode_state_gen_5()\n",
    "                x_card = torch.Tensor(x_card).unsqueeze(1).to(device) #1 for 5,33 -> 5,1,33 | 0 for 5,1,33 -> 1,5,1,33\n",
    "                x_state = torch.tensor(x_state).to(device) # 8 to 1,8\n",
    "                legal_move = nothanks.get_legal_action() # a list \n",
    "                legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n",
    "                move_raw, log_prob, entropy, value = model.forward(x_card, x_state, legal_move_mask)\n",
    "            move = nothanks.move_encode.get(move_raw.item())\n",
    "        nothanks.action(move)    \n",
    "    \n",
    "    winner_index = np.argmax(nothanks.calculate_ranking())\n",
    "    win_record[model_index[winner_index]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "323c13dc-5c0d-45bf-9f1c-dbfbf4044322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:41:56.800493Z",
     "iopub.status.busy": "2025-04-19T14:41:56.800231Z",
     "iopub.status.idle": "2025-04-19T14:41:56.835626Z",
     "shell.execute_reply": "2025-04-19T14:41:56.834928Z",
     "shell.execute_reply.started": "2025-04-19T14:41:56.800472Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>total</th>\n",
       "      <th>win</th>\n",
       "      <th>win_pct</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>model_gen_5_5_default_rwd_37_iter.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>model_gen_5_5_default_rwd_38_iter.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>model_gen_5_5_default_rwd_58_iter.pth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  total  win  win_pct                             model_name\n",
       "0      0     10    5      0.5  model_gen_5_5_default_rwd_37_iter.pth\n",
       "1      1     10    3      0.3  model_gen_5_5_default_rwd_38_iter.pth\n",
       "2      2     10    2      0.2  model_gen_5_5_default_rwd_58_iter.pth"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([select_record, win_record]).T\\\n",
    ".rename(columns = {0: 'total',\n",
    "         1: 'win'\n",
    "        })\\\n",
    ".assign(win_pct = lambda df: df['win']/df['total'])\\\n",
    ".sort_values('win_pct', ascending = False)\\\n",
    ".reset_index()\\\n",
    ".assign(model_name = lambda df: df['index'].apply(lambda x: model_name_dict.get(x)))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7175487,
     "sourceId": 11452216,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 307707,
     "modelInstanceId": 286894,
     "sourceId": 342981,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 308514,
     "modelInstanceId": 287724,
     "sourceId": 344038,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
