{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a345ea-dd69-438d-accc-1eeb4fe996c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:30.825721Z",
     "iopub.status.busy": "2025-04-19T14:23:30.825449Z",
     "iopub.status.idle": "2025-04-19T14:23:30.855348Z",
     "shell.execute_reply": "2025-04-19T14:23:30.854653Z",
     "shell.execute_reply.started": "2025-04-19T14:23:30.825700Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Training PPO\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82cbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dda7e44-ac20-4ee9-9ae5-772c0944474a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:37.274309Z",
     "iopub.status.busy": "2025-04-19T14:23:37.273941Z",
     "iopub.status.idle": "2025-04-19T14:23:37.359716Z",
     "shell.execute_reply": "2025-04-19T14:23:37.358942Z",
     "shell.execute_reply.started": "2025-04-19T14:23:37.274288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de52ca57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:37.360952Z",
     "iopub.status.busy": "2025-04-19T14:23:37.360644Z",
     "iopub.status.idle": "2025-04-19T14:23:37.384876Z",
     "shell.execute_reply": "2025-04-19T14:23:37.384206Z",
     "shell.execute_reply.started": "2025-04-19T14:23:37.360921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8fdb3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43a060",
   "metadata": {},
   "source": [
    "## Gen 3 - 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "435fe918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:37.386940Z",
     "iopub.status.busy": "2025-04-19T14:23:37.386266Z",
     "iopub.status.idle": "2025-04-19T14:23:37.393813Z",
     "shell.execute_reply": "2025-04-19T14:23:37.393174Z",
     "shell.execute_reply.started": "2025-04-19T14:23:37.386916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ppo(nn.Module):\n",
    "    def __init__(self, n_player, n_card = 33):\n",
    "        super().__init__()\n",
    "        self.n_action = 2\n",
    "        self.n_card = n_card\n",
    "        self.n_player = n_player\n",
    "        self.n_param_per_player = self.n_card + 1 # 33 cards + 1 number of chips\n",
    "        self.n_state_param = self.n_card*2 + 5 # 33 for flipped card, 33 for remain card, 1 for chip in pot, 1 for number of cards remained, 1 for good card self, 1 for good card other, 1 for chipinpot/current\n",
    "        self.input_dim = self.n_player*self.n_param_per_player + self.n_state_param\n",
    "        \n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, self.n_action)\n",
    "            )\n",
    "        \n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, 1)\n",
    "            )\n",
    "    \n",
    "    def get_policy(self, X, legal_move_mask):\n",
    "        \"\"\"Mask the legal output\n",
    "        legal_move_mask: boolean tensor, True for masked\"\"\"\n",
    "        logit = self.policy(X)\n",
    "        logit_masked = logit.masked_fill(legal_move_mask, float('-inf'))\n",
    "        return logit_masked\n",
    "\n",
    "    def forward(self, X, legal_move_mask, action = None):\n",
    "        \"\"\"Get value, probability\n",
    "        legal_move_mask: boolean tensor\n",
    "        action: tensor(1) Integer. This is the old sampled action. If none will do sampling\n",
    "        \"\"\"\n",
    "        logit = self.get_policy(X, legal_move_mask)\n",
    "        prob = Categorical(logits = logit)\n",
    "        if action == None:\n",
    "            action = prob.sample() # sample the action\n",
    "        log_prob = prob.log_prob(action) # this will be used for surrogate loss (log(a) - log(b) = log(a/b))\n",
    "        value = self.value(X)\n",
    "\n",
    "        return action, log_prob, prob.entropy(), value # sampled action, log probability of it, its entropy,value from value network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb0f1b",
   "metadata": {},
   "source": [
    "## Gen 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e3e7c35-ac68-437f-83b4-35e4136280ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:37.394959Z",
     "iopub.status.busy": "2025-04-19T14:23:37.394733Z",
     "iopub.status.idle": "2025-04-19T14:23:37.408767Z",
     "shell.execute_reply": "2025-04-19T14:23:37.408093Z",
     "shell.execute_reply.started": "2025-04-19T14:23:37.394938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gen 4 - collapsing opponents\n",
    "\n",
    "class ppo_gen_4(ppo):\n",
    "    def __init__(self, n_player, n_card = 33):\n",
    "        super().__init__(n_player, n_card)\n",
    "        # self.n_action = 2\n",
    "        # self.n_card = n_card\n",
    "        # self.n_player = n_player\n",
    "        self.n_param_per_player = self.n_card + 1 # 33 cards + 1 number of chips\n",
    "        self.n_state_param = self.n_card*2 + 5 # 33 for flipped card, 33 for remain card, 1 for chip in pot, 1 for number of cards remained, 1 for good card self, 1 for good card other, 1 for chipinpot/current\n",
    "        self.input_dim = 2*self.n_param_per_player + self.n_state_param # 2 because 1 for self, 1 for opponents\n",
    "        \n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, self.n_action)\n",
    "            )\n",
    "        \n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, 1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be023fba",
   "metadata": {},
   "source": [
    "## Gen 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c3934f4-a83d-4421-ad1d-128468a1f4fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:38.775214Z",
     "iopub.status.busy": "2025-04-19T14:23:38.774945Z",
     "iopub.status.idle": "2025-04-19T14:23:38.780307Z",
     "shell.execute_reply": "2025-04-19T14:23:38.779521Z",
     "shell.execute_reply.started": "2025-04-19T14:23:38.775194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Flatten_custom(nn.Module):\n",
    "    def __init__(self, start_dim_batch: int = 1, start_dim_unbatch: int = 0, end_dim: int = -1) -> None:\n",
    "        super().__init__()\n",
    "        self.start_dim_batch = start_dim_batch\n",
    "        self.start_dim_unbatch = start_dim_unbatch\n",
    "        self.end_dim = end_dim\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 4:\n",
    "            return x.flatten(self.start_dim_batch, self.end_dim)\n",
    "        else:\n",
    "            return x.flatten(self.start_dim_unbatch, self.end_dim)\n",
    "\n",
    "flatten_custom  = Flatten_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "811e1918-0b96-4ae6-a3d8-4d0de3530ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:23:39.527734Z",
     "iopub.status.busy": "2025-04-19T14:23:39.527483Z",
     "iopub.status.idle": "2025-04-19T14:23:39.539268Z",
     "shell.execute_reply": "2025-04-19T14:23:39.538520Z",
     "shell.execute_reply.started": "2025-04-19T14:23:39.527713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ppo_gen_5(ppo):\n",
    "    def __init__(self, n_player, n_card = 33):\n",
    "        super().__init__(n_player, n_card)\n",
    "        self.in_channel = n_player + 2 # 1 for flipped card, 1 for remaining cards\n",
    "        self.out_channel = 16\n",
    "        self.n_state_param = n_player + 5 # 1 for chip in pot, 1 for number of cards remained, 1 for good card self, 1 for good card other, 1 for chipinpot/current\n",
    "        self.flatten_dimension = 512 # hard code\n",
    "        self.gen = 5\n",
    "        self.flatten_custom = Flatten_custom()\n",
    "\n",
    "        \n",
    "        self.cnn_policy = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels = self.in_channel,\n",
    "            out_channels = self.out_channel,\n",
    "            kernel_size = (1, 3)\n",
    "            ),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            Flatten_custom()\n",
    "        )\n",
    "\n",
    "        self.linear_state_policy = nn.Sequential(\n",
    "            nn.Linear(self.n_state_param, 16),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "        )\n",
    "        \n",
    "        self.ff_policy = nn.Sequential(\n",
    "            nn.Linear(self.flatten_dimension, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, self.n_action)\n",
    "            )\n",
    "        \n",
    "        self.cnn_value = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels = self.in_channel,\n",
    "            out_channels = self.out_channel,\n",
    "            kernel_size = (1, 3)\n",
    "            ),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            Flatten_custom()\n",
    "        )\n",
    "\n",
    "        self.linear_state_value = nn.Linear(self.n_state_param, 16)\n",
    "\n",
    "        self.ff_value = nn.Sequential(\n",
    "            nn.Linear(self.flatten_dimension, 256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(128, 1)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward_concat(self, x_card, x_state, cnn_layer, linear_layer):\n",
    "        x_card_flat = cnn_layer(x_card)\n",
    "        x_state_flat = linear_layer(x_state)\n",
    "        if len(x_card_flat.shape) == 1:\n",
    "            dim = 0\n",
    "        else:\n",
    "            dim = 1\n",
    "        return torch.cat([x_card_flat, x_state_flat], dim = dim)\n",
    "\n",
    "    def get_policy(self, x_card, x_state, legal_move_mask):\n",
    "        \"\"\"Mask the legal output\n",
    "        legal_move_mask: boolean tensor, True for masked\"\"\"\n",
    "        policy_concat = self.forward_concat(x_card, x_state, self.cnn_policy, self.linear_state_policy) # flattened + concat\n",
    "        logit = self.ff_policy(policy_concat)\n",
    "        logit_masked = logit.masked_fill(legal_move_mask, float('-inf'))\n",
    "        return logit_masked\n",
    "\n",
    "    def get_value(self, x_card, x_state):\n",
    "        value_concat = self.forward_concat(x_card, x_state, self.cnn_value, self.linear_state_value) # flattened + concat\n",
    "        value = self.ff_value(value_concat)\n",
    "        return value\n",
    "\n",
    "    def forward(self, x_card, x_state, legal_move_mask, action = None):\n",
    "        \"\"\"Get value, probability\n",
    "        legal_move_mask: boolean tensor\n",
    "        action: tensor(1) Integer. This is the old sampled action. If none will do sampling\n",
    "        \"\"\"\n",
    "        logit = self.get_policy(x_card, x_state, legal_move_mask)\n",
    "        prob = Categorical(logits = logit)\n",
    "        if action == None:\n",
    "            action = prob.sample() # sample the action\n",
    "        log_prob = prob.log_prob(action) # this will be used for surrogate loss (log(a) - log(b) = log(a/b))\n",
    "\n",
    "        value = self.get_value(x_card, x_state)\n",
    "        \n",
    "        return action, log_prob, prob.entropy(), value # sampled action, log probability of it, its entropy,value from value network\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1257888",
   "metadata": {},
   "source": [
    "# Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22836843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:24:54.382889Z",
     "iopub.status.busy": "2025-04-19T14:24:54.382306Z",
     "iopub.status.idle": "2025-04-19T14:24:54.491367Z",
     "shell.execute_reply": "2025-04-19T14:24:54.490645Z",
     "shell.execute_reply.started": "2025-04-19T14:24:54.382859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class nothanks_ppo(game):\n",
    "    def __init__(self, card = None):\n",
    "        super().__init__(card)\n",
    "        self.move_encode = {0: 'pass',\n",
    "                            1: 'take'\n",
    "                            }\n",
    "        \n",
    "    def rotate_player(self, turn):\n",
    "        player_list = list(range(self.n_player))\n",
    "        return player_list[turn:] + player_list[:turn]\n",
    "        \n",
    "        \n",
    "    def get_state(self):\n",
    "        # Get info about the state to save it\n",
    "        player_info = []\n",
    "        for player in self.players:\n",
    "            player_info.append((player.card, player.chip))\n",
    "        return player_info, self.turn, self.remain_card, self.chip_in_pot, self.current_card\n",
    "\n",
    "    def get_state_gen_3_5(self):\n",
    "        \"\"\"rotate player\"\"\"\n",
    "        player_info = []\n",
    "        player_list = self.rotate_player(self.turn)\n",
    "        for player_index in player_list:\n",
    "            player = self.players[player_index]\n",
    "            player_info.append((player.card, player.chip))\n",
    "        return player_info, self.turn, self.remain_card, self.chip_in_pot, self.current_card\n",
    "\n",
    "    def get_state_gen_4(self):\n",
    "        \"\"\"Rotate player + Collapse opponents\"\"\"\n",
    "        player_info = []\n",
    "        player_list = self.rotate_player(self.turn)\n",
    "\n",
    "        # self\n",
    "        player_index = player_list[0]\n",
    "        player = self.players[player_index]\n",
    "        player_info.append((player.card, player.chip))\n",
    "\n",
    "        #opponent\n",
    "        opponent_card = []\n",
    "        min_chip = 100\n",
    "        for player_index in player_list[1:]:\n",
    "            player = self.players[player_index]\n",
    "            opponent_card.extend(player.card)\n",
    "            if player.chip < min_chip:\n",
    "                min_chip = player.chip\n",
    "        player_info.append((opponent_card, min_chip))\n",
    "        return player_info, self.turn, self.remain_card, self.chip_in_pot, self.current_card\n",
    "        \n",
    "    \n",
    "    def encode_card(self, card_list: list) -> list:\n",
    "        \"\"\"Encode the card list to binaries\"\"\"\n",
    "        encode = [0]* len(self.full_deck)\n",
    "        for card in card_list:\n",
    "            encode[card - self.min_card] = 1\n",
    "        return encode\n",
    "    \n",
    "    # def encode_turn(self, turn) -> list:\n",
    "    #     return [1 if i == turn else 0 for i in range(self.n_player)]\n",
    "\n",
    "    def check_favorable_self(self):\n",
    "        player_tmp = self.players[self.turn]\n",
    "        if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def check_favorable_other(self):\n",
    "        other_player = [player_tmp for index, player_tmp in enumerate(self.players) if index != self.turn]\n",
    "        check = []\n",
    "        for player_tmp in other_player:\n",
    "            if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n",
    "                check.append(1)\n",
    "            else:\n",
    "                check.append(0)\n",
    "        return max(check)\n",
    "        \n",
    "    \n",
    "    def encode_state(self, func):\n",
    "        \"\"\"Feature engineering here\"\"\"\n",
    "        player_info, turn, remain_card, chip_in_pot, current_card = func()\n",
    "        result = []\n",
    "        for player_card, chip in player_info:\n",
    "            chip_tmp = chip/max(self.full_deck)\n",
    "            card_tmp = self.encode_card(player_card)\n",
    "            \n",
    "            result.extend(card_tmp)\n",
    "            result.append(chip_tmp)\n",
    "        \n",
    "        # result.extend(self.encode_turn(self.turn))\n",
    "        result.extend(self.encode_card([current_card]))\n",
    "        result.append(chip_in_pot/max(self.full_deck))\n",
    "        result.extend(self.encode_card(remain_card))\n",
    "        result.append((len(self.remain_card) - self.n_remove_card)/(len(self.full_deck) - self.n_remove_card))\n",
    "        result.append(self.check_favorable_self())\n",
    "\n",
    "        #new\n",
    "        result.append(self.check_favorable_other())\n",
    "        result.append(chip_in_pot/self.current_card)\n",
    "        # player_a, chip_a, ..., player_n, chip_n, turn, current_card, chip, remain_card, n_legal_remain_card, good card self, good card opponent, chip_in_pot/current_card\n",
    "        return result\n",
    "\n",
    "    def encode_state_gen_5(self):\n",
    "        \"\"\"Feature engineering here\"\"\"\n",
    "        # player_info, turn, remain_card, chip_in_pot, current_card = self.get_state()\n",
    "        player_info, turn, remain_card, chip_in_pot, current_card = self.get_state_gen_3_5()\n",
    "        \n",
    "\n",
    "        x_card = [self.encode_card(player_card) for player_card, _ in player_info]\n",
    "        x_card.append(self.encode_card([current_card]))\n",
    "        x_card.append(self.encode_card(remain_card))\n",
    "        \n",
    "        x_state = [chip/max(self.full_deck) for _, chip in player_info]\n",
    "        x_state.append(chip_in_pot/max(self.full_deck))\n",
    "        x_state.append((len(self.remain_card) - self.n_remove_card)/(len(self.full_deck) - self.n_remove_card))\n",
    "        x_state.append(self.check_favorable_self())\n",
    "        x_state.append(self.check_favorable_other())\n",
    "        x_state.append(chip_in_pot/self.current_card)\n",
    "        \n",
    "        # player_a, chip_a, ..., player_n, chip_n, turn, current_card, chip, remain_card, n_legal_remain_card, good card self, good card opponent, chip_in_pot/current_card\n",
    "        return x_card, x_state\n",
    "\n",
    "    \n",
    "    def calculate_reward_2(self, action):\n",
    "        player_tmp = self.players[self.turn]\n",
    "        \n",
    "        if action == 'pass':\n",
    "            # pass over half of the card value and the card is favorable is bad, punish for being too greedy\n",
    "            if any(abs(self.current_card - card_tmp) == 1 for card_tmp in player_tmp.card):\n",
    "                if self.chip_in_pot >= self.current_card//2:\n",
    "                    return -3\n",
    "            return -0.2  # light discouragement to avoid infinite pass\n",
    "    \n",
    "        if action == 'take':\n",
    "            \n",
    "            # Penalize taking too late or too early\n",
    "            if player_tmp.chip == 0:\n",
    "                return -2\n",
    "            if self.chip_in_pot == 0:\n",
    "                return -2\n",
    "                \n",
    "            reward = 0\n",
    "\n",
    "            # Reward for taking early in the game\n",
    "            if self.chip_in_pot < self.current_card and len(player_tmp.card) < 4:\n",
    "                reward += (self.chip_in_pot / (self.current_card + 1)) * 3\n",
    "    \n",
    "            # Encourage sequential cards\n",
    "            if any(abs(self.current_card - card_tmp) <= 3 for card_tmp in player_tmp.card):\n",
    "                reward += 2\n",
    "    \n",
    "            # Penalty for taking later in the game\n",
    "            distance_threshold = 4\n",
    "            if len(player_tmp.card) > 4:\n",
    "                dist = min(abs(self.current_card - c) for c in player_tmp.card)\n",
    "                if dist > distance_threshold:\n",
    "                    reward -= (dist - distance_threshold) * 0.5\n",
    "            return reward\n",
    "    \n",
    "    def calculate_reward_3(self, action):\n",
    "        return 0\n",
    "                \n",
    "    def reward_func(self, move):\n",
    "        return self.calculate_reward_3(move)\n",
    "                \n",
    "    def rollout(self, model, func, n_game = None):\n",
    "        \"\"\"Play games, save state\n",
    "        Need to get the turn\n",
    "        \"\"\"\n",
    "        random_chance = 0.99\n",
    "        # FIX: need to send 1 terminal state for each player:\n",
    "        playing_buffer = {i: [] for i in range(self.n_player)}\n",
    "        i = 0\n",
    "        while self.is_continue:\n",
    "            current_state = torch.tensor(self.encode_state(func)).to(device)\n",
    "            legal_move = self.get_legal_action() # a list \n",
    "            legal_move_mask = torch.tensor([False if move in legal_move else True for move in self.move_encode.values()]).to(device)\n",
    "            random_move = None\n",
    "            if random.random() > random_chance:\n",
    "                random_move = torch.tensor(random.choice([0 if move == 'pass' else 1 for move in legal_move])).to(device)\n",
    "            with torch.no_grad():\n",
    "                move_raw, log_prob, entropy, value = model.forward(current_state, legal_move_mask, random_move)\n",
    "            move = self.move_encode.get(move_raw.item())\n",
    "            reward = torch.tensor([self.reward_func(move)]).to(device)\n",
    "            playing_buffer[self.turn].append([current_state, move_raw, legal_move_mask, log_prob, value, reward]) # if this change, need to change the hard code\n",
    "            # move\n",
    "            self.is_continue = self.action(move)\n",
    "        final_reward = self.calculate_ranking()\n",
    "\n",
    "        for player in range(self.n_player):\n",
    "            playing_buffer[player].append([None, None, None, None, None, final_reward[player]])  # if this change, need to change the hard code\n",
    "            # playing_buffer[player].append([None, None, None, None, None, -self.players[player].calculate_score() ])  # if this change, need to change the hard code\n",
    "        return playing_buffer\n",
    "\n",
    "    def rollout_gen_5(self, model, n_game = None):\n",
    "        \"\"\"Play games, save state\n",
    "        Need to get the turn\n",
    "        \"\"\"\n",
    "        random_chance = 0.99\n",
    "        # FIX: need to send 1 terminal state for each player:\n",
    "        playing_buffer = {i: [] for i in range(self.n_player)}\n",
    "        i = 0\n",
    "        while self.is_continue:\n",
    "            \n",
    "            x_card, x_state = self.encode_state_gen_5()\n",
    "            # print(torch.Tensor(x_card).shape)\n",
    "            x_card = torch.Tensor(x_card).unsqueeze(1).to(device) #1 for 5,33 -> 5,1,33 | 0 for 5,1,33 -> 1,5,1,33\n",
    "            x_state = torch.tensor(x_state).to(device) # 8 to 1,8\n",
    "            # print(x_card.shape)\n",
    "            # print(x_state.shape)\n",
    "            legal_move = self.get_legal_action() # a list \n",
    "            legal_move_mask = torch.tensor([False if move in legal_move else True for move in self.move_encode.values()]).to(device)\n",
    "            # print(legal_move_mask.shape)\n",
    "            random_move = None\n",
    "            if random.random() > random_chance:\n",
    "                random_move = torch.tensor(random.choice([0 if move == 'pass' else 1 for move in legal_move])).to(device)\n",
    "            with torch.no_grad():\n",
    "                move_raw, log_prob, entropy, value = model.forward(x_card, x_state, legal_move_mask, random_move)\n",
    "            move = self.move_encode.get(move_raw.item())\n",
    "            reward = torch.tensor([self.reward_func(move)]).to(device)\n",
    "            playing_buffer[self.turn].append([x_card,x_state, move_raw, legal_move_mask, log_prob, value, reward]) # if this change, need to change the hard code\n",
    "            # move\n",
    "            self.is_continue = self.action(move)\n",
    "        final_reward = self.calculate_ranking()\n",
    "\n",
    "        for player in range(self.n_player):\n",
    "            playing_buffer[player].append([None, None, None, None, None, None, final_reward[player]])  # if this change, need to change the hard code\n",
    "            # playing_buffer[player].append([None, None, None, None, None, -self.players[player].calculate_score() ])  # if this change, need to change the hard code\n",
    "        return playing_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf9b07",
   "metadata": {},
   "source": [
    "# Calculate targets & create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4e455da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:12:11.757281Z",
     "iopub.status.busy": "2025-04-19T13:12:11.756946Z",
     "iopub.status.idle": "2025-04-19T13:12:11.763786Z",
     "shell.execute_reply": "2025-04-19T13:12:11.762800Z",
     "shell.execute_reply.started": "2025-04-19T13:12:11.757256Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gen 4\n",
    "\n",
    "def create_training_data(play_buffer, gamma = 0.99, reward_index = -1):\n",
    "    \"\"\"\n",
    "    gamma: discount constant\n",
    "    reward_index: index of reward returned in the play buffer\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for _, player_data in play_buffer.items():\n",
    "        discounted_reward = player_data[-1][reward_index] # take the reward of the last stage. At the end of the game, all players receive 1 more step containing the final reward (final rank)\n",
    "        for index in reversed(range(len(player_data) - 1)): # go from back to front, skip the final step\n",
    "\n",
    "            state_tmp, move_tmp, legal_move_mask, log_prob_tmp, value_tmp, reward_tmp = player_data[index]\n",
    "            \n",
    "            # discounted reward\n",
    "            discounted_reward = reward_tmp + discounted_reward*gamma\n",
    "\n",
    "            #advantage\n",
    "            advantage_tmp = discounted_reward - value_tmp\n",
    "            # advantage_target = [advantage_tmp] + advantage_target # need to detach this at policy loss\n",
    "\n",
    "            # policy_old = [policy_tmp] + policy_old # need to detach this at policy loss\n",
    "            training_data.append([state_tmp, move_tmp, legal_move_mask, log_prob_tmp, advantage_tmp, discounted_reward]) #state, action, sampled action, advantage, discounted_reward (aka return)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "326a5b4a-200b-4eba-b1fb-05d386948757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:04.711132Z",
     "iopub.status.busy": "2025-04-19T14:25:04.710401Z",
     "iopub.status.idle": "2025-04-19T14:25:04.715990Z",
     "shell.execute_reply": "2025-04-19T14:25:04.715145Z",
     "shell.execute_reply.started": "2025-04-19T14:25:04.711098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gen 5\n",
    "def create_training_data_gen_5(play_buffer, gamma = 0.99, reward_index = -1):\n",
    "    \"\"\"\n",
    "    gamma: discount constant\n",
    "    reward_index: index of reward returned in the play buffer\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for _, player_data in play_buffer.items():\n",
    "        discounted_reward = player_data[-1][reward_index] # take the reward of the last stage. At the end of the game, all players receive 1 more step containing the final reward (final rank)\n",
    "        for index in reversed(range(len(player_data) - 1)): # go from back to front, skip the final step\n",
    "\n",
    "            x_card_tmp, x_state_tmp, move_tmp, legal_move_mask, log_prob_tmp, value_tmp, reward_tmp = player_data[index]\n",
    "            \n",
    "            # discounted reward\n",
    "            discounted_reward = reward_tmp + discounted_reward*gamma\n",
    "\n",
    "            #advantage\n",
    "            advantage_tmp = discounted_reward - value_tmp\n",
    "            # advantage_target = [advantage_tmp] + advantage_target # need to detach this at policy loss\n",
    "\n",
    "            # policy_old = [policy_tmp] + policy_old # need to detach this at policy loss\n",
    "            training_data.append([x_card_tmp, x_state_tmp, move_tmp, legal_move_mask, log_prob_tmp, advantage_tmp, discounted_reward]) #state, action, sampled action, advantage, discounted_reward (aka return)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09062f4",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11afd372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:11.056561Z",
     "iopub.status.busy": "2025-04-19T14:25:11.056301Z",
     "iopub.status.idle": "2025-04-19T14:25:11.060775Z",
     "shell.execute_reply": "2025-04-19T14:25:11.060102Z",
     "shell.execute_reply.started": "2025-04-19T14:25:11.056541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b299655d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:11.158941Z",
     "iopub.status.busy": "2025-04-19T14:25:11.158363Z",
     "iopub.status.idle": "2025-04-19T14:25:11.162512Z",
     "shell.execute_reply": "2025-04-19T14:25:11.161883Z",
     "shell.execute_reply.started": "2025-04-19T14:25:11.158922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch_data):\n",
    "    result = []\n",
    "    for index, item in enumerate(zip(*batch_data)):\n",
    "        # result.append(torch.stack(item).unsqueeze(dim = 1))\n",
    "        result.append(torch.stack(item))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "731b7a50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:59:00.730931Z",
     "iopub.status.busy": "2025-04-19T13:59:00.730598Z",
     "iopub.status.idle": "2025-04-19T13:59:00.735483Z",
     "shell.execute_reply": "2025-04-19T13:59:00.734535Z",
     "shell.execute_reply.started": "2025-04-19T13:59:00.730909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 4,\n",
    "          'shuffle': True,\n",
    "          'collate_fn': collate_fn\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958f39a",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd3a2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIAL = 10\n",
    "N_CYCLE = 20\n",
    "N_PLAYER = 3\n",
    "BATCH_SIZE = 64\n",
    "DATA_LENGTH = 5000\n",
    "N_EPOCH = 4\n",
    "GEN = 5\n",
    "LEARNING_RATE_list = [2e-4, 5e-4, 7e-4, 1e-3]\n",
    "e_list = [0.1, 0.2, 0.3] #clipping constant\n",
    "value_coef_list = [0.5, 0.6, 0.7]\n",
    "entropy_coef_list = [0.01, 0.02, 0.03]\n",
    "param_list = [LEARNING_RATE_list, e_list, value_coef_list, entropy_coef_list]\n",
    "param_record = []\n",
    "randomized_record = []\n",
    "\n",
    "dataloader_params = {'batch_size': BATCH_SIZE,\n",
    "          'shuffle': True,\n",
    "          'drop_last': True, # drop the last batch where the size could be 1\n",
    "          'collate_fn': collate_fn\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08cea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.0005 | e: 0.3 | value_coef: 0.5 | entropy_coef: 0.02\n",
      "-------------CYCLE: 0-------------\n",
      "game length: 45.0\n",
      "tensor(-2.6808, grad_fn=<NegBackward0>) tensor(216.7564, grad_fn=<MeanBackward0>) tensor(0.6900, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9866, grad_fn=<NegBackward0>) tensor(205.5308, grad_fn=<MeanBackward0>) tensor(0.6918, grad_fn=<MeanBackward0>)\n",
      "tensor(3.0439, grad_fn=<NegBackward0>) tensor(208.8417, grad_fn=<MeanBackward0>) tensor(0.6927, grad_fn=<MeanBackward0>)\n",
      "tensor(3.2691, grad_fn=<NegBackward0>) tensor(226.3994, grad_fn=<MeanBackward0>) tensor(0.6930, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3386, grad_fn=<NegBackward0>) tensor(248.2862, grad_fn=<MeanBackward0>) tensor(0.6931, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9901, grad_fn=<NegBackward0>) tensor(227.9572, grad_fn=<MeanBackward0>) tensor(0.6930, grad_fn=<MeanBackward0>)\n",
      "tensor(4.2138, grad_fn=<NegBackward0>) tensor(204.7685, grad_fn=<MeanBackward0>) tensor(0.6925, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4693, grad_fn=<NegBackward0>) tensor(209.0412, grad_fn=<MeanBackward0>) tensor(0.6920, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.8190, grad_fn=<NegBackward0>) tensor(189.9969, grad_fn=<MeanBackward0>) tensor(0.6906, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2006, grad_fn=<NegBackward0>) tensor(211.6269, grad_fn=<MeanBackward0>) tensor(0.6883, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9061, grad_fn=<NegBackward0>) tensor(261.8471, grad_fn=<MeanBackward0>) tensor(0.6844, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.7120, grad_fn=<NegBackward0>) tensor(232.0418, grad_fn=<MeanBackward0>) tensor(0.6797, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6598, grad_fn=<NegBackward0>) tensor(240.7436, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2646, grad_fn=<NegBackward0>) tensor(243.9203, grad_fn=<MeanBackward0>) tensor(0.6606, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9220, grad_fn=<NegBackward0>) tensor(218.2594, grad_fn=<MeanBackward0>) tensor(0.6535, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0127, grad_fn=<NegBackward0>) tensor(224.7609, grad_fn=<MeanBackward0>) tensor(0.6506, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6296, grad_fn=<NegBackward0>) tensor(237.7789, grad_fn=<MeanBackward0>) tensor(0.6514, grad_fn=<MeanBackward0>)\n",
      "tensor(3.9619, grad_fn=<NegBackward0>) tensor(211.0409, grad_fn=<MeanBackward0>) tensor(0.6538, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0345, grad_fn=<NegBackward0>) tensor(240.8756, grad_fn=<MeanBackward0>) tensor(0.6569, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.6848, grad_fn=<NegBackward0>) tensor(197.2117, grad_fn=<MeanBackward0>) tensor(0.6637, grad_fn=<MeanBackward0>)\n",
      "tensor(1.5360, grad_fn=<NegBackward0>) tensor(253.3191, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9729, grad_fn=<NegBackward0>) tensor(215.1856, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7289, grad_fn=<NegBackward0>) tensor(220.0972, grad_fn=<MeanBackward0>) tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7270, grad_fn=<NegBackward0>) tensor(207.1485, grad_fn=<MeanBackward0>) tensor(0.6768, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.5204, grad_fn=<NegBackward0>) tensor(239.8153, grad_fn=<MeanBackward0>) tensor(0.6783, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7852, grad_fn=<NegBackward0>) tensor(222.5544, grad_fn=<MeanBackward0>) tensor(0.6779, grad_fn=<MeanBackward0>)\n",
      "tensor(3.0292, grad_fn=<NegBackward0>) tensor(200.8377, grad_fn=<MeanBackward0>) tensor(0.6778, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3255, grad_fn=<NegBackward0>) tensor(221.3725, grad_fn=<MeanBackward0>) tensor(0.6775, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3117, grad_fn=<NegBackward0>) tensor(229.3949, grad_fn=<MeanBackward0>) tensor(0.6773, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4449, grad_fn=<NegBackward0>) tensor(197.7144, grad_fn=<MeanBackward0>) tensor(0.6772, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5675, grad_fn=<NegBackward0>) tensor(265.0795, grad_fn=<MeanBackward0>) tensor(0.6775, grad_fn=<MeanBackward0>)\n",
      "tensor(2.5174, grad_fn=<NegBackward0>) tensor(238.0706, grad_fn=<MeanBackward0>) tensor(0.6762, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9823, grad_fn=<NegBackward0>) tensor(183.3479, grad_fn=<MeanBackward0>) tensor(0.6746, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4813, grad_fn=<NegBackward0>) tensor(201.5564, grad_fn=<MeanBackward0>) tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2791, grad_fn=<NegBackward0>) tensor(218.4428, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(2.7979, grad_fn=<NegBackward0>) tensor(214.0782, grad_fn=<MeanBackward0>) tensor(0.6728, grad_fn=<MeanBackward0>)\n",
      "tensor(3.3379, grad_fn=<NegBackward0>) tensor(206.2899, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0471, grad_fn=<NegBackward0>) tensor(210.7524, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.6538, grad_fn=<NegBackward0>) tensor(202.9174, grad_fn=<MeanBackward0>) tensor(0.6715, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2961, grad_fn=<NegBackward0>) tensor(213.7103, grad_fn=<MeanBackward0>) tensor(0.6711, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6750, grad_fn=<NegBackward0>) tensor(223.4991, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0318, grad_fn=<NegBackward0>) tensor(195.5367, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(1.5464, grad_fn=<NegBackward0>) tensor(218.7491, grad_fn=<MeanBackward0>) tensor(0.6699, grad_fn=<MeanBackward0>)\n",
      "tensor(3.7207, grad_fn=<NegBackward0>) tensor(175.3751, grad_fn=<MeanBackward0>) tensor(0.6698, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7299, grad_fn=<NegBackward0>) tensor(230.8604, grad_fn=<MeanBackward0>) tensor(0.6690, grad_fn=<MeanBackward0>)\n",
      "tensor(3.9631, grad_fn=<NegBackward0>) tensor(167.6860, grad_fn=<MeanBackward0>) tensor(0.6686, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2669, grad_fn=<NegBackward0>) tensor(207.6547, grad_fn=<MeanBackward0>) tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "tensor(3.8098, grad_fn=<NegBackward0>) tensor(172.7700, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor(4.6190, grad_fn=<NegBackward0>) tensor(184.9200, grad_fn=<MeanBackward0>) tensor(0.6703, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6370, grad_fn=<NegBackward0>) tensor(219.8721, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3846, grad_fn=<NegBackward0>) tensor(242.6079, grad_fn=<MeanBackward0>) tensor(0.6708, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7508, grad_fn=<NegBackward0>) tensor(200.7836, grad_fn=<MeanBackward0>) tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "tensor(2.1226, grad_fn=<NegBackward0>) tensor(195.4787, grad_fn=<MeanBackward0>) tensor(0.6717, grad_fn=<MeanBackward0>)\n",
      "tensor(2.8662, grad_fn=<NegBackward0>) tensor(243.7328, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2834, grad_fn=<NegBackward0>) tensor(243.0302, grad_fn=<MeanBackward0>) tensor(0.6730, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3758, grad_fn=<NegBackward0>) tensor(220.9100, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(3.0757, grad_fn=<NegBackward0>) tensor(183.0709, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(2.1060, grad_fn=<NegBackward0>) tensor(205.4400, grad_fn=<MeanBackward0>) tensor(0.6736, grad_fn=<MeanBackward0>)\n",
      "tensor(3.5349, grad_fn=<NegBackward0>) tensor(180.7949, grad_fn=<MeanBackward0>) tensor(0.6742, grad_fn=<MeanBackward0>)\n",
      "tensor(3.1622, grad_fn=<NegBackward0>) tensor(180.8538, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6650, grad_fn=<NegBackward0>) tensor(184.5938, grad_fn=<MeanBackward0>) tensor(0.6748, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8963, grad_fn=<NegBackward0>) tensor(214.1779, grad_fn=<MeanBackward0>) tensor(0.6751, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.8686, grad_fn=<NegBackward0>) tensor(234.8061, grad_fn=<MeanBackward0>) tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3929, grad_fn=<NegBackward0>) tensor(197.5088, grad_fn=<MeanBackward0>) tensor(0.6749, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3064, grad_fn=<NegBackward0>) tensor(216.0043, grad_fn=<MeanBackward0>) tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "tensor(2.7242, grad_fn=<NegBackward0>) tensor(203.0655, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.3609, grad_fn=<NegBackward0>) tensor(218.6200, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3424, grad_fn=<NegBackward0>) tensor(204.6192, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4931, grad_fn=<NegBackward0>) tensor(172.6879, grad_fn=<MeanBackward0>) tensor(0.6726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5484, grad_fn=<NegBackward0>) tensor(168.4270, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4413, grad_fn=<NegBackward0>) tensor(207.2956, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9105, grad_fn=<NegBackward0>) tensor(188.5246, grad_fn=<MeanBackward0>) tensor(0.6710, grad_fn=<MeanBackward0>)\n",
      "tensor(4.7124, grad_fn=<NegBackward0>) tensor(214.1422, grad_fn=<MeanBackward0>) tensor(0.6709, grad_fn=<MeanBackward0>)\n",
      "tensor(2.8407, grad_fn=<NegBackward0>) tensor(167.2159, grad_fn=<MeanBackward0>) tensor(0.6711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1934, grad_fn=<NegBackward0>) tensor(191.8151, grad_fn=<MeanBackward0>) tensor(0.6711, grad_fn=<MeanBackward0>)\n",
      "tensor(2.7196, grad_fn=<NegBackward0>) tensor(228.5616, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0566, grad_fn=<NegBackward0>) tensor(186.4724, grad_fn=<MeanBackward0>) tensor(0.6710, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2809, grad_fn=<NegBackward0>) tensor(181.5729, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "Epoch: 0 - loss: 108.71\n",
      "tensor(1.6684, grad_fn=<NegBackward0>) tensor(173.7841, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(4.1710, grad_fn=<NegBackward0>) tensor(154.9220, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5181, grad_fn=<NegBackward0>) tensor(192.9558, grad_fn=<MeanBackward0>) tensor(0.6708, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.9564, grad_fn=<NegBackward0>) tensor(197.2985, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.4314, grad_fn=<NegBackward0>) tensor(226.5661, grad_fn=<MeanBackward0>) tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5720, grad_fn=<NegBackward0>) tensor(171.2467, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1381, grad_fn=<NegBackward0>) tensor(166.6042, grad_fn=<MeanBackward0>) tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1009, grad_fn=<NegBackward0>) tensor(155.9855, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9355, grad_fn=<NegBackward0>) tensor(162.8729, grad_fn=<MeanBackward0>) tensor(0.6711, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4871, grad_fn=<NegBackward0>) tensor(141.4823, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.9083, grad_fn=<NegBackward0>) tensor(177.6984, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0394, grad_fn=<NegBackward0>) tensor(173.3682, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(3.2933, grad_fn=<NegBackward0>) tensor(200.3799, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(2.7323, grad_fn=<NegBackward0>) tensor(166.7201, grad_fn=<MeanBackward0>) tensor(0.6727, grad_fn=<MeanBackward0>)\n",
      "tensor(2.7840, grad_fn=<NegBackward0>) tensor(161.3479, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2058, grad_fn=<NegBackward0>) tensor(159.7725, grad_fn=<MeanBackward0>) tensor(0.6729, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2419, grad_fn=<NegBackward0>) tensor(200.5174, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7157, grad_fn=<NegBackward0>) tensor(146.4908, grad_fn=<MeanBackward0>) tensor(0.6734, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0213, grad_fn=<NegBackward0>) tensor(160.7849, grad_fn=<MeanBackward0>) tensor(0.6732, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0386, grad_fn=<NegBackward0>) tensor(143.1419, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9094, grad_fn=<NegBackward0>) tensor(154.6377, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(4.8767, grad_fn=<NegBackward0>) tensor(152.7755, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3349, grad_fn=<NegBackward0>) tensor(159.1625, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5002, grad_fn=<NegBackward0>) tensor(150.1539, grad_fn=<MeanBackward0>) tensor(0.6730, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3644, grad_fn=<NegBackward0>) tensor(161.5204, grad_fn=<MeanBackward0>) tensor(0.6730, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2190, grad_fn=<NegBackward0>) tensor(163.4589, grad_fn=<MeanBackward0>) tensor(0.6729, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2607, grad_fn=<NegBackward0>) tensor(157.7375, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(3.8517, grad_fn=<NegBackward0>) tensor(126.5112, grad_fn=<MeanBackward0>) tensor(0.6725, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0903, grad_fn=<NegBackward0>) tensor(156.0063, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.4641, grad_fn=<NegBackward0>) tensor(157.7486, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0090, grad_fn=<NegBackward0>) tensor(148.9801, grad_fn=<MeanBackward0>) tensor(0.6728, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3836, grad_fn=<NegBackward0>) tensor(144.7945, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.1259, grad_fn=<NegBackward0>) tensor(143.6106, grad_fn=<MeanBackward0>) tensor(0.6717, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1888, grad_fn=<NegBackward0>) tensor(149.3724, grad_fn=<MeanBackward0>) tensor(0.6724, grad_fn=<MeanBackward0>)\n",
      "tensor(2.5776, grad_fn=<NegBackward0>) tensor(144.8178, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0401, grad_fn=<NegBackward0>) tensor(128.8045, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9861, grad_fn=<NegBackward0>) tensor(102.3397, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4207, grad_fn=<NegBackward0>) tensor(130.5338, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(3.1911, grad_fn=<NegBackward0>) tensor(170.0300, grad_fn=<MeanBackward0>) tensor(0.6715, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1062, grad_fn=<NegBackward0>) tensor(120.9222, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4626, grad_fn=<NegBackward0>) tensor(146.6503, grad_fn=<MeanBackward0>) tensor(0.6721, grad_fn=<MeanBackward0>)\n",
      "tensor(4.1390, grad_fn=<NegBackward0>) tensor(127.9823, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2076, grad_fn=<NegBackward0>) tensor(157.2566, grad_fn=<MeanBackward0>) tensor(0.6706, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8900, grad_fn=<NegBackward0>) tensor(157.6740, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8060, grad_fn=<NegBackward0>) tensor(139.1927, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.5982, grad_fn=<NegBackward0>) tensor(166.1068, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(3.5633, grad_fn=<NegBackward0>) tensor(156.9047, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(3.2344, grad_fn=<NegBackward0>) tensor(163.1081, grad_fn=<MeanBackward0>) tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "tensor(4.4070, grad_fn=<NegBackward0>) tensor(109.1111, grad_fn=<MeanBackward0>) tensor(0.6711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9975, grad_fn=<NegBackward0>) tensor(142.6146, grad_fn=<MeanBackward0>) tensor(0.6724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9601, grad_fn=<NegBackward0>) tensor(120.1873, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(3.8833, grad_fn=<NegBackward0>) tensor(148.6922, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3549, grad_fn=<NegBackward0>) tensor(163.4919, grad_fn=<MeanBackward0>) tensor(0.6725, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.7274, grad_fn=<NegBackward0>) tensor(123.2326, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9808, grad_fn=<NegBackward0>) tensor(151.2143, grad_fn=<MeanBackward0>) tensor(0.6726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5025, grad_fn=<NegBackward0>) tensor(171.1065, grad_fn=<MeanBackward0>) tensor(0.6728, grad_fn=<MeanBackward0>)\n",
      "tensor(4.2569, grad_fn=<NegBackward0>) tensor(148.1528, grad_fn=<MeanBackward0>) tensor(0.6730, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8100, grad_fn=<NegBackward0>) tensor(129.1446, grad_fn=<MeanBackward0>) tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4695, grad_fn=<NegBackward0>) tensor(115.6117, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(2.6522, grad_fn=<NegBackward0>) tensor(141.8253, grad_fn=<MeanBackward0>) tensor(0.6742, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1823, grad_fn=<NegBackward0>) tensor(174.4315, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7845, grad_fn=<NegBackward0>) tensor(115.5826, grad_fn=<MeanBackward0>) tensor(0.6747, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4599, grad_fn=<NegBackward0>) tensor(144.6224, grad_fn=<MeanBackward0>) tensor(0.6748, grad_fn=<MeanBackward0>)\n",
      "tensor(4.7354, grad_fn=<NegBackward0>) tensor(140.3051, grad_fn=<MeanBackward0>) tensor(0.6745, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8791, grad_fn=<NegBackward0>) tensor(142.5570, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3331, grad_fn=<NegBackward0>) tensor(163.6189, grad_fn=<MeanBackward0>) tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "tensor(3.7700, grad_fn=<NegBackward0>) tensor(151.5568, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(3.0615, grad_fn=<NegBackward0>) tensor(125.1879, grad_fn=<MeanBackward0>) tensor(0.6741, grad_fn=<MeanBackward0>)\n",
      "tensor(2.7901, grad_fn=<NegBackward0>) tensor(106.8439, grad_fn=<MeanBackward0>) tensor(0.6737, grad_fn=<MeanBackward0>)\n",
      "tensor(4.3826, grad_fn=<NegBackward0>) tensor(135.1348, grad_fn=<MeanBackward0>) tensor(0.6736, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0087, grad_fn=<NegBackward0>) tensor(114.9515, grad_fn=<MeanBackward0>) tensor(0.6730, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4483, grad_fn=<NegBackward0>) tensor(111.4648, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4214, grad_fn=<NegBackward0>) tensor(157.2252, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8918, grad_fn=<NegBackward0>) tensor(130.0805, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2844, grad_fn=<NegBackward0>) tensor(147.4208, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0814, grad_fn=<NegBackward0>) tensor(122.3046, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(3.8172, grad_fn=<NegBackward0>) tensor(148.3515, grad_fn=<MeanBackward0>) tensor(0.6732, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.6107, grad_fn=<NegBackward0>) tensor(142.8726, grad_fn=<MeanBackward0>) tensor(0.6724, grad_fn=<MeanBackward0>)\n",
      "Epoch: 1 - loss: 77.6\n",
      "tensor(-2.3776, grad_fn=<NegBackward0>) tensor(127.7299, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9085, grad_fn=<NegBackward0>) tensor(98.9605, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0630, grad_fn=<NegBackward0>) tensor(142.4193, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4398, grad_fn=<NegBackward0>) tensor(148.9840, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5569, grad_fn=<NegBackward0>) tensor(123.0097, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.6959, grad_fn=<NegBackward0>) tensor(145.6311, grad_fn=<MeanBackward0>) tensor(0.6710, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1770, grad_fn=<NegBackward0>) tensor(110.9073, grad_fn=<MeanBackward0>) tensor(0.6715, grad_fn=<MeanBackward0>)\n",
      "tensor(4.6817, grad_fn=<NegBackward0>) tensor(140.9746, grad_fn=<MeanBackward0>) tensor(0.6709, grad_fn=<MeanBackward0>)\n",
      "tensor(2.5071, grad_fn=<NegBackward0>) tensor(100.1897, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(4.0856, grad_fn=<NegBackward0>) tensor(131.2256, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8774, grad_fn=<NegBackward0>) tensor(143.6298, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0490, grad_fn=<NegBackward0>) tensor(155.9788, grad_fn=<MeanBackward0>) tensor(0.6730, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6519, grad_fn=<NegBackward0>) tensor(117.1418, grad_fn=<MeanBackward0>) tensor(0.6734, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5727, grad_fn=<NegBackward0>) tensor(125.3640, grad_fn=<MeanBackward0>) tensor(0.6737, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3639, grad_fn=<NegBackward0>) tensor(167.0128, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(4.2926, grad_fn=<NegBackward0>) tensor(113.4837, grad_fn=<MeanBackward0>) tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9134, grad_fn=<NegBackward0>) tensor(120.6397, grad_fn=<MeanBackward0>) tensor(0.6747, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3392, grad_fn=<NegBackward0>) tensor(147.0459, grad_fn=<MeanBackward0>) tensor(0.6756, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7648, grad_fn=<NegBackward0>) tensor(122.2034, grad_fn=<MeanBackward0>) tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.6310, grad_fn=<NegBackward0>) tensor(151.2087, grad_fn=<MeanBackward0>) tensor(0.6752, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2058, grad_fn=<NegBackward0>) tensor(100.0439, grad_fn=<MeanBackward0>) tensor(0.6756, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9940, grad_fn=<NegBackward0>) tensor(120.8224, grad_fn=<MeanBackward0>) tensor(0.6749, grad_fn=<MeanBackward0>)\n",
      "tensor(3.1736, grad_fn=<NegBackward0>) tensor(124.9627, grad_fn=<MeanBackward0>) tensor(0.6750, grad_fn=<MeanBackward0>)\n",
      "tensor(2.6568, grad_fn=<NegBackward0>) tensor(167.1838, grad_fn=<MeanBackward0>) tensor(0.6760, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.0438, grad_fn=<NegBackward0>) tensor(107.4459, grad_fn=<MeanBackward0>) tensor(0.6755, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9069, grad_fn=<NegBackward0>) tensor(116.0490, grad_fn=<MeanBackward0>) tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2331, grad_fn=<NegBackward0>) tensor(120.3233, grad_fn=<MeanBackward0>) tensor(0.6753, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1649, grad_fn=<NegBackward0>) tensor(132.2307, grad_fn=<MeanBackward0>) tensor(0.6747, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.2029, grad_fn=<NegBackward0>) tensor(186.4726, grad_fn=<MeanBackward0>) tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2988, grad_fn=<NegBackward0>) tensor(155.3081, grad_fn=<MeanBackward0>) tensor(0.6734, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4992, grad_fn=<NegBackward0>) tensor(90.5820, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.6613, grad_fn=<NegBackward0>) tensor(191.2487, grad_fn=<MeanBackward0>) tensor(0.6734, grad_fn=<MeanBackward0>)\n",
      "tensor(3.1055, grad_fn=<NegBackward0>) tensor(112.8956, grad_fn=<MeanBackward0>) tensor(0.6729, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4404, grad_fn=<NegBackward0>) tensor(156.9217, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(3.3327, grad_fn=<NegBackward0>) tensor(107.0351, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3105, grad_fn=<NegBackward0>) tensor(124.6288, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0068, grad_fn=<NegBackward0>) tensor(122.0774, grad_fn=<MeanBackward0>) tensor(0.6725, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2069, grad_fn=<NegBackward0>) tensor(136.4957, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(3.8881, grad_fn=<NegBackward0>) tensor(121.6313, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(3.6292, grad_fn=<NegBackward0>) tensor(100.8341, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3929, grad_fn=<NegBackward0>) tensor(119.8453, grad_fn=<MeanBackward0>) tensor(0.6714, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.5534, grad_fn=<NegBackward0>) tensor(134.6605, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5377, grad_fn=<NegBackward0>) tensor(115.4990, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(3.6846, grad_fn=<NegBackward0>) tensor(109.5792, grad_fn=<MeanBackward0>) tensor(0.6729, grad_fn=<MeanBackward0>)\n",
      "tensor(3.6700, grad_fn=<NegBackward0>) tensor(104.1655, grad_fn=<MeanBackward0>) tensor(0.6731, grad_fn=<MeanBackward0>)\n",
      "tensor(4.1831, grad_fn=<NegBackward0>) tensor(136.2095, grad_fn=<MeanBackward0>) tensor(0.6734, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3771, grad_fn=<NegBackward0>) tensor(142.0494, grad_fn=<MeanBackward0>) tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9607, grad_fn=<NegBackward0>) tensor(161.0244, grad_fn=<MeanBackward0>) tensor(0.6741, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5651, grad_fn=<NegBackward0>) tensor(118.6839, grad_fn=<MeanBackward0>) tensor(0.6745, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4416, grad_fn=<NegBackward0>) tensor(120.5885, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.2380, grad_fn=<NegBackward0>) tensor(142.4626, grad_fn=<MeanBackward0>) tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4121, grad_fn=<NegBackward0>) tensor(120.4821, grad_fn=<MeanBackward0>) tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5088, grad_fn=<NegBackward0>) tensor(125.3292, grad_fn=<MeanBackward0>) tensor(0.6738, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.7028, grad_fn=<NegBackward0>) tensor(152.7649, grad_fn=<MeanBackward0>) tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4399, grad_fn=<NegBackward0>) tensor(101.5804, grad_fn=<MeanBackward0>) tensor(0.6741, grad_fn=<MeanBackward0>)\n",
      "tensor(3.6097, grad_fn=<NegBackward0>) tensor(134.4662, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9071, grad_fn=<NegBackward0>) tensor(131.7802, grad_fn=<MeanBackward0>) tensor(0.6731, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.4443, grad_fn=<NegBackward0>) tensor(129.0231, grad_fn=<MeanBackward0>) tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2842, grad_fn=<NegBackward0>) tensor(99.9633, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.4227, grad_fn=<NegBackward0>) tensor(129.3549, grad_fn=<MeanBackward0>) tensor(0.6728, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0977, grad_fn=<NegBackward0>) tensor(95.9840, grad_fn=<MeanBackward0>) tensor(0.6722, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2540, grad_fn=<NegBackward0>) tensor(136.7742, grad_fn=<MeanBackward0>) tensor(0.6725, grad_fn=<MeanBackward0>)\n",
      "tensor(4.5351, grad_fn=<NegBackward0>) tensor(107.2848, grad_fn=<MeanBackward0>) tensor(0.6723, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9530, grad_fn=<NegBackward0>) tensor(118.2639, grad_fn=<MeanBackward0>) tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "tensor(2.3460, grad_fn=<NegBackward0>) tensor(98.3521, grad_fn=<MeanBackward0>) tensor(0.6710, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3757, grad_fn=<NegBackward0>) tensor(113.4552, grad_fn=<MeanBackward0>) tensor(0.6705, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1443, grad_fn=<NegBackward0>) tensor(114.2900, grad_fn=<MeanBackward0>) tensor(0.6709, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.2229, grad_fn=<NegBackward0>) tensor(144.1466, grad_fn=<MeanBackward0>) tensor(0.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.9871, grad_fn=<NegBackward0>) tensor(134.2245, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.8675, grad_fn=<NegBackward0>) tensor(130.5603, grad_fn=<MeanBackward0>) tensor(0.6712, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1455, grad_fn=<NegBackward0>) tensor(132.6383, grad_fn=<MeanBackward0>) tensor(0.6698, grad_fn=<MeanBackward0>)\n",
      "tensor(4.0987, grad_fn=<NegBackward0>) tensor(88.3808, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(1.5136, grad_fn=<NegBackward0>) tensor(116.5568, grad_fn=<MeanBackward0>) tensor(0.6690, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.2768, grad_fn=<NegBackward0>) tensor(147.2725, grad_fn=<MeanBackward0>) tensor(0.6687, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1869, grad_fn=<NegBackward0>) tensor(125.4789, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(4.3222, grad_fn=<NegBackward0>) tensor(161.9970, grad_fn=<MeanBackward0>) tensor(0.6686, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3816, grad_fn=<NegBackward0>) tensor(93.6002, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6313, grad_fn=<NegBackward0>) tensor(126.0303, grad_fn=<MeanBackward0>) tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "Epoch: 2 - loss: 66.1\n",
      "tensor(2.5225, grad_fn=<NegBackward0>) tensor(125.6756, grad_fn=<MeanBackward0>) tensor(0.6689, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6535, grad_fn=<NegBackward0>) tensor(136.4971, grad_fn=<MeanBackward0>) tensor(0.6681, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5573, grad_fn=<NegBackward0>) tensor(80.2223, grad_fn=<MeanBackward0>) tensor(0.6675, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.5295, grad_fn=<NegBackward0>) tensor(117.0414, grad_fn=<MeanBackward0>) tensor(0.6671, grad_fn=<MeanBackward0>)\n",
      "tensor(4.9660, grad_fn=<NegBackward0>) tensor(113.6127, grad_fn=<MeanBackward0>) tensor(0.6677, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3084, grad_fn=<NegBackward0>) tensor(136.3461, grad_fn=<MeanBackward0>) tensor(0.6671, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2396, grad_fn=<NegBackward0>) tensor(121.4930, grad_fn=<MeanBackward0>) tensor(0.6684, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4769, grad_fn=<NegBackward0>) tensor(118.6844, grad_fn=<MeanBackward0>) tensor(0.6687, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.3864, grad_fn=<NegBackward0>) tensor(114.1664, grad_fn=<MeanBackward0>) tensor(0.6685, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0985, grad_fn=<NegBackward0>) tensor(124.2481, grad_fn=<MeanBackward0>) tensor(0.6686, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0375, grad_fn=<NegBackward0>) tensor(120.6512, grad_fn=<MeanBackward0>) tensor(0.6693, grad_fn=<MeanBackward0>)\n",
      "tensor(4.0115, grad_fn=<NegBackward0>) tensor(105.3368, grad_fn=<MeanBackward0>) tensor(0.6704, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1878, grad_fn=<NegBackward0>) tensor(128.2024, grad_fn=<MeanBackward0>) tensor(0.6713, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5863, grad_fn=<NegBackward0>) tensor(135.8084, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2781, grad_fn=<NegBackward0>) tensor(144.0360, grad_fn=<MeanBackward0>) tensor(0.6727, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3803, grad_fn=<NegBackward0>) tensor(77.6198, grad_fn=<MeanBackward0>) tensor(0.6741, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9365, grad_fn=<NegBackward0>) tensor(99.1736, grad_fn=<MeanBackward0>) tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2177, grad_fn=<NegBackward0>) tensor(155.5777, grad_fn=<MeanBackward0>) tensor(0.6748, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8566, grad_fn=<NegBackward0>) tensor(125.8711, grad_fn=<MeanBackward0>) tensor(0.6762, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3124, grad_fn=<NegBackward0>) tensor(124.5556, grad_fn=<MeanBackward0>) tensor(0.6769, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4402, grad_fn=<NegBackward0>) tensor(101.2829, grad_fn=<MeanBackward0>) tensor(0.6767, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6938, grad_fn=<NegBackward0>) tensor(151.5536, grad_fn=<MeanBackward0>) tensor(0.6772, grad_fn=<MeanBackward0>)\n",
      "tensor(4.0530, grad_fn=<NegBackward0>) tensor(132.8528, grad_fn=<MeanBackward0>) tensor(0.6760, grad_fn=<MeanBackward0>)\n",
      "tensor(3.2223, grad_fn=<NegBackward0>) tensor(90.7960, grad_fn=<MeanBackward0>) tensor(0.6758, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4363, grad_fn=<NegBackward0>) tensor(95.4712, grad_fn=<MeanBackward0>) tensor(0.6761, grad_fn=<MeanBackward0>)\n",
      "tensor(4.5957, grad_fn=<NegBackward0>) tensor(102.6220, grad_fn=<MeanBackward0>) tensor(0.6757, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3674, grad_fn=<NegBackward0>) tensor(136.8389, grad_fn=<MeanBackward0>) tensor(0.6754, grad_fn=<MeanBackward0>)\n",
      "tensor(2.1743, grad_fn=<NegBackward0>) tensor(123.1194, grad_fn=<MeanBackward0>) tensor(0.6752, grad_fn=<MeanBackward0>)\n",
      "tensor(2.3464, grad_fn=<NegBackward0>) tensor(108.1245, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0889, grad_fn=<NegBackward0>) tensor(114.8486, grad_fn=<MeanBackward0>) tensor(0.6735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1297, grad_fn=<NegBackward0>) tensor(128.2339, grad_fn=<MeanBackward0>) tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.7187, grad_fn=<NegBackward0>) tensor(121.0670, grad_fn=<MeanBackward0>) tensor(0.6715, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7707, grad_fn=<NegBackward0>) tensor(107.2895, grad_fn=<MeanBackward0>) tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "tensor(4.5538, grad_fn=<NegBackward0>) tensor(130.5000, grad_fn=<MeanBackward0>) tensor(0.6700, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2014, grad_fn=<NegBackward0>) tensor(155.9491, grad_fn=<MeanBackward0>) tensor(0.6688, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6928, grad_fn=<NegBackward0>) tensor(155.9969, grad_fn=<MeanBackward0>) tensor(0.6685, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0992, grad_fn=<NegBackward0>) tensor(101.8177, grad_fn=<MeanBackward0>) tensor(0.6682, grad_fn=<MeanBackward0>)\n",
      "tensor(3.5245, grad_fn=<NegBackward0>) tensor(103.4317, grad_fn=<MeanBackward0>) tensor(0.6681, grad_fn=<MeanBackward0>)\n",
      "tensor(5.2499, grad_fn=<NegBackward0>) tensor(109.7625, grad_fn=<MeanBackward0>) tensor(0.6690, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4533, grad_fn=<NegBackward0>) tensor(99.0217, grad_fn=<MeanBackward0>) tensor(0.6693, grad_fn=<MeanBackward0>)\n",
      "tensor(3.1196, grad_fn=<NegBackward0>) tensor(120.8144, grad_fn=<MeanBackward0>) tensor(0.6707, grad_fn=<MeanBackward0>)\n",
      "tensor(2.7683, grad_fn=<NegBackward0>) tensor(124.3229, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7674, grad_fn=<NegBackward0>) tensor(146.4800, grad_fn=<MeanBackward0>) tensor(0.6733, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2519, grad_fn=<NegBackward0>) tensor(101.2785, grad_fn=<MeanBackward0>) tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1463, grad_fn=<NegBackward0>) tensor(127.8618, grad_fn=<MeanBackward0>) tensor(0.6740, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4854, grad_fn=<NegBackward0>) tensor(91.2983, grad_fn=<MeanBackward0>) tensor(0.6739, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0703, grad_fn=<NegBackward0>) tensor(128.2838, grad_fn=<MeanBackward0>) tensor(0.6743, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0230, grad_fn=<NegBackward0>) tensor(116.6969, grad_fn=<MeanBackward0>) tensor(0.6742, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.7719, grad_fn=<NegBackward0>) tensor(115.9646, grad_fn=<MeanBackward0>) tensor(0.6736, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9978, grad_fn=<NegBackward0>) tensor(99.4431, grad_fn=<MeanBackward0>) tensor(0.6730, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9039, grad_fn=<NegBackward0>) tensor(147.2450, grad_fn=<MeanBackward0>) tensor(0.6720, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7230, grad_fn=<NegBackward0>) tensor(97.9642, grad_fn=<MeanBackward0>) tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6484, grad_fn=<NegBackward0>) tensor(113.6474, grad_fn=<MeanBackward0>) tensor(0.6717, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m             loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     89\u001b[0m             nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;66;03m# FIX: check this\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m             \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(loss_record\u001b[38;5;241m/\u001b[39mindex,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     93\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./ppo_weight/hyperparam_tuning_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    235\u001b[0m         group,\n\u001b[0;32m    236\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m         state_steps,\n\u001b[0;32m    242\u001b[0m     )\n\u001b[1;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\optim\\adam.py:476\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    474\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 476\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    478\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for trial in range(N_TRIAL):\n",
    "    if GEN in [3, 3.5]:\n",
    "        model = ppo(N_PLAYER).to(device)\n",
    "    elif GEN == 4:\n",
    "        model = ppo_gen_4(N_PLAYER).to(device)\n",
    "    elif GEN == 5:\n",
    "        model = ppo_gen_5(N_PLAYER).to(device)\n",
    "\n",
    "    while True:\n",
    "        random_param_index = [random.choice(range(len(a))) for a in param_list]\n",
    "        if random_param_index not in randomized_record:\n",
    "            break\n",
    "    randomized_record.append(random_param_index)\n",
    "    \n",
    "    LEARNING_RATE, e, value_coef, entropy_coef = [a[b] for a,b in zip(param_list, random_param_index)]\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    param_record.append(\n",
    "        {'learning_rate': LEARNING_RATE,\n",
    "        'e': e,\n",
    "        'value_coef': value_coef,\n",
    "        'entropy_coef': entropy_coef,\n",
    "       'index': trial\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f'learning_rate {LEARNING_RATE} | e: {e} | value_coef: {value_coef} | entropy_coef: {entropy_coef}')  \n",
    "    for cycle in range(N_CYCLE):\n",
    "        print(f'-------------CYCLE: {cycle}-------------')\n",
    "    \n",
    "        # Rollout\n",
    "        training_data = []\n",
    "        game_length = []\n",
    "        while len(training_data) <= DATA_LENGTH:\n",
    "            nothanks = nothanks_ppo()\n",
    "            if GEN == 3:\n",
    "                play_buffer = nothanks.rollout(model, nothanks.get_state)\n",
    "                training_data_tmp = create_training_data(play_buffer)\n",
    "            elif GEN == 3.5:\n",
    "                play_buffer = nothanks.rollout(model, nothanks.get_state_gen_3_5)\n",
    "                training_data_tmp = create_training_data(play_buffer)\n",
    "            elif GEN == 5:\n",
    "                play_buffer = nothanks.rollout_gen_5(model)\n",
    "                training_data_tmp = create_training_data_gen_5(play_buffer)\n",
    "\n",
    "            game_length.append(len(training_data_tmp))\n",
    "            training_data.extend(training_data_tmp)\n",
    "        print(f'game length: {round(np.mean(game_length),0)}')\n",
    "        \n",
    "        # create a new data loader\n",
    "        train_data = dataset(training_data)\n",
    "        dataloader = DataLoader(train_data, **dataloader_params)\n",
    "        \n",
    "        # Train\n",
    "        for epoch in range(N_EPOCH):\n",
    "            loss_record = 0\n",
    "            for index, input_data in enumerate(dataloader):\n",
    "                if GEN == 5:\n",
    "                    x_card_tmp, x_state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = input_data\n",
    "                else:\n",
    "                    state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = input_data\n",
    "                optimizer.zero_grad()\n",
    "                if GEN == 5:\n",
    "                    _, log_prob_new, entropy, value_new = model.forward(x_card_tmp, \n",
    "                                                                        x_state_tmp,\n",
    "                                                                        legal_move_mask= legal_move_mask,\n",
    "                                                                        action = move_tmp)\n",
    "                else:\n",
    "                    _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n",
    "                                                            legal_move_mask= legal_move_mask,\n",
    "                                                            action = move_tmp)\n",
    "                # policy loss\n",
    "                # advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/(advantage_tmp.std() + 1e-8)\n",
    "                ratio = torch.exp(log_prob_new - log_prob_old).unsqueeze(dim = 1) # pi_new/pi_old\n",
    "                surrogate_1 = ratio*advantage_tmp\n",
    "                ratio_clamp = torch.clamp(ratio, 1 - e, 1 + e) # clipped ratio\n",
    "                surrogate_2 = ratio_clamp*advantage_tmp\n",
    "                policy_loss = -torch.min(surrogate_1, surrogate_2).mean() #FIX: is this adv detached? yes\n",
    "\n",
    "                # value loss\n",
    "                value_loss = ((value_new - discounted_reward)**2).mean()\n",
    "    \n",
    "                # entropy loss: to encourage exploration\n",
    "                entropy_loss = entropy.mean()\n",
    "                loss = policy_loss + value_coef * value_loss - entropy_coef * entropy_loss\n",
    "                loss_record += loss.item()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.5) # FIX: check this\n",
    "                optimizer.step()\n",
    "    \n",
    "            print(f'Epoch: {epoch} - loss: {round(loss_record/index,2)}')\n",
    "    torch.save(model.state_dict(), f'./ppo_weight/hyperparam_tuning_{trial}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14dede",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1b65913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:21.547192Z",
     "iopub.status.busy": "2025-04-19T14:25:21.546930Z",
     "iopub.status.idle": "2025-04-19T14:25:23.870722Z",
     "shell.execute_reply": "2025-04-19T14:25:23.870144Z",
     "shell.execute_reply.started": "2025-04-19T14:25:21.547173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 5e-4\n",
    "N_PLAYER = 3\n",
    "DATA_LENGTH = 5000\n",
    "N_CYCLE = 100\n",
    "N_EPOCH = 4\n",
    "GEN = 5\n",
    "e = 0.3 #clipping constant\n",
    "value_coef = 0.7\n",
    "entropy_coef = 0.03\n",
    "\n",
    "if GEN in [3, 3.5]:\n",
    "    model = ppo(N_PLAYER).to(device)\n",
    "elif GEN == 4:\n",
    "    model = ppo_gen_4(N_PLAYER).to(device)\n",
    "elif GEN == 5:\n",
    "    model = ppo_gen_5(N_PLAYER).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('./weight/hyperparam_tuning_0.pth'))\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f1f115b-092d-4c1d-9d68-b3adf6c29654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:23.872798Z",
     "iopub.status.busy": "2025-04-19T14:25:23.871909Z",
     "iopub.status.idle": "2025-04-19T14:25:23.875858Z",
     "shell.execute_reply": "2025-04-19T14:25:23.875216Z",
     "shell.execute_reply.started": "2025-04-19T14:25:23.872778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataloader_params = {'batch_size': BATCH_SIZE,\n",
    "          'shuffle': True,\n",
    "          'drop_last': True, # drop the last batch where the size could be 1\n",
    "          'collate_fn': collate_fn\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0bb4c8d-8159-4073-b1aa-46d9b022bc69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:25:23.876853Z",
     "iopub.status.busy": "2025-04-19T14:25:23.876586Z",
     "iopub.status.idle": "2025-04-19T14:25:23.893971Z",
     "shell.execute_reply": "2025-04-19T14:25:23.893337Z",
     "shell.execute_reply.started": "2025-04-19T14:25:23.876837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "game_length_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21f8f888",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-19T14:32:17.616228Z",
     "iopub.status.busy": "2025-04-19T14:32:17.615489Z",
     "iopub.status.idle": "2025-04-19T14:39:12.141346Z",
     "shell.execute_reply": "2025-04-19T14:39:12.140429Z",
     "shell.execute_reply.started": "2025-04-19T14:32:17.616194Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------CYCLE: 0-------------\n",
      "game length: 51.0\n",
      "Epoch: 0 - loss: 152.15\n",
      "Epoch: 1 - loss: 106.49\n",
      "Epoch: 2 - loss: 86.66\n",
      "Epoch: 3 - loss: 80.26\n",
      "-------------CYCLE: 1-------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m     training_data_tmp \u001b[38;5;241m=\u001b[39m create_training_data(play_buffer)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m GEN \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     play_buffer \u001b[38;5;241m=\u001b[39m \u001b[43mnothanks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_gen_5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     training_data_tmp \u001b[38;5;241m=\u001b[39m create_training_data_gen_5(play_buffer)\n\u001b[0;32m     22\u001b[0m game_length\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(training_data_tmp))\n",
      "Cell \u001b[1;32mIn[54], line 218\u001b[0m, in \u001b[0;36mnothanks_ppo.rollout_gen_5\u001b[1;34m(self, model, n_game)\u001b[0m\n\u001b[0;32m    216\u001b[0m     random_move \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(random\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m move \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m move \u001b[38;5;129;01min\u001b[39;00m legal_move]))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 218\u001b[0m     move_raw, log_prob, entropy, value \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_card\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegal_move_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_move\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_encode\u001b[38;5;241m.\u001b[39mget(move_raw\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    220\u001b[0m reward \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_func(move)])\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[53], line 89\u001b[0m, in \u001b[0;36mppo_gen_5.forward\u001b[1;34m(self, x_card, x_state, legal_move_mask, action)\u001b[0m\n\u001b[0;32m     86\u001b[0m     action \u001b[38;5;241m=\u001b[39m prob\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;66;03m# sample the action\u001b[39;00m\n\u001b[0;32m     87\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m prob\u001b[38;5;241m.\u001b[39mlog_prob(action) \u001b[38;5;66;03m# this will be used for surrogate loss (log(a) - log(b) = log(a/b))\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_card\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action, log_prob, prob\u001b[38;5;241m.\u001b[39mentropy(), value\n",
      "Cell \u001b[1;32mIn[53], line 75\u001b[0m, in \u001b[0;36mppo_gen_5.get_value\u001b[1;34m(self, x_card, x_state)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_card, x_state):\n\u001b[0;32m     74\u001b[0m     value_concat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_concat(x_card, x_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_state_value) \u001b[38;5;66;03m# flattened + concat\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_concat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_flag = 1\n",
    "\n",
    "for cycle in range(N_CYCLE):\n",
    "    print(f'-------------CYCLE: {cycle}-------------')\n",
    "\n",
    "    # Rollout\n",
    "    training_data = []\n",
    "    game_length = []\n",
    "    while len(training_data) <= DATA_LENGTH:\n",
    "        nothanks = nothanks_ppo()\n",
    "\n",
    "        if GEN == 3:\n",
    "            play_buffer = nothanks.rollout(model, nothanks.get_state)\n",
    "            training_data_tmp = create_training_data(play_buffer)\n",
    "        elif GEN == 3.5:\n",
    "            play_buffer = nothanks.rollout(model, nothanks.get_state_gen_3_5)\n",
    "            training_data_tmp = create_training_data(play_buffer)\n",
    "        elif GEN == 5:\n",
    "            play_buffer = nothanks.rollout_gen_5(model)\n",
    "            training_data_tmp = create_training_data_gen_5(play_buffer)\n",
    "\n",
    "        game_length.append(len(training_data_tmp))\n",
    "        training_data.extend(training_data_tmp)\n",
    "    print(f'game length: {round(np.mean(game_length),0)}')\n",
    "    game_length_list.append(round(np.mean(game_length),0))\n",
    "    \n",
    "    # create a new data loader\n",
    "    train_data = dataset(training_data)\n",
    "    dataloader = DataLoader(train_data, **dataloader_params)\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(N_EPOCH):\n",
    "        loss_record = 0\n",
    "        # for index, (state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward) in enumerate(dataloader):\n",
    "        for index, input_data in enumerate(dataloader):\n",
    "            if GEN == 5:\n",
    "                x_card_tmp, x_state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = input_data\n",
    "            else:\n",
    "                state_tmp, move_tmp, legal_move_mask, log_prob_old, advantage_tmp, discounted_reward = input_data\n",
    "            optimizer.zero_grad()\n",
    "            if GEN == 5:\n",
    "                _, log_prob_new, entropy, value_new = model.forward(x_card_tmp, \n",
    "                                                                    x_state_tmp,\n",
    "                                                                    legal_move_mask= legal_move_mask,\n",
    "                                                                    action = move_tmp)\n",
    "            else:\n",
    "                _, log_prob_new, entropy, value_new = model.forward(X = state_tmp, \n",
    "                                                        legal_move_mask= legal_move_mask,\n",
    "                                                        action = move_tmp)\n",
    "            \n",
    "            # policy loss\n",
    "            # advantage_norm_tmp = (advantage_tmp - advantage_tmp.mean())/(advantage_tmp.std() + 1e-8)\n",
    "            ratio = torch.exp(log_prob_new - log_prob_old).unsqueeze(dim = 1) # pi_new/pi_old\n",
    "            surrogate_1 = ratio*advantage_tmp\n",
    "            ratio_clamp = torch.clamp(ratio, 1 - e, 1 + e) # clipped ratio\n",
    "            surrogate_2 = ratio_clamp*advantage_tmp\n",
    "            policy_loss = -torch.min(surrogate_1, surrogate_2).mean() #FIX: is this adv detached? yes\n",
    "\n",
    "            # value loss\n",
    "            value_loss = ((value_new - discounted_reward)**2).mean()\n",
    "\n",
    "            # entropy loss: to encourage exploration\n",
    "            entropy_loss = entropy.mean()\n",
    "\n",
    "            loss = policy_loss + value_coef * value_loss - entropy_coef * entropy_loss\n",
    "            loss_record += loss.item()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.5) # FIX: check this\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch} - loss: {round(loss_record/index,2)}')\n",
    "        loss_list.append(loss_record//index)\n",
    "    torch.save(model.state_dict(), './ppo_weight/model_state_tmp.pth')\n",
    "    if cycle % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'./ppo_weight/model_local_gen_{GEN}_default_rwd_{cycle}_iter.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3da580-5a6b-4775-a454-b946cef1ca0f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T05:12:36.624295Z",
     "iopub.status.idle": "2025-04-19T05:12:36.624660Z",
     "shell.execute_reply": "2025-04-19T05:12:36.624486Z",
     "shell.execute_reply.started": "2025-04-19T05:12:36.624470Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "sns.lineplot([i.item() for i in loss_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "sns.lineplot([i.item() for i in game_length_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be777e5b-c2d6-4e05-bb6d-5f3edda4b323",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d138a360-0b2d-403e-bd90-17070754e5b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T05:12:36.634967Z",
     "iopub.status.idle": "2025-04-19T05:12:36.635219Z",
     "shell.execute_reply": "2025-04-19T05:12:36.635115Z",
     "shell.execute_reply.started": "2025-04-19T05:12:36.635100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f63e88cd-5c9c-45e0-96e7-01aa6d0f9178",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T05:12:36.637541Z",
     "iopub.status.idle": "2025-04-19T05:12:36.637828Z",
     "shell.execute_reply": "2025-04-19T05:12:36.637681Z",
     "shell.execute_reply.started": "2025-04-19T05:12:36.637666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f'./ppo_weight/trained_model/model_gen_5_default_rwd_57_iter.pth'\n",
    "\n",
    "\n",
    "\n",
    "if 'gen_3' in path:\n",
    "    model = ppo(N_PLAYER).to(device)\n",
    "    GEN = 3\n",
    "    if 'gen_3_5' in path:\n",
    "        GEN = 3.5\n",
    "elif 'gen_4' in path:\n",
    "    model = ppo_gen_4(N_PLAYER).to(device)\n",
    "    GEN = 4\n",
    "elif 'gen_5' in path:\n",
    "    model = ppo_gen_5(N_PLAYER).to(device)\n",
    "    GEN = 5\n",
    "\n",
    "model.load_state_dict(torch.load(path, map_location = torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ea02b",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "570417da-dfd9-4789-a587-e661bd2f148c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-19T14:04:19.116939Z",
     "iopub.status.busy": "2025-04-19T14:04:19.116634Z",
     "iopub.status.idle": "2025-04-19T14:04:19.142878Z",
     "shell.execute_reply": "2025-04-19T14:04:19.141450Z",
     "shell.execute_reply.started": "2025-04-19T14:04:19.116918Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Card: 29 | Chip in pot: 0 | Player: 0 - Chip: 11 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 29 | Chip in pot: 1 | Player: 1 - Chip: 11 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 29 | Chip in pot: 2 | Player: 2 - Chip: 11 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 29 | Chip in pot: 3 | Player: 0 - Chip: 10 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 29 | Chip in pot: 4 | Player: 1 - Chip: 10 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 29 | Chip in pot: 5 | Player: 2 - Chip: 10 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 29 | Chip in pot: 6 | Player: 0 - Chip: 9 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 28 | Chip in pot: 0 | Player: 0 - Chip: 15 | Card owned: [29]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 17 | Chip in pot: 0 | Player: 0 - Chip: 15 | Card owned: [29, 28]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 17 | Chip in pot: 1 | Player: 1 - Chip: 9 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 17 | Chip in pot: 2 | Player: 2 - Chip: 9 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 17 | Chip in pot: 3 | Player: 0 - Chip: 14 | Card owned: [29, 28]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 0 | Player: 0 - Chip: 17 | Card owned: [29, 28, 17]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 1 | Player: 1 - Chip: 8 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 2 | Player: 2 - Chip: 8 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 3 | Player: 0 - Chip: 16 | Card owned: [29, 28, 17]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 4 | Player: 1 - Chip: 7 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 5 | Player: 2 - Chip: 7 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 6 | Player: 0 - Chip: 15 | Card owned: [29, 28, 17]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 7 | Player: 1 - Chip: 6 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 8 | Player: 2 - Chip: 6 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 34 | Chip in pot: 9 | Player: 0 - Chip: 14 | Card owned: [29, 28, 17]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 27 | Chip in pot: 0 | Player: 0 - Chip: 23 | Card owned: [29, 28, 17, 34]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 27 | Chip in pot: 1 | Player: 1 - Chip: 5 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 27 | Chip in pot: 2 | Player: 2 - Chip: 5 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 27 | Chip in pot: 3 | Player: 0 - Chip: 22 | Card owned: [29, 28, 17, 34]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 10 | Chip in pot: 0 | Player: 0 - Chip: 25 | Card owned: [29, 28, 17, 34, 27]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 10 | Chip in pot: 1 | Player: 1 - Chip: 4 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 10 | Chip in pot: 2 | Player: 2 - Chip: 4 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 33 | Chip in pot: 0 | Player: 2 - Chip: 6 | Card owned: [10]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 33 | Chip in pot: 1 | Player: 0 - Chip: 24 | Card owned: [29, 28, 17, 34, 27]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 11 | Chip in pot: 0 | Player: 0 - Chip: 25 | Card owned: [29, 28, 17, 34, 27, 33]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 11 | Chip in pot: 1 | Player: 1 - Chip: 3 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 11 | Chip in pot: 2 | Player: 2 - Chip: 5 | Card owned: [10]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 30 | Chip in pot: 0 | Player: 2 - Chip: 7 | Card owned: [10, 11]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 30 | Chip in pot: 1 | Player: 0 - Chip: 24 | Card owned: [29, 28, 17, 34, 27, 33]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 30 | Chip in pot: 2 | Player: 1 - Chip: 2 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 30 | Chip in pot: 3 | Player: 2 - Chip: 6 | Card owned: [10, 11]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 30 | Chip in pot: 4 | Player: 0 - Chip: 23 | Card owned: [29, 28, 17, 34, 27, 33]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 19 | Chip in pot: 0 | Player: 0 - Chip: 27 | Card owned: [29, 28, 17, 34, 27, 33, 30]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 19 | Chip in pot: 1 | Player: 1 - Chip: 1 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 19 | Chip in pot: 2 | Player: 2 - Chip: 5 | Card owned: [10, 11]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 19 | Chip in pot: 3 | Player: 0 - Chip: 26 | Card owned: [29, 28, 17, 34, 27, 33, 30]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 19 | Chip in pot: 4 | Player: 1 - Chip: 0 | Card owned: []\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 5 | Chip in pot: 0 | Player: 1 - Chip: 4 | Card owned: [19]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 5 | Chip in pot: 1 | Player: 2 - Chip: 4 | Card owned: [10, 11]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 12 | Chip in pot: 0 | Player: 2 - Chip: 5 | Card owned: [10, 11, 5]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 12 | Chip in pot: 1 | Player: 0 - Chip: 25 | Card owned: [29, 28, 17, 34, 27, 33, 30]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 12 | Chip in pot: 2 | Player: 1 - Chip: 3 | Card owned: [19]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 12 | Chip in pot: 3 | Player: 2 - Chip: 4 | Card owned: [10, 11, 5]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 16 | Chip in pot: 0 | Player: 2 - Chip: 7 | Card owned: [10, 11, 5, 12]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 16 | Chip in pot: 1 | Player: 0 - Chip: 24 | Card owned: [29, 28, 17, 34, 27, 33, 30]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 20 | Chip in pot: 0 | Player: 0 - Chip: 25 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 20 | Chip in pot: 1 | Player: 1 - Chip: 2 | Card owned: [19]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 20 | Chip in pot: 2 | Player: 2 - Chip: 6 | Card owned: [10, 11, 5, 12]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 20 | Chip in pot: 3 | Player: 0 - Chip: 24 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 20 | Chip in pot: 4 | Player: 1 - Chip: 1 | Card owned: [19]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 0 | Player: 1 - Chip: 5 | Card owned: [19, 20]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 1 | Player: 2 - Chip: 5 | Card owned: [10, 11, 5, 12]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 2 | Player: 0 - Chip: 23 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 3 | Player: 1 - Chip: 4 | Card owned: [19, 20]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 4 | Player: 2 - Chip: 4 | Card owned: [10, 11, 5, 12]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 5 | Player: 0 - Chip: 22 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 6 | Player: 1 - Chip: 3 | Card owned: [19, 20]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 7 | Player: 2 - Chip: 3 | Card owned: [10, 11, 5, 12]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 24 | Chip in pot: 8 | Player: 0 - Chip: 21 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 21 | Chip in pot: 0 | Player: 0 - Chip: 29 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 21 | Chip in pot: 1 | Player: 1 - Chip: 2 | Card owned: [19, 20]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 21 | Chip in pot: 2 | Player: 2 - Chip: 2 | Card owned: [10, 11, 5, 12]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 21 | Chip in pot: 3 | Player: 0 - Chip: 28 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 21 | Chip in pot: 4 | Player: 1 - Chip: 1 | Card owned: [19, 20]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 15 | Chip in pot: 0 | Player: 1 - Chip: 5 | Card owned: [19, 20, 21]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 15 | Chip in pot: 1 | Player: 2 - Chip: 1 | Card owned: [10, 11, 5, 12]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 15 | Chip in pot: 2 | Player: 0 - Chip: 27 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 3 | Chip in pot: 0 | Player: 0 - Chip: 29 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24, 15]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 3 | Chip in pot: 1 | Player: 1 - Chip: 4 | Card owned: [19, 20, 21]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 3 | Chip in pot: 2 | Player: 2 - Chip: 0 | Card owned: [10, 11, 5, 12]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 18 | Chip in pot: 0 | Player: 2 - Chip: 2 | Card owned: [10, 11, 5, 12, 3]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 18 | Chip in pot: 1 | Player: 0 - Chip: 28 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24, 15]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 25 | Chip in pot: 0 | Player: 0 - Chip: 29 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24, 15, 18]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 25 | Chip in pot: 1 | Player: 1 - Chip: 3 | Card owned: [19, 20, 21]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 25 | Chip in pot: 2 | Player: 2 - Chip: 1 | Card owned: [10, 11, 5, 12, 3]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 25 | Chip in pot: 3 | Player: 0 - Chip: 28 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24, 15, 18]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 35 | Chip in pot: 0 | Player: 0 - Chip: 31 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24, 15, 18, 25]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 35 | Chip in pot: 1 | Player: 1 - Chip: 2 | Card owned: [19, 20, 21]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 35 | Chip in pot: 2 | Player: 2 - Chip: 0 | Card owned: [10, 11, 5, 12, 3]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 23 | Chip in pot: 0 | Player: 2 - Chip: 2 | Card owned: [10, 11, 5, 12, 3, 35]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 23 | Chip in pot: 1 | Player: 0 - Chip: 30 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24, 15, 18, 25]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 6 | Chip in pot: 0 | Player: 0 - Chip: 31 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24, 15, 18, 25, 23]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 6 | Chip in pot: 1 | Player: 1 - Chip: 1 | Card owned: [19, 20, 21]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 6 | Chip in pot: 2 | Player: 2 - Chip: 1 | Card owned: [10, 11, 5, 12, 3, 35]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n",
      "------------------------------\n",
      "Card: 14 | Chip in pot: 0 | Player: 2 - Chip: 3 | Card owned: [10, 11, 5, 12, 3, 35, 6]\n",
      "\n",
      "------------------------------\n",
      "Move taken: pass\n",
      "------------------------------\n",
      "Card: 14 | Chip in pot: 1 | Player: 0 - Chip: 30 | Card owned: [29, 28, 17, 34, 27, 33, 30, 16, 24, 15, 18, 25, 23]\n",
      "\n",
      "------------------------------\n",
      "Move taken: take\n"
     ]
    }
   ],
   "source": [
    "move_encode = {\"0\": \"pass\",\n",
    "                \"1\": \"take\"}\n",
    "nothanks = nothanks_ppo()\n",
    "human_index = 5\n",
    "\n",
    "while nothanks.is_continue:\n",
    "    print('------------------------------')\n",
    "    print(f'''Card: {nothanks.current_card} | Chip in pot: {nothanks.chip_in_pot} | Player: {nothanks.turn} - {nothanks.players[nothanks.turn]}\\n'''\n",
    ")\n",
    "    print('------------------------------')\n",
    "    if nothanks.turn == human_index:\n",
    "        move = move_encode.get(input(\"\"\"Your turn:\n",
    "0: pass\n",
    "1: take\n",
    "Enter here: \"\"\"))\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            if GEN != 5:\n",
    "                if GEN == 3:\n",
    "                    current_state = torch.tensor(nothanks.encode_state(nothanks.get_state)).to(device)\n",
    "                elif GEN in (3.5, 4):\n",
    "                    current_state = torch.tensor(nothanks.encode_state(nothanks.get_state_gen_3_5)).to(device)                    \n",
    "                legal_move = nothanks.get_legal_action() # a list \n",
    "                legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n",
    "                move_raw, log_prob, entropy, value = model.forward(current_state, legal_move_mask)\n",
    "            else:\n",
    "                x_card, x_state = nothanks.encode_state_gen_5()\n",
    "                x_card = torch.Tensor(x_card).unsqueeze(1).to(device) #1 for 5,33 -> 5,1,33 | 0 for 5,1,33 -> 1,5,1,33\n",
    "                x_state = torch.tensor(x_state).to(device) # 8 to 1,8\n",
    "                legal_move = nothanks.get_legal_action() # a list \n",
    "                legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n",
    "                move_raw, log_prob, entropy, value = model.forward(x_card, x_state, legal_move_mask)\n",
    "            move = nothanks.move_encode.get(move_raw.item())\n",
    "\n",
    "    print(f'Move taken: {move}')\n",
    "    nothanks.action(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e0c7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 28, 17, 34, 27, 33, 30, 16, 24, 15, 18, 25, 23, 14]\n",
      "[19, 20, 21]\n",
      "[10, 11, 5, 12, 3, 35, 6]\n"
     ]
    }
   ],
   "source": [
    "# End-game hand\n",
    "for player_tmp in nothanks.players:\n",
    "    print(player_tmp.card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03988333-1df4-4521-8044-1ed1277389ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:31:39.917479Z",
     "iopub.status.busy": "2025-04-19T14:31:39.917278Z",
     "iopub.status.idle": "2025-04-19T14:31:39.920866Z",
     "shell.execute_reply": "2025-04-19T14:31:39.920171Z",
     "shell.execute_reply.started": "2025-04-19T14:31:39.917463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-66\n",
      "-19\n",
      "-51\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "for player_tmp in nothanks.players:\n",
    "    print(player_tmp.calculate_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d8199ca-ec52-4932-bb96-0bb4e41a6fde",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T05:12:36.641368Z",
     "iopub.status.idle": "2025-04-19T05:12:36.641555Z",
     "shell.execute_reply": "2025-04-19T05:12:36.641473Z",
     "shell.execute_reply.started": "2025-04-19T05:12:36.641465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(-20.0), np.float64(20.0), np.float64(0.0)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking - endgame reward\n",
    "nothanks.calculate_ranking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b0e15-b5b2-4330-88ba-9935285e4b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T05:01:47.951447Z",
     "iopub.status.busy": "2025-04-17T05:01:47.951202Z",
     "iopub.status.idle": "2025-04-17T05:01:47.957353Z",
     "shell.execute_reply": "2025-04-17T05:01:47.956611Z",
     "shell.execute_reply.started": "2025-04-17T05:01:47.951429Z"
    }
   },
   "source": [
    "# Pitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8de9adc-e99f-4179-a0a3-a0ed7808d4b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:39:31.144708Z",
     "iopub.status.busy": "2025-04-19T14:39:31.144481Z",
     "iopub.status.idle": "2025-04-19T14:39:31.149432Z",
     "shell.execute_reply": "2025-04-19T14:39:31.148762Z",
     "shell.execute_reply.started": "2025-04-19T14:39:31.144692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_prefix = 'model_gen_5_5_default_rwd'\n",
    "# model_prefix = 'hyperparam_tuning_'\n",
    "model_list = [i for i in os.listdir('./ppo_weight/trained_model/') if i.startswith(model_prefix)]\n",
    "# model_list = ['model_gen_3_default_rwd_50_iter.pth',\n",
    "#               'model_gen_3_default_rwd_60_iter.pth',\n",
    "#               'model_gen_3_default_rwd_80_iter.pth',\n",
    "#              ]\n",
    "model_name_dict = {a:b for a, b in enumerate(model_list)}\n",
    "n_model = len(model_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46581afe-719a-4403-be80-789a403fd652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:39:31.904229Z",
     "iopub.status.busy": "2025-04-19T14:39:31.904054Z",
     "iopub.status.idle": "2025-04-19T14:39:31.907857Z",
     "shell.execute_reply": "2025-04-19T14:39:31.907219Z",
     "shell.execute_reply.started": "2025-04-19T14:39:31.904215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "select_record = {i:0 for i in range(n_model)}\n",
    "win_record = {i:0 for i in range(n_model)}\n",
    "move_encode = {\"0\": \"pass\",\n",
    "                \"1\": \"take\"}\n",
    "\n",
    "n_match = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4881e608",
   "metadata": {},
   "source": [
    "## Pitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "146842f3-3f0b-4bf1-bbbd-b3adbe774589",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-19T14:19:45.452643Z",
     "iopub.status.busy": "2025-04-19T14:19:45.452292Z",
     "iopub.status.idle": "2025-04-19T14:19:45.486778Z",
     "shell.execute_reply": "2025-04-19T14:19:45.485411Z",
     "shell.execute_reply.started": "2025-04-19T14:19:45.452619Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:01<00:00,  7.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(n_match)):\n",
    "    \n",
    "    model_index = random.sample(range(n_model), k = 3)        \n",
    "    for index in model_index:\n",
    "        select_record[index] += 1\n",
    "    model_list = []\n",
    "    for index in model_index:\n",
    "        path = f'./ppo_weight/trained_model/{model_name_dict.get(index)}'\n",
    "        if 'gen_3' in path:\n",
    "            model = ppo(N_PLAYER).to(device)\n",
    "            GEN = 3\n",
    "            if 'gen_3_5' in path:\n",
    "                GEN = 3.5\n",
    "        elif 'gen_4' in path:\n",
    "            model = ppo_gen_4(N_PLAYER).to(device)\n",
    "            GEN = 4\n",
    "        elif 'gen_5' in path:\n",
    "            model = ppo_gen_5(N_PLAYER).to(device)\n",
    "            GEN = 5\n",
    "        \n",
    "        model.load_state_dict(torch.load(path, map_location = torch.device(device)))\n",
    "        model_list.append(model)\n",
    "    \n",
    "    \n",
    "    nothanks = nothanks_ppo()\n",
    "    while nothanks.is_continue:\n",
    "        with torch.no_grad():\n",
    "            if GEN != 5:\n",
    "                if GEN == 3:\n",
    "                    current_state = torch.tensor(nothanks.encode_state(nothanks.get_state)).to(device)\n",
    "                elif GEN in (3.5, 4):\n",
    "                    current_state = torch.tensor(nothanks.encode_state(nothanks.get_state_gen_3_5)).to(device)                    \n",
    "                legal_move = nothanks.get_legal_action() # a list \n",
    "                legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n",
    "                move_raw, log_prob, entropy, value = model.forward(current_state, legal_move_mask)\n",
    "            else:\n",
    "                x_card, x_state = nothanks.encode_state_gen_5()\n",
    "                x_card = torch.Tensor(x_card).unsqueeze(1).to(device) #1 for 5,33 -> 5,1,33 | 0 for 5,1,33 -> 1,5,1,33\n",
    "                x_state = torch.tensor(x_state).to(device) # 8 to 1,8\n",
    "                legal_move = nothanks.get_legal_action() # a list \n",
    "                legal_move_mask = torch.tensor([False if move in legal_move else True for move in nothanks.move_encode.values()]).to(device)\n",
    "                move_raw, log_prob, entropy, value = model.forward(x_card, x_state, legal_move_mask)\n",
    "            move = nothanks.move_encode.get(move_raw.item())\n",
    "        nothanks.action(move)    \n",
    "    \n",
    "    winner_index = np.argmax(nothanks.calculate_ranking())\n",
    "    win_record[model_index[winner_index]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "323c13dc-5c0d-45bf-9f1c-dbfbf4044322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:41:56.800493Z",
     "iopub.status.busy": "2025-04-19T14:41:56.800231Z",
     "iopub.status.idle": "2025-04-19T14:41:56.835626Z",
     "shell.execute_reply": "2025-04-19T14:41:56.834928Z",
     "shell.execute_reply.started": "2025-04-19T14:41:56.800472Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>total</th>\n",
       "      <th>win</th>\n",
       "      <th>win_pct</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>model_gen_5_5_default_rwd_37_iter.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>model_gen_5_5_default_rwd_58_iter.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>model_gen_5_5_default_rwd_38_iter.pth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  total  win  win_pct                             model_name\n",
       "0      0     10    4      0.4  model_gen_5_5_default_rwd_37_iter.pth\n",
       "1      2     10    4      0.4  model_gen_5_5_default_rwd_58_iter.pth\n",
       "2      1     10    2      0.2  model_gen_5_5_default_rwd_38_iter.pth"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([select_record, win_record]).T\\\n",
    ".rename(columns = {0: 'total',\n",
    "         1: 'win'\n",
    "        })\\\n",
    ".assign(win_pct = lambda df: df['win']/df['total'])\\\n",
    ".sort_values('win_pct', ascending = False)\\\n",
    ".reset_index()\\\n",
    ".assign(model_name = lambda df: df['index'].apply(lambda x: model_name_dict.get(x)))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7175487,
     "sourceId": 11452216,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 307707,
     "modelInstanceId": 286894,
     "sourceId": 342981,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 308514,
     "modelInstanceId": 287724,
     "sourceId": 344038,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
